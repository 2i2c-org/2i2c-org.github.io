<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Reliability | 2i2c</title><link>https://2i2c.org/tag/reliability/</link><atom:link href="https://2i2c.org/tag/reliability/index.xml" rel="self" type="application/rss+xml"/><description>Reliability</description><generator>Hugo Blox Builder (https://hugoblox.com)</generator><language>en-us</language><lastBuildDate>Wed, 08 Oct 2025 00:00:00 +0000</lastBuildDate><image><url>https://2i2c.org/media/sharing.png</url><title>Reliability</title><link>https://2i2c.org/tag/reliability/</link></image><item><title>Combating tcp scanning on mybinder.org with the tcpflowkiller</title><link>https://2i2c.org/blog/2025/mybinder-antiabuse-scanning/</link><pubDate>Wed, 08 Oct 2025 00:00:00 +0000</pubDate><guid>https://2i2c.org/blog/2025/mybinder-antiabuse-scanning/</guid><description>&lt;p>We&amp;rsquo;ve deployed a new tool to &lt;code>mybinder.org&lt;/code> that automatically detects and stops port scanning activity, helping us maintain service reliability while being responsible citizens of the internet.&lt;/p>
&lt;p>Port scanning is a common part of network-based exploits, and many server hosts prohibit this activity (including Hetzner, where the 2i2c &lt;code>mybinder.org&lt;/code> infrastructure lives). We developed a little tool called
&lt;a href="https://github.com/cryptnono/cryptnono/pull/46" target="_blank" rel="noopener" >tcpflowkiller&lt;/a> as part of the
&lt;a href="https://github.com/cryptnono/cryptnono" target="_blank" rel="noopener" >cryptnono&lt;/a> project (our anti-abuse set of tools for hosted JupyterHub and Binder infrastructure) to automatically kill processes that exhibit port scanning behavior. This reduces the likelihood of triggering our server host&amp;rsquo;s abuse policies and helps keep &lt;code>mybinder.org&lt;/code> running reliably.&lt;/p>
&lt;h2 id="why-this-matters">
Why this matters
&lt;a class="header-anchor" href="#why-this-matters">#&lt;/a>
&lt;/h2>&lt;p>As providers of public compute, it&amp;rsquo;s our responsibility to make sure people can&amp;rsquo;t use our infrastructure to abuse others. This is part of being responsible citizens of the internet. It also saves us time in dealing with outages because cloud providers (understandably) block access when they suspect there is abuse.&lt;/p>
&lt;p>Hetzner and similar hosts have many benefits (including
&lt;a href="" >significant cost savings&lt;/a>), and tools like tcpflowkiller help keep hubs and binders running smoothly on such hosts, which have different abuse policies than the big commercial cloud providers.&lt;/p>
&lt;p>AWS and other cloud providers have proprietary ways to combat abuse (like
&lt;a href="https://docs.aws.amazon.com/guardduty/latest/ug/what-is-guardduty.html" target="_blank" rel="noopener" >AWS GuardDuty&lt;/a>). We could have spent our time investing in developing rules there. Instead, contributing to cryptnono helps provide the same set of features in a cloud-agnostic way, in line with
&lt;a href="https://2i2c.org/open-practices/" target="_blank" rel="noopener" >our principles&lt;/a> of supporting open infrastructure that gives communities control over their infrastructure.&lt;/p>
&lt;p>This tool
&lt;a href="https://github.com/jupyterhub/mybinder.org-deploy/pull/3436" target="_blank" rel="noopener" >has now been deployed to mybinder.org&lt;/a>, and we&amp;rsquo;ll monitor its effectiveness over time. We may roll this out to 2i2c public BinderHubs in the future based on patterns we observe.&lt;/p>
&lt;h2 id="learn-more">
Learn more
&lt;a class="header-anchor" href="#learn-more">#&lt;/a>
&lt;/h2>&lt;ul>
&lt;li>
&lt;a href="https://github.com/cryptnono/cryptnono/pull/46" target="_blank" rel="noopener" >tcpflowkiller pull request&lt;/a>&lt;/li>
&lt;li>
&lt;a href="https://github.com/jupyterhub/mybinder.org-deploy/pull/3436" target="_blank" rel="noopener" >mybinder.org deployment&lt;/a>&lt;/li>
&lt;li>
&lt;a href="https://en.wikipedia.org/wiki/Port_scanner" target="_blank" rel="noopener" >Port scanning on Wikipedia&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="acknowledgements">
Acknowledgements
&lt;a class="header-anchor" href="#acknowledgements">#&lt;/a>
&lt;/h2>&lt;ul>
&lt;li>Thanks to
&lt;a href="https://2i2c.org/collaborators/gesis/" >GESIS&lt;/a> for their continued support of &lt;code>mybinder.org&lt;/code> and to
&lt;a href="https://github.com/rgaiacs" target="_blank" rel="noopener" >Raniere Silva&lt;/a> for collaborating on this deployment with us.&lt;/li>
&lt;/ul></description></item><item><title>Demonstrating our infrastructure's reliability with a hub status page for our communities</title><link>https://2i2c.org/blog/2025/status-page/</link><pubDate>Tue, 23 Sep 2025 00:00:00 +0000</pubDate><guid>https://2i2c.org/blog/2025/status-page/</guid><description>&lt;p>One of 2i2c&amp;rsquo;s goals is to &lt;strong>make the cloud safe for science&lt;/strong>.
A big part of this is making the black box of commercial cloud infrastructure more predictable and reliable for our member communities, across our network of community hubs that all operate autonomously.&lt;/p>
&lt;a href="https://docs.google.com/forms/d/e/1FAIpQLSff-u-sWFuwO1-VTgk2Ir7f1nfUUlLevQk_Vkk_jnmcI1nJnw/viewform?usp=pp_url&amp;amp;entry.648332035=https://2i2c.org/blog/2025/status-page/" target="_blank" rel="noopener" class="text-decoration-none">
&lt;div class="alert alert-info d-flex align-items-start p-3" role="button" style="transition: all 0.2s ease; box-shadow: 0 2px 4px rgba(0,0,0,0.1);" onmouseover="this.style.backgroundColor='#b3e5fc'; this.style.boxShadow='0 4px 8px rgba(0,0,0,0.15)'; this.style.transform='translateY(-1px)'" onmouseout="this.style.backgroundColor=''; this.style.boxShadow='0 2px 4px rgba(0,0,0,0.1)'; this.style.transform='translateY(0)'" onfocus="this.style.backgroundColor='#b3e5fc'; this.style.boxShadow='0 4px 8px rgba(0,0,0,0.15)'; this.style.transform='translateY(-1px)'" onblur="this.style.backgroundColor=''; this.style.boxShadow='0 2px 4px rgba(0,0,0,0.1)'; this.style.transform='translateY(0)'">
&lt;div class="fw-bold mb-1">&lt;span style="font-weight:bold">Give us feedback!&lt;/span> Click here to provide feedback that will help us make this more impactful.&lt;/div>
&lt;/div>
&lt;/a>
&lt;p>To that end, we&amp;rsquo;ve created a &lt;strong>status page for 2i2c&amp;rsquo;s network of community hubs&lt;/strong>. This is a source of truth to provide a high-level picture of the stability of our infrastructure, let a community know if their hub is experiencing a problem, and to give us a heads up when things aren&amp;rsquo;t working as expected. You can check it out at:&lt;/p>
&lt;p>ðŸ‘‰
&lt;a href="http://status.2i2c.org" target="_blank" rel="noopener" >&lt;strong>&lt;code>status.2i2c.org&lt;/code>&lt;/strong>&lt;/a>&lt;/p>
&lt;figure id="figure-the-2i2c-status-page-gives-communities-a-high-level-view-of-the-uptime-for-our-entire-network-of-community-hubs">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="The 2i2c Status Page gives communities a high-level view of the uptime for our entire network of community hubs." srcset="
/blog/2025/status-page/featured_hudcfdf27a10fbca3598dd77978ccf2720_32254_65a3e43ecff516e4749f4c8de6cece80.webp 400w,
/blog/2025/status-page/featured_hudcfdf27a10fbca3598dd77978ccf2720_32254_b5951eee6a91520a1d5155144fcbfbc5.webp 760w,
/blog/2025/status-page/featured_hudcfdf27a10fbca3598dd77978ccf2720_32254_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://2i2c.org/blog/2025/status-page/featured_hudcfdf27a10fbca3598dd77978ccf2720_32254_65a3e43ecff516e4749f4c8de6cece80.webp"
width="760"
height="476"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
The 2i2c Status Page gives communities a high-level view of the uptime for our entire network of community hubs.
&lt;/figcaption>&lt;/figure>
&lt;p>While we make status more visible, we&amp;rsquo;re also
&lt;a href="https://github.com/2i2c-org/team-compass/pull/1021" target="_blank" rel="noopener" >streamlining our incident response processes&lt;/a> in order to more quickly respond to outages when they occur (ideally, before a community has even noticed!).&lt;/p>
&lt;p>There are still plenty of improvements we&amp;rsquo;d like to make: for example, we&amp;rsquo;re focusing on major outages right now, but would like to extend some level of reporting for &lt;em>degraded&lt;/em> service, like unexpectedly slow start times.&lt;/p>
&lt;h2 id="learn-more">
Learn more
&lt;a class="header-anchor" href="#learn-more">#&lt;/a>
&lt;/h2>&lt;ul>
&lt;li>ðŸ‘‰
&lt;a href="https://2i2c-hubs.trust.pagerduty.com/posts/dashboard" target="_blank" rel="noopener" >The status page&lt;/a>&lt;/li>
&lt;li>ðŸ‘‰
&lt;a href="https://docs.2i2c.org/admin/reliability/status-page/" target="_blank" rel="noopener" >The status page documentation&lt;/a>&lt;/li>
&lt;li>ðŸ‘‰
&lt;a href="https://github.com/2i2c-org/team-compass/pull/1021" target="_blank" rel="noopener" >Our new process for incident response&lt;/a>&lt;/li>
&lt;li>ðŸ‘‰ Follow an
&lt;a href="https://github.com/2i2c-org/infrastructure/issues/6417" target="_blank" rel="noopener" >in-progress initiative to improve the reliability of our infrastructure&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>Solving classes of problems, rather than just an instance of a problem (with an example)</title><link>https://2i2c.org/blog/2025/automating-support-upgrades/</link><pubDate>Mon, 09 Jun 2025 00:00:00 +0000</pubDate><guid>https://2i2c.org/blog/2025/automating-support-upgrades/</guid><description>
&lt;h2 id="the-problem">
The Problem
&lt;a class="header-anchor" href="#the-problem">#&lt;/a>
&lt;/h2>&lt;p>Two of our the communities we serve (
&lt;a href="https://nmfs-openscapes.github.io/" target="_blank" rel="noopener" >NMFS Openscapes&lt;/a> and
&lt;a href="https://book.cryointhecloud.com" target="_blank" rel="noopener" >CryoCloud&lt;/a>) reported issues with starting GPU nodes on their hubs. Upon investigation, I discovered that the
&lt;a href="https://github.com/kubernetes/autoscaler" target="_blank" rel="noopener" >cluster autoscaler&lt;/a> seems to not recognize that GPUs were available in the cluster at all suddenly, and hence wasn&amp;rsquo;t provisioning the nodes. A restart of the cluster-autoscaler pod fixed the issue for both these communities.&lt;/p>
&lt;h2 id="an-incomplete-solution">
An incomplete solution
&lt;a class="header-anchor" href="#an-incomplete-solution">#&lt;/a>
&lt;/h2>&lt;p>But is that the end of the story? Not if we want to provide reliable long term infrastructure to communities with minimal
&lt;a href="https://sre.google/sre-book/eliminating-toil/" target="_blank" rel="noopener" >toil&lt;/a> on the part of 2i2c engineers!&lt;/p>
&lt;p>One of the engineering principles I&amp;rsquo;m trying to have us more intentionally and structurally embody is the idea that we don&amp;rsquo;t fix individual instances of problems, but &lt;strong>whole classes of problems, rather than just an individual instance of the problem&lt;/strong>. Fixing the immediate issue is &lt;em>not enough&lt;/em> - we need to understand what &lt;strong>class of issues&lt;/strong> was manifesting itself in this particular fashion, and fix &lt;em>that&lt;/em>.&lt;/p>
&lt;h2 id="what-was-the-class-of-issues-we-could-fix-here">
What was the &lt;strong>class of issues&lt;/strong> we could fix here?
&lt;a class="header-anchor" href="#what-was-the-class-of-issues-we-could-fix-here">#&lt;/a>
&lt;/h2>&lt;p>Digging in, I realized that our version of cluster-autoscaler was a little behind and not the latest. I &lt;em>presumed&lt;/em> this was a bug in cluster-autoscaler (given a restart fixed it, implying it is a bug about state). To me, the &lt;em>class of problem&lt;/em> here is that we were not rolling out releases to our &amp;ldquo;supporting infrastructure&amp;rdquo; fast enough. Perhaps if we were on the most recent cluster-autoscaler release, this issue would have never happened.&lt;/p>
&lt;p>Additionally, this failure to scale up was reported to us by the community rather than by an automated alert. We should change that too!&lt;/p>
&lt;h2 id="structured-solutions">
Structured solutions
&lt;a class="header-anchor" href="#structured-solutions">#&lt;/a>
&lt;/h2>&lt;p>We follow a two week sprint cycle, and I love the (hard won) structure it provides us. I don&amp;rsquo;t want to arbitrarily start doing work that upsets prior committed work from that structure. However, we also treat support requests seriously and try to work them into the sprint. So I timeboxed myself for one hour, and saw what I could accomplish. Turns out, a lot!&lt;/p>
&lt;ol>
&lt;li>I
&lt;a href="https://github.com/2i2c-org/infrastructure/pull/6183" target="_blank" rel="noopener" >upgraded all our support components&lt;/a>, tested them, and rolled them out to &lt;em>all&lt;/em> our communities! This included upgrading Grafana, Prometheus, nginx-ingress as well as the cluster-autoscaler. This also restarts the cluster-autoscaler across our clusters, fixing this issue for other communities (if any had it).&lt;/li>
&lt;li>I
&lt;a href="https://github.com/2i2c-org/infrastructure/pull/6182" target="_blank" rel="noopener" >re-enabled&lt;/a> the automatic once a month PR for upgrading these support tasks. We had switched to doing them on a manual sprint cadence, but clearly that was not fast enough nor automated enough. We will instead work these into the sprint once the bot opens the PR. Credit to
&lt;a href="https://github.com/consideratio" target="_blank" rel="noopener" >Erik Sundell&lt;/a> for initially setting this up&lt;/li>
&lt;li>Create
&lt;a href="https://github.com/2i2c-org/infrastructure/issues/6185" target="_blank" rel="noopener" >an issue&lt;/a> to track the alert creation, and put it in our sprint backlog.&lt;/li>
&lt;li>(In an additional fifteen minute timebox) Write this blog post, to communicate out both to the affected communities and others what we have done.&lt;/li>
&lt;/ol>
&lt;p>By timeboxing myself, I didn&amp;rsquo;t upset our sprint cadence and was able to continue doing other work I had committed to in the sprint, while also fixing this &lt;em>class of issues&lt;/em> to the best of my ability.&lt;/p>
&lt;h2 id="moving-forward">
Moving forward
&lt;a class="header-anchor" href="#moving-forward">#&lt;/a>
&lt;/h2>&lt;p>While we have been &lt;em>implicitly&lt;/em> trying to solve whole classes of issues rather than individual instances of an issue as a team for a while, I want us to &lt;em>explicitly&lt;/em> do it from now on. Communicating this out to our communities is an important part of that, as is internal team training. This blog post is the former, and we are continually working on the latter :)&lt;/p>
&lt;h2 id="acknowledgements">
Acknowledgements
&lt;a class="header-anchor" href="#acknowledgements">#&lt;/a>
&lt;/h2>&lt;ul>
&lt;li>Thanks to the
&lt;a href="https://2i2c.org/collaborators/openscapes/" >OpenScapes&lt;/a> and
&lt;a href="https://2i2c.org/collaborators/cryocloud/" >CryoCloud&lt;/a> communities for working with us closely on infrastructure to identify improvements like this.&lt;/li>
&lt;/ul></description></item><item><title>Simplifying and speeding up Binder builds with BuildKit</title><link>https://2i2c.org/blog/2025/binder-buildkit/</link><pubDate>Mon, 03 Mar 2025 00:00:00 +0000</pubDate><guid>https://2i2c.org/blog/2025/binder-buildkit/</guid><description>&lt;p>Chris and Yuvi recently wrote
&lt;a href="https://blog.jupyter.org/simplifying-and-speeding-up-binder-builds-with-buildkit-d44f96582994" target="_blank" rel="noopener" >a blog post on the Jupyter blog&lt;/a> about a recent experiment to significantly reduce the cost of running a node on the mybinder.org federation.&lt;/p>
&lt;h2 id="acknowledgements">
Acknowledgements
&lt;a class="header-anchor" href="#acknowledgements">#&lt;/a>
&lt;/h2>&lt;ul>
&lt;li>
&lt;a href="https://2i2c.org/collaborators/pythia/" >Project Pythia&lt;/a> provides support for some of our work with the Binder project.&lt;/li>
&lt;li>
&lt;a href="https://2i2c.org/collaborators/jupyterhub/" >JupyterHub&lt;/a> for working with us to get this new node deployed for mybinder.org.&lt;/li>
&lt;/ul></description></item><item><title>Tech update: Multiple JupyterHubs, multiple clusters, one repository.</title><link>https://2i2c.org/blog/2022/ci-cd-improvements/</link><pubDate>Tue, 19 Apr 2022 00:00:00 +0000</pubDate><guid>https://2i2c.org/blog/2022/ci-cd-improvements/</guid><description>&lt;p>2i2c manages the configuration and deployment of multiple Kubernetes clusters and JupyterHubs from
&lt;a href="https://github.com/2i2c-org/infrastructure" target="_blank" rel="noopener" >a single open infrastructure repository&lt;/a>.
This is a challenging problem, as it requires us to centralize information about a number of &lt;em>independent&lt;/em> cloud services, and deploy them in an efficient and reliable manner.
Our initial attempt at this had a number of inefficiencies, and we recently completed an overhaul of its configuration and deployment infrastructure.&lt;/p>
&lt;p>This post is a short description of what we did and the benefit that it had.
It covers the technical details and provides links to more information about our deployment setup.
We hope that it helps other organizations make similar improvements to their own infrastructure.&lt;/p>
&lt;h2 id="our-problem">
Our problem
&lt;a class="header-anchor" href="#our-problem">#&lt;/a>
&lt;/h2>&lt;p>2i2c&amp;rsquo;s problem is similar to that of many large organizations that have independent sub-communities within them.
We must centralize the operation and configuration of JupyterHubs in order to boost our efficiency in developing and operating them, but must also treat these hubs &lt;em>independently&lt;/em> because their user communities are not necessarily related, and because we want communities to
&lt;a href="https://2i2c.org/right-to-replicate/" >be able to replicate their infrastructure on their own&lt;/a>.&lt;/p>
&lt;p>A year ago, we built the first version of our deployment infrastructure at
&lt;a href="https://github.com/2i2c-org/infrastructure" target="_blank" rel="noopener" >&lt;i class='fa-brands fa-github'>&lt;/i> github.com/2i2c-org/infrastructure&lt;/a>.
Over the last year of operation, we identified a number of major shortcomings:&lt;/p>
&lt;ul>
&lt;li>Within a Kubernetes cluster, we deployed hubs sequentially, not in parallel. This grew out of a common practice of
&lt;a href="https://sre.google/workbook/canarying-releases/" target="_blank" rel="noopener" >Canary deployments&lt;/a> that allowed us to test changes on a &lt;strong>staging hub&lt;/strong> before rolling them out to a &lt;strong>production hub&lt;/strong>.&lt;/li>
&lt;li>We used a single configuration file for all hubs within a cluster, which led to confusion and difficulty in identifying a hub-specific configuration.&lt;/li>
&lt;li>Moreover, any change to a hub within a cluster caused a re-deploy of &lt;em>all hubs on that cluster&lt;/em>. This is because we did not know whether a given change touched cluster-wide configuration or hub-specific configuration.&lt;/li>
&lt;/ul>
&lt;h2 id="our-goal">
Our goal
&lt;a class="header-anchor" href="#our-goal">#&lt;/a>
&lt;/h2>&lt;p>So, we spent several weeks discussing a plan to resolve these major problems - here were our goals:&lt;/p>
&lt;ul>
&lt;li>We should be able to &lt;strong>upgrade a specific hub&lt;/strong> alone, by inspecting which configuration files have been added or modified.&lt;/li>
&lt;li>&lt;strong>Production hubs should be upgraded in parallel&lt;/strong> when they are effectively run independently.&lt;/li>
&lt;li>We should &lt;strong>use staging hubs as &amp;ldquo;canary&amp;rdquo; deployments&lt;/strong> and not continue upgrading production hubs if the staging hub fails.&lt;/li>
&lt;/ul>
&lt;h2 id="an-overview-of-our-changes">
An overview of our changes
&lt;a class="header-anchor" href="#an-overview-of-our-changes">#&lt;/a>
&lt;/h2>&lt;p>To accomplish this, we needed to identify which hub required an upgrade based on file additions/modifications.
This took a lot of discussion and iteration on design, and so we share it below in the hopes that it is helpful to others!&lt;/p>
&lt;h3 id="improvements-to-our-code-and-structure">
Improvements to our code and structure
&lt;a class="header-anchor" href="#improvements-to-our-code-and-structure">#&lt;/a>
&lt;/h3>&lt;p>We made a few major changes to
&lt;a href="https://github.com/2i2c-org/infrastructure" target="_blank" rel="noopener" >the infrastructure repository&lt;/a> to facilitate the deployment logic described above.
Here are the major changes we implemented:&lt;/p>
&lt;ul>
&lt;li>We separated each hub&amp;rsquo;s configuration into its own file, or set of files. For example,
&lt;a href="https://github.com/2i2c-org/infrastructure/blob/master/config/clusters/2i2c/staging.values.yaml" target="_blank" rel="noopener" >here is 2i2c&amp;rsquo;s &lt;code>staging&lt;/code> hub configuration&lt;/a>.&lt;/li>
&lt;li>We created a separate &lt;code>cluster.yaml&lt;/code> file that holds the canonical list of hubs deployed to that cluster and the configuration file(s) associated with each one. For example,
&lt;a href="https://github.com/2i2c-org/infrastructure/blob/master/config/clusters/2i2c/cluster.yaml" target="_blank" rel="noopener" >here is 2i2c&amp;rsquo;s GKE cluster configuration&lt;/a>, which contains a reference to the previously mentioned
&lt;a href="https://github.com/2i2c-org/infrastructure/blob/master/config/clusters/2i2c/cluster.yaml#L14-L26" target="_blank" rel="noopener" >staging hub&lt;/a>.&lt;/li>
&lt;li>We updated
&lt;a href="https://github.com/2i2c-org/infrastructure/tree/master/deployer" target="_blank" rel="noopener" >our deployer module&lt;/a> to do the following things:
&lt;ul>
&lt;li>Inspect the list of files modified in a Pull Request.&lt;/li>
&lt;li>From this list, calculate the name of a hub that required an upgrade, and the name of its respective cluster.&lt;/li>
&lt;li>Trigger a GitHub Actions workflow that deploys changes in parallel for each cluster/hub pair.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>In addition to these structural and code changes, we also developed new GitHub Actions workflows that control the entire process.&lt;/p>
&lt;h3 id="a-github-actions-workflow-for-upgrading-our-jupyterhubs">
A GitHub Actions workflow for upgrading our JupyterHubs
&lt;a class="header-anchor" href="#a-github-actions-workflow-for-upgrading-our-jupyterhubs">#&lt;/a>
&lt;/h3>&lt;p>We defined a new GitHub Actions workflow that carries out the logic described above.
These are all defined in
&lt;a href="https://github.com/2i2c-org/infrastructure/blob/master/.github/workflows/deploy-hubs.yaml" target="_blank" rel="noopener" >this &lt;code>deploy-hubs.yaml&lt;/code> configuration file&lt;/a>.
Here are the major jobs in this workflow, and what each does:&lt;/p>
&lt;ol>
&lt;li>
&lt;p>&lt;code>generate-jobs&lt;/code>: Generate a list of clusters/hubs that must be upgraded, given the files that are changed in a Pull Request.&lt;/p>
&lt;ul>
&lt;li>Evaluate an input list of added/modified files in a PR&lt;/li>
&lt;li>Decide if the added/modified files warrant an upgrade of a hub&lt;/li>
&lt;li>Generate a list of hubs and clusters that require upgrades, and some extra details:
&lt;ul>
&lt;li>Does the support chart that is deployed to the cluster also need an upgrade?&lt;/li>
&lt;li>Does a staging hub on this cluster require an upgrade?&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>This produced two outputs to be used in subsequent steps:&lt;/p>
&lt;ul>
&lt;li>A &lt;strong>human-readable table&lt;/strong> including information on &lt;em>why&lt;/em> a given deployment requires an upgrade (using the excellent
&lt;a href="https://github.com/Textualize/rich" target="_blank" rel="noopener" >Rich library&lt;/a>).&lt;/li>
&lt;li>&lt;strong>JSON outputs&lt;/strong> that can be interpreted by GitHub Actions as sets of matrix jobs to run.&lt;/li>
&lt;/ul>
&lt;figure id="figure-our-staging-and-support-hub-job-matrix-tells-github-actions-to-deploy-staging-and-support-upgrades-that-act-as-canaries-and-stop-production-deploys-if-they-fail">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Our staging and support hub job matrix tells GitHub Actions to deploy staging and support upgrades that act as canaries and stop production deploys if they fail." srcset="
/blog/2022/ci-cd-improvements/images/staging-hub-matrix_hu7a1bb3fb06e3f581f944c2d267a10ff9_107479_ca59e5ca8dcd2b1ebeab736126bdfc9f.webp 400w,
/blog/2022/ci-cd-improvements/images/staging-hub-matrix_hu7a1bb3fb06e3f581f944c2d267a10ff9_107479_c650383168feaeb478769bd20033f23c.webp 760w,
/blog/2022/ci-cd-improvements/images/staging-hub-matrix_hu7a1bb3fb06e3f581f944c2d267a10ff9_107479_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://2i2c.org/blog/2022/ci-cd-improvements/images/staging-hub-matrix_hu7a1bb3fb06e3f581f944c2d267a10ff9_107479_ca59e5ca8dcd2b1ebeab736126bdfc9f.webp"
width="760"
height="529"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
Our staging and support hub job matrix tells GitHub Actions to deploy staging and support upgrades that act as canaries and stop production deploys if they fail.
&lt;/figcaption>&lt;/figure>
&lt;/li>
&lt;li>
&lt;p>&lt;code>upgrade-support-and-staging&lt;/code>: Update the support and staging Helm charts on each cluster. These are &amp;ldquo;shared infrastructure&amp;rdquo; Helm charts that control services that are shared across all hubs.&lt;/p>
&lt;ul>
&lt;li>Accepts the JSON list described above to determine what to do next&lt;/li>
&lt;li>Parallelises over clusters&lt;/li>
&lt;li>Upgrades the support chart of each if required&lt;/li>
&lt;li>Upgrades a staging hub for the cluster if required (for canary deployments, this is always required if at least one production hub is to be upgraded on the cluster)&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;code>filter-generate-jobs&lt;/code>: Allows us to treat the support / staging hubs as canary deployments for all the production hubs on a cluster.&lt;/p>
&lt;ul>
&lt;li>If a staging/support hub deploy fails, removes any jobs for the corresponding cluster.&lt;/li>
&lt;li>Allows production deploys to continue on &lt;em>other clusters&lt;/em>.&lt;/li>
&lt;/ul>
&lt;figure id="figure-our-production-hub-job-matrix-tells-github-actions-which-hubs-to-update-with-new-changes-these-are-triggered-if-a-clusters-stagingsupport-job-does-not-fail">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Our production hub job matrix tells GitHub Actions which hubs to update with new changes. These are triggered if a cluster&amp;#39;s staging/support job does not fail." srcset="
/blog/2022/ci-cd-improvements/images/prod-hub-matrix_huad3521b0ae4afb8512dab5e3fdf016b6_36691_1ae3e22a321454a0fe1662b19a894e36.webp 400w,
/blog/2022/ci-cd-improvements/images/prod-hub-matrix_huad3521b0ae4afb8512dab5e3fdf016b6_36691_bdf6ab31265f2e43b125c72339342841.webp 760w,
/blog/2022/ci-cd-improvements/images/prod-hub-matrix_huad3521b0ae4afb8512dab5e3fdf016b6_36691_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://2i2c.org/blog/2022/ci-cd-improvements/images/prod-hub-matrix_huad3521b0ae4afb8512dab5e3fdf016b6_36691_1ae3e22a321454a0fe1662b19a894e36.webp"
width="760"
height="515"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
Our production hub job matrix tells GitHub Actions which hubs to update with new changes. These are triggered if a cluster&amp;rsquo;s staging/support job does not fail.
&lt;/figcaption>&lt;/figure>
&lt;/li>
&lt;li>
&lt;p>&lt;code>upgrade-prod-hubs&lt;/code>: Deploy updates to each production hub.&lt;/p>
&lt;ul>
&lt;li>Accepts the JSON list described above to determine what to do next&lt;/li>
&lt;li>Parallelises over each production hub that requires an upgrade&lt;/li>
&lt;li>Deploy the relevant changes to that hub&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ol>
&lt;h2 id="concluding-remarks">
Concluding Remarks
&lt;a class="header-anchor" href="#concluding-remarks">#&lt;/a>
&lt;/h2>&lt;p>We think that this is a nice balance of infrastructure complexity and flexibility.
It allows us to separate the configuration of each hub and cluster, which makes each more maintainable by us, and is more aligned with a community&amp;rsquo;s
&lt;a href="https://2i2c.org/right-to-replicate/" >Right to Replicate&lt;/a> their infrastructure.
It allows us to remove the interdependence of deploy jobs that do not &lt;em>need&lt;/em> to be dependent, which makes our deploys more efficient.
Finally, it allows us to make &lt;em>targeted deploys&lt;/em> more effectively, which reduces the amount of toil and unnecessary waiting associated with each change. (It also
&lt;a href="https://github.blog/2021-04-22-environmental-sustainability-github/" target="_blank" rel="noopener" >reduces our carbon footprint by reducing unnecessary GitHub Action time&lt;/a>).&lt;/p>
&lt;p>We hope that this is a useful resource for others to follow if they also maintain JupyterHubs for multiple communities.
If you have any ideas of how we could further improve this infrastructure, please reach out on GitHub!
If you know of a community that would like 2i2c to
&lt;a href="https://2i2c.org/service/" target="_blank" rel="noopener" >manage a hub for your community&lt;/a>, please
&lt;a href="" >send us an email&lt;/a>.&lt;/p>
&lt;p>&lt;em>&lt;strong>Acknowledgements&lt;/strong>: The infrastructure described in this post was developed by
&lt;a href="" >the 2i2c engineering team&lt;/a>, and this post was edited by
&lt;a href="" >Chris Holdgraf&lt;/a>.&lt;/em>&lt;/p></description></item></channel></rss>