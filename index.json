[{"authors":["chris-holdgraf"],"categories":null,"content":"Chris is the Executive Director of 2i2c. He was previously a post-doctoral researcher in the Department of Statistics at UC Berkeley, and a Community Architect with the Division of Data Science at Berkeley. He is also a team member of Project Jupyter (particularly the JupyterHub and Binder teams), with a focus on how infrastructure can support interactive computing workflows in research and education. He’s interested in the boundary between technology, open-source software, and research and education workflows, as well as how open communities can support and extend these workflows in a way that makes science more impactful and inclusive. His background is in cognitive and computational neuroscience, where he used predictive models to understand the auditory system in the human brain.\nHighlights:\n10+ years leading and building open source projects, open infrastructure teams and services Jupyter Distinguished Contributor Co-led JupyterHub, Binder, and Jupyter Book Co-created the DataHub interactive computing service for the Data Science Education Program at UC Berkeley. ","date":1738108800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1738108800,"objectID":"6b264ebb4849fa5ae2987cd0caffb03d","permalink":"https://2i2c.org/author/chris-holdgraf/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/chris-holdgraf/","section":"authors","summary":"Chris is the Executive Director of 2i2c. He was previously a post-doctoral researcher in the Department of Statistics at UC Berkeley, and a Community Architect with the Division of Data Science at Berkeley.","tags":null,"title":"Chris Holdgraf","type":"authors"},{"authors":["yuvi-panda"],"categories":null,"content":"Building participatory open infrastructure for scientific \u0026amp; educational use cases. A Project Jupyter team member working on infrastructure related projects. Ex Wikimedia and ex-GNOME. Let’s eliminate accidental complexities wherever we find them.\nHighlights:\n10+ years experience building open infrastructure for scientific and educational communities Jupyter Distinguished Contributor Leader in the JupyterHub and Binder projects Served as the Infrastructure Architect behind UC Berkeley’s scalable DataHub Former ops engineer at Wikimedia and GNOME. ","date":1738108800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1738108800,"objectID":"0a9477094d0ef5674613765d19d77fa3","permalink":"https://2i2c.org/author/yuvi-panda/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/yuvi-panda/","section":"authors","summary":"Building participatory open infrastructure for scientific \u0026 educational use cases. A Project Jupyter team member working on infrastructure related projects. Ex Wikimedia and ex-GNOME. Let’s eliminate accidental complexities wherever we find them.","tags":null,"title":"Yuvi Panda","type":"authors"},{"authors":["sarah-gibson"],"categories":null,"content":"Sarah Gibson is an Open Source Infrastructure Engineer at 2i2c, an open source contributor and advocate. She holds more than two years of experience as a Research Engineer at a national institute for data science and artificial intelligence, as well as holding a core contributor role in the open source projects Binder, JupyterHub, and The Turing Way. Sarah is passionate about working with domain experts to leverage cloud computing in order to accelerate cutting-edge, data-intensive research and disseminating the results in an open, reproducible and reusable manner.\nSarah holds a Fellowship with the Software Sustainability Institute and advocates for best software practices in research. She is a member of the mybinder.org operating team and maintains infrastructure supporting over 150k launches of reproducible computational environments per week. She has also mentored projects through two cohorts of the Open Life Science programme, imparting lived experience of her skills participating and leading in open science projects.\n","date":1738058248,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1738059014,"objectID":"83b3d2127330b720674bb862052a869c","permalink":"https://2i2c.org/author/sarah-gibson/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/sarah-gibson/","section":"authors","summary":"Sarah Gibson is an Open Source Infrastructure Engineer at 2i2c, an open source contributor and advocate. She holds more than two years of experience as a Research Engineer at a national institute for data science and artificial intelligence, as well as holding a core contributor role in the open source projects Binder, JupyterHub, and The Turing Way.","tags":null,"title":"Sarah Gibson","type":"authors"},{"authors":["angus-hollands"],"categories":null,"content":"Angus Hollands is an Open Source Applications Engineer at 2i2c. He was previously a post-doctoral researcher in the Computational High Energy Physics group at Princeton University. He has a long-standing history of working collaboratively in open source projects, such as Executable Books, Jupyter, scikit-hep, and Blender. He is motivated by open-source, open-science, and the FAIR principles to build a more accessible, empowering future for scientific research and publication. His scientific background is in nuclear structure, in which he studied a PhD at the University of Birmingham.\n","date":1737417600,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1737417600,"objectID":"33be3fd611c72f8b1268083cb150e1c0","permalink":"https://2i2c.org/author/angus-hollands/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/angus-hollands/","section":"authors","summary":"Angus Hollands is an Open Source Applications Engineer at 2i2c. He was previously a post-doctoral researcher in the Computational High Energy Physics group at Princeton University. He has a long-standing history of working collaboratively in open source projects, such as Executable Books, Jupyter, scikit-hep, and Blender.","tags":null,"title":"Angus Hollands","type":"authors"},{"authors":["georgiana-dolocan"],"categories":null,"content":"Software Engineer irreversibly in love with open source. A JupyterHub team member, focusing on infrastructure and community growth. Previously JupyterHub Contributor in Residence and Outreachy intern through an internship that supports diversity in open source and free software.\n","date":1737072e3,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1737072e3,"objectID":"6b99443e1887b9f34a76d5ae9503a4e1","permalink":"https://2i2c.org/author/georgiana-dolocan/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/georgiana-dolocan/","section":"authors","summary":"Software Engineer irreversibly in love with open source. A JupyterHub team member, focusing on infrastructure and community growth. Previously JupyterHub Contributor in Residence and Outreachy intern through an internship that supports diversity in open source and free software.","tags":null,"title":"Georgiana Dolocan","type":"authors"},{"authors":["jenny-wong"],"categories":null,"content":"Jenny is a Product Manager focused on Platform and Services for 2i2c. Her work has included the CZI-funded Catalyst Project, an initiative aiming to provide research communities in Latin America and Africa with access to large-scale scientific infrastructure. She’s built community-based training materials for interactive cloud-native workflows. Jenny is responsible for direct community engagement to ensure the alignment of Product and Services value streams to the needs of the communities we serve.\nAs a former research software engineer, Jenny has considerable experience supporting researchers with writing documentation, creating video tutorials, and designing and delivering training for advanced research computing. Jenny is also a qualified Software Carpentries Instructor.\nJenny’s background is in mathematics, with a special interest in geophysical fluid dynamics. She obtained a PhD in the subject with her thesis titled “A slurry model of the F-layer in the Earth’s core”.\n","date":1731888e3,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1731888e3,"objectID":"2f015795f698666394aa3c63de977b49","permalink":"https://2i2c.org/author/jenny-wong/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/jenny-wong/","section":"authors","summary":"Jenny is a Product Manager focused on Platform and Services for 2i2c. Her work has included the CZI-funded Catalyst Project, an initiative aiming to provide research communities in Latin America and Africa with access to large-scale scientific infrastructure.","tags":null,"title":"Jenny Wong","type":"authors"},{"authors":["james-munroe"],"categories":null,"content":"James is Senior Product Manager, Open Science Enablement for 2i2c. Coming from a background as an associate professor in the Department of Physics and Physical Oceanography at Memorial University of Newfoundland, he is a strong advocate for enabling scientists and students to be efficient and effective in their computational workflows. Building on previous work in big data oceanography with links to the Pangeo project, COSIMA: Consortium for Ocean-Sea Ice Modelling in Australia, and CIOOS: Canadian Integrated Ocean Observing System, James wants to bring the strength of the Jupyter ecosystem to users across a broad range of educational and research domains.\n","date":1720137600,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1720137600,"objectID":"1603084ce2f0780df78913a58b0e5817","permalink":"https://2i2c.org/author/james-munroe/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/james-munroe/","section":"authors","summary":"James is Senior Product Manager, Open Science Enablement for 2i2c. Coming from a background as an associate professor in the Department of Physics and Physical Oceanography at Memorial University of Newfoundland, he is a strong advocate for enabling scientists and students to be efficient and effective in their computational workflows.","tags":null,"title":"James Munroe","type":"authors"},{"authors":["harold-campbell"],"categories":null,"content":"I enjoy building and supporting communities of practice. I have built a small JS visualization library and dabbled in delivery management systems. Recently, I have strong interests in music (programming VST, etc.), AI and data science.\nHighlights:\n15+ years industry experience spanning companies in Africa and Jamaica 10+ years experience in agile consulting and coaching in technical and product teams Core skills span Enterprise Agile Coaching, Change Management, DevOps, and cloud consultations. ","date":1713139200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1713139200,"objectID":"1871ee3c936a96ebd5a3f1d03bd46ac0","permalink":"https://2i2c.org/author/harold-campbell/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/harold-campbell/","section":"authors","summary":"I enjoy building and supporting communities of practice. I have built a small JS visualization library and dabbled in delivery management systems. Recently, I have strong interests in music (programming VST, etc.","tags":null,"title":"Harold Campbell","type":"authors"},{"authors":["admin"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://2i2c.org/author/2i2c/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/2i2c/","section":"authors","summary":"","tags":null,"title":"2i2c","type":"authors"},{"authors":["april-johnson"],"categories":null,"content":"April is a people \u0026amp; transformation consultant who brings ideas to life, whether that’s making big change happen or creating teams from scratch. She has helped people make their businesses greener, design and build their technology and talent organizations, go public, incorporate new capabilities through acquisition, and scale up for the future.\nHighlights:\n20+ years growing and guiding technology organizations Ex-Global Head of Transformation at Thoughtworks (Europe, Latin America, India, North America, and Asia) expertise in human-centered design, agility, people leadership, change, leading remote and asynchronous agile teams, coaching, and non-profit development. ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"864ac812a97e8f624c7a0b8fe4e1be98","permalink":"https://2i2c.org/author/april-johnson/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/april-johnson/","section":"authors","summary":"April is a people \u0026 transformation consultant who brings ideas to life, whether that’s making big change happen or creating teams from scratch. She has helped people make their businesses greener, design and build their technology and talent organizations, go public, incorporate new capabilities through acquisition, and scale up for the future.","tags":null,"title":"April Johnson","type":"authors"},{"authors":["cathryn-carson"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"d06aefb9519756f12b367d49725e76d9","permalink":"https://2i2c.org/author/cathryn-carson/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/cathryn-carson/","section":"authors","summary":"","tags":null,"title":"Cathryn Carson","type":"authors"},{"authors":["damian-avila"],"categories":null,"content":"Father, Software Developer, Quant, (formerly) Biochemist, and some other things ;-) Currently living between Córdoba and Buenos Aires, Argentina. I have made some contributions to popular Open Source projects such as Jupyter, Nikola, and Bokeh. I have also started several projects being RISE (a “live” slideshow for the Jupyter notebook) the most popular one. You can easily find videos of some of my talks and tutorials at multiples national and international conferences. How can I help?\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"9a4427d33f68e5b2a7e48689f801048a","permalink":"https://2i2c.org/author/damian-avila/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/damian-avila/","section":"authors","summary":"Father, Software Developer, Quant, (formerly) Biochemist, and some other things ;-) Currently living between Córdoba and Buenos Aires, Argentina. I have made some contributions to popular Open Source projects such as Jupyter, Nikola, and Bokeh.","tags":null,"title":"Damián Avila","type":"authors"},{"authors":["erik-sundell"],"categories":null,"content":"Attracted by an inclusive culture and a leverage for a positive world impact, Erik has steered towards open source development in the Jupyter ecosystem from working as a math and physics teacher in Sweden.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"236074155e2fe6a29b991c7208e4c8e5","permalink":"https://2i2c.org/author/erik-sundell/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/erik-sundell/","section":"authors","summary":"Attracted by an inclusive culture and a leverage for a positive world impact, Erik has steered towards open source development in the Jupyter ecosystem from working as a math and physics teacher in Sweden.","tags":null,"title":"Erik Sundell","type":"authors"},{"authors":["fernando-perez"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"3ef1af30502eabcbfbf1b6b9fdec9086","permalink":"https://2i2c.org/author/fernando-perez/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/fernando-perez/","section":"authors","summary":"","tags":null,"title":"Fernando Perez","type":"authors"},{"authors":["giuliano-maciocci"],"categories":null,"content":"Giuliano is a product specialist with an extensive User Experience background and strong analytical skills, I help organisations define their product development roadmaps and customer engagement strategies with a user-focused, data-driven approach that starts by building a shared understanding of what constitutes value, then structures and empowers the organisational talent needed to deliver it. (from Giuliano’s LinkedIn profile)\nHighlights:\n10+ years experience driving growth in companies Ex-Chief Product Officer at Ex Ordo Ex-head of Product at eLife Sciences Led the open science product Executable Research Article Led Qualcomm to $65M platform sale Contributed significantly to mobile design and innovation at Adobe. ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"3d1a70b6153ee523987a5adb34530f61","permalink":"https://2i2c.org/author/giuliano-maciocci/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/giuliano-maciocci/","section":"authors","summary":"Giuliano is a product specialist with an extensive User Experience background and strong analytical skills, I help organisations define their product development roadmaps and customer engagement strategies with a user-focused, data-driven approach that starts by building a shared understanding of what constitutes value, then structures and empowers the organisational talent needed to deliver it.","tags":null,"title":"Giuliano Maciocci","type":"authors"},{"authors":["jim-colliander"],"categories":null,"content":"Jim is a 2i2c Co-Founder. He is a Professor of Mathematics at the University of British Columbia and previously served (2016-2021) as the Director of The Pacific Institute for the Mathematical Sciences (PIMS). While at PIMS and using infrastructure from Compute Canada, he helped create a national-scale JupyterHub service called Syzygy. He co-founded Callysto, a collaboration between PIMS and Cybera. Callysto develops open education resources and training programs for students and teachers in grades 5-12 leveraging cloud-hosted interactive computing. Colliander also co-found Crowdmark, an education technology company based in Toronto that provides workflows and AI-based improvements to education assessment.\nHighlights:\nAward-winning mathematician and professor Ex-Director of the Pacific Institute for Mathematical Sciences He utilized Compute Canada infrastructure to establish Syzygy, a national JupyterHub service Co-founded Callysto for interactive computing in K-12 education. ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"f4e8cb10915e4de235af6e01631e7fd8","permalink":"https://2i2c.org/author/jim-colliander/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/jim-colliander/","section":"authors","summary":"Jim is a 2i2c Co-Founder. He is a Professor of Mathematics at the University of British Columbia and previously served (2016-2021) as the Director of The Pacific Institute for the Mathematical Sciences (PIMS).","tags":null,"title":"Jim Colliander","type":"authors"},{"authors":["lindsey-heagy"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"a0558a9a07b39d5ff5cb0cc779f87cc5","permalink":"https://2i2c.org/author/lindsey-heagy/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/lindsey-heagy/","section":"authors","summary":"","tags":null,"title":"Lindsey Heagy","type":"authors"},{"authors":["ryan-abernathy"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"ee4ec873203b28c0eeafd2019d926eb5","permalink":"https://2i2c.org/author/ryan-abernathey/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/ryan-abernathey/","section":"authors","summary":"","tags":null,"title":"Ryan Abernathey","type":"authors"},{"authors":["Yuvi Panda","Chris Holdgraf"],"categories":["impact"],"content":" If you’re interested in supporting mybinder.org with cloud resources, financial resources, or human resources, please see the Support Binder page for how you can help.\ntl;dr: The 2i2c team is joining the mybinder.org federation with a single-node BinderHub instance at 2i2c.mybinder.org. It should be much cheaper to run than auto-scaling Kubernetes clusters, and might be a good way to support mybinder.org more sustainably. For questions or comments, join this Jupyter Zulip thread.\nmybinder.org is a massive public service for creating and sharing reproducible computational environments. It is managed by the JupyterHub team and members of the mybinder.org federation. One challenge in running mybinder.org is identifying cloud credits or financial resources to support the cloud infrastructure that runs the service. Two years ago, Google stopped supporting mybinder.org federation with cloud credits, and last month the federation lost more capacity, leaving only GESIS and OVH as remaining federation members1. This makes mybinder.org less reliable, slower, and generally less useful to the world.\nThe landscape of cloud infrastructure technology and services has changed considerably, and we think that there’s a way to deploy BinderHub instances with lower costs and less complexity. We’ve accomplished this by deploying a single-node Kubernetes cluster on a VM provider that is much cheaper, now running at 2i2c.mybinder.org. This both relieves Binder’s short-term capacity shortage and may provide an easier pathway for others to support the project in the future.\nBelow, we’ll describe what has changed to enable this, what we’re deploying, and what the impact should be.\nCloud infrastructure has become cheaper and more commodified # A key theory of mybinder.org (and 2i2c) is that commercial cloud infrastructure will be commidified over time – what begins as cutting-edge functionality will become commonplace and offered across all cloud providers. As a result, costs will go down over time. Abstractions like Kubernetes will allow you to easily migrate workflows and infrastructure between cloud providers. As a result, you’ll be able to easily follow those costs where there are better options. That’s essentially what is happening here.\nThere are two key changes that make it much easier to deploy a BinderHub instance at a fraction of the cost:\nFirst, Kubernetes has matured and become easier to deploy. When mybinder.org started, it was using the cutting-edge of Kubernetes functionality. This meant that we needed to use cloud providers that provided a managed Kubernetes service to deal with this complexity. A managed Kubernetes offering tends to be expensive, offered by only a few cloud providers, and thus raises costs across-the-board for the provider that offers it.\nHowever, this was almost a decade ago, and Kubernetes has become both more functional and more stable. There are now many more ways of running Kubernetes, especially for simpler workflows that don’t require autoscaling. In the last several months, we’ve been experimenting with single-node Kubernetes workflows via K3s2. K3s is a lightweight Kubernetes distribution that is much easier to deploy and manage. It’s designed for things like edge computing and low-resource environments, and it can be deployed with a single script!\nBy running a Kubernetes cluster on a single node, we don’t need a “managed Kubernetes service”, which means we can choose from a much larger pool of infrastructure / cloud providers. If all we need is a running VM, this is something the tech industry has been doing for decades.\nSecond, Managed Object Storage services have more open source options, and are more commodified and cheaper. In addition to Kubernetes, the other thing that BinderHub needs is a way to store and retrieve images for the environments that it builds. This also used to be a fairly complex problem, and thus required managed solutions from cloud providers that charged a premium for their service. However, a number of open source object storage solutions have emerged and made it much easier for providers to support this workflow.3. Because these are open source, infrastructure providers can provide managed object storage at a fraction of the cost.\nBecause of these two things, we’ve learned that we can run a BinderHub instance on a single VM from a much larger pool of infrastructure providers. This means we should be able to run BinderHub instances at a fraction of the cost.4\nDeploying BinderHub on a single-node VM is cheaper and simpler # Last week, we deployed 2i2c.mybinder.org, a single-node Kubernetes instance on Hetzner cloud using K3s. This will run on a single node VM, with a Kubernetes instance that is entirely managed by us, and with managed object storage from Hetzner. Compared to other cloud providers, it is around 5x cheaper per month.\nComparison of rough monthly costs across different cloud providers for similar VM instances. These are rough estimates based on cloud …","date":1738108800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1738108800,"objectID":"1fc84a43cb9639a11edb3c8fafb1f7df","permalink":"https://2i2c.org/blog/2025/binder-singlenode/","publishdate":"2025-01-29T00:00:00Z","relpermalink":"/blog/2025/binder-singlenode/","section":"blog","summary":"If you’re interested in supporting mybinder.org with cloud resources, financial resources, or human resources, please see the Support Binder page for how you can help.\ntl;dr: The 2i2c team is joining the mybinder.","tags":["open source"],"title":"2i2c joins the mybinder.org federation with a cheaper and faster way to deploy Binderhub","type":"blog"},{"authors":["Sarah Gibson"],"categories":["impact"],"content":"When sharing a storage disk between users, as is usually the case in a JupyterHub deployment, it is important to put in guardrails so that one user cannot eat up the whole storage capacity from the rest of the users. To this end, 2i2c in close collaboration with Development Seed have developed the jupyterhub-home-nfs project which is a Helm chart that permits enforcing per-user quotas on the storage space.\nNote that this feature is currently available to AWS hosted hubs only and will be rolled out to other cloud providers in the future. Under the hood, the Helm chart runs NFS Ganesha as an in-cluster NFS server, backed by XFS as the underlying filesystem. Storage quota is enforced through XFS’s native quota management utility xfs_quota.\nSince this feature moves our infrastructure away from managed filesystems (such as AWS’s Elastic File System) that cannot support per-user storage quotas, we have also developed monitoring and alerting mechanisms that will let us know when the disks are getting full, and automated back-ups for disaster recovery.\nIf you would like to try this on your 2i2c-managed hub, please get in touch.\nThis project can also be used with any Kubernetes-based JupyterHub, as per our Right to Replicate policy, so please try it out on your own deployment and let us know what you think!\nCredit # This project was developed and deployed in collaboration with Tarashish Mishra from Development Seed, funded through the NASA VEDA project.\n","date":1738058248,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1738059014,"objectID":"06b7e410ee836c79132c9afcc51712ff","permalink":"https://2i2c.org/blog/2025/per-user-storage-quota/","publishdate":"2025-01-28T09:57:28Z","relpermalink":"/blog/2025/per-user-storage-quota/","section":"blog","summary":"When sharing a storage disk between users, as is usually the case in a JupyterHub deployment, it is important to put in guardrails so that one user cannot eat up the whole storage capacity from the rest of the users.","tags":["open-source"],"title":"Enforcing per-user storage quotas with `jupyterhub-home-nfs`","type":"blog"},{"authors":["Chris Holdgraf","Angus Hollands"],"categories":["impact"],"content":"A key challenge in the open source space is that projects are often independent and autonomous, with relatively few formal ways to collaborate and coordinate efforts. While this usually isn’t a big deal, it means that there is a missed opportunity to grow the impact of an ecosystem because it requires coordinated development among multiple stakeholders within it.\nThis is one of the reasons we created 2i2c’s open community hub platform. By deploying a single platform that utilizes entirely open infrastructure that we contribute back to, we have visibility over a variety of projects along with the need to combine them together for a specific end-user outcome. One-such development scenario recently came up involving Jupyter Book 2 and JupyterHub.\nAllowing readers to “bring their own Binders” # We’ve recently been working to integrate Jupyter Book 2 workflows with our community hubs for a more seamless experience (for example, having book pages link back to interactive cloud sessions that allow users to interact with the content). We imagine a network of Jupyter Books that all build upon the same core infrastructures (JupyterHub, Binder, etc) for cloud-based computing. Our hope is to allow a user to bring their own Binder with them so that they can interact with another book’s content with their own cloud infrastructure. For example:\nA student with access to binder.myuniversity.edu could read a Jupyter Book created by a professor at otheruniversity.edu. The Jupyter Book is defined with a Binder specification that has a recipe for re-building the environment needed to run te book’s content. From the professor’s book, the student can choose to launch an interactive Binder sessions on their university’s Binder, allowing them to interact with the book’s content on their own infrastructure. We want a workflow like this to be as seamless and un-complicated as possible. We also want it to follow the same fundamental workflow as the nbgitpuller-based launch buttons. Along the way, we realized that we needed to coordinate development across Jupyter Book 2], JupyterHub, and BinderHub.\nThe three projects (Jupyter Book, BinderHub, and JupyterHub) that needed to work together to enable ‘bring your own binderhub’ workflows. Getting Jupyter Book to discover Jupyter Hub # As we began developing this workflow, we realized that there was a blocker in the JupyterHub and BinderHub ecosystem that needed to be fixed. We needed a way to ask a JupyterHub whether it had an unauthenticated end-point for service discovery. Basically, a way to ask a hub “what kind of hub are you, and how can we launch an interactive session on you?” Doing this is simple-enough - JupyterHub already has a way of reporting its version and application type, which allows us to infer how to launch interactive sessions. But, we hit a snag in an HTML context.\nBy default, JupyterHub disallows certain kinds of Cross-Origin Resource Sharing (CORS) requests, in order to restrict other applications from abusing a JupyterHub’s API. If you hit parts of a JupyterHub API from the command line, things work fine. But if you do the same thing via JavaScript from a website, the request is disallowed. This was a problem if we want Jupyter Book (a web application) to be able to make requests of JupyterHub’s API.\nSo, we realized that we needed to make an upstream contribution in JupyterHub in order to enable an interaction between JupyterHub and Jupyter Book. In this case, it was a relatively simple fix: allowing CORS requests for the specific API endpoint we needed (which is a very lightweight endpoint that is not vulnerable to security risks, and is broadly useful to make accessible)1. That resulted in two PRs:\njupyterhub/jupyterhub#4966 allows CORS requests for the API that was needed for service discovery in JupyterHub. jupyterhub/binderhub#1906 enables this workflow on a BinderHub so that its services can be discovered. jupyter-book/myst-theme#503 adds new launch button functionality to Jupyter Book 2 that allows readers to bring their own Binder / JupyterHub links for launching. (this is what necessitated the above two PRs) As a result of this upstream contribution loop, JupyterHub can now accept API requests at its “service discovery” endpoint, which means that Jupyter Book (and any other web application) can more easily learn about a hub’s capabilities and version.\nWe wanted to share this short vignette because it’s a good reflection of the kind of value that 2i2c tries to provide, given its role in helping to build and enhance networks of infrastructure, domain communities, and open source communities. In this case, we enabled a cross-project workflow that required knowledge of each project, and a vision for how they could be used together in a way that exceeded the sum of their parts.\nWe think there’s a lot more potential in these kinds of workflows, and are eager to continue our work to identify and enhance community-centric infrastructure for interactive computing. …","date":1737417600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1737417600,"objectID":"8d69958597250c9e86925706aaf80654","permalink":"https://2i2c.org/blog/2025/jupyter-book-cors/","publishdate":"2025-01-21T00:00:00Z","relpermalink":"/blog/2025/jupyter-book-cors/","section":"blog","summary":"A key challenge in the open source space is that projects are often independent and autonomous, with relatively few formal ways to collaborate and coordinate efforts. While this usually isn’t a big deal, it means that there is a missed opportunity to grow the impact of an ecosystem because it requires coordinated development among multiple stakeholders within it.","tags":["open source"],"title":"Designing for an ecosystem: a case study in cross-project open source contribution","type":"blog"},{"authors":["Georgiana Dolocan"],"categories":["enhancements"],"content":"We are excited to announce that all 2i2c hubs now run JupyterHub 5.0!\nThis is an upgrade that brings some exciting new features and improvements. Some of the highlights include:\nThe possibility to enable user-initiated server sharing Authenticator-managed roles Also, JupyterHub 5 will enable us to offer per-group shared directories in the future! Tracking Issue.\nCheckout the JupyterHub 5.0 migration docs or the changelog for more details.\n","date":1737072e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1737072e3,"objectID":"740a133e8f73eed9a9d92c1b30d1b4e1","permalink":"https://2i2c.org/blog/2025/jupyterhub5-upgrade/","publishdate":"2025-01-17T00:00:00Z","relpermalink":"/blog/2025/jupyterhub5-upgrade/","section":"blog","summary":"We are excited to announce that all 2i2c hubs now run JupyterHub 5.0!\nThis is an upgrade that brings some exciting new features and improvements. Some of the highlights include:","tags":[],"title":"2i2c hubs now run JupyterHub 5.0","type":"blog"},{"authors":["Yuvi Panda","Chris Holdgraf"],"categories":["organization"],"content":"In this post, we’re sharing our Commitment to Open Technology. It is focused on software licenses for reasons we’ll describe below. We hope that it clarifies what kind of licenses we’ll use, and assures our communities that we will not change our stance towards open source technology in the future. This ensures 2i2c’s long-term commitment to community-owned and open infrastructure.\nBeing a platform and service provider gives us a lot of power, and also introduces a potential source of lock-in for our member communities. While 2i2c’s organizational mission and culture are strongly aligned with open infrastructure, we believe it’s important to encode commitments like these in a formal way to provide both transparency and accountability to our member communities.\nOur commitment to open technology # Below we copy the original language of this policy from our Commitment to Open Technology:\nDefinitions of MUST, MUST NOT, SHOULD, MAY, etc are defined in RFC 2119\nAll engineering artifacts (code, documentation, etc) produced by 2i2c’s engineering team MUST be licensed under an open source license approved by a non-profit organization that is not 2i2c. Open Source Projects originating at 2i2c, or stewarded by 2i2c, MUST NOT require a Contributor Licensing Agreement that includes Copyright Assignment to 2i2c. The list of external organizations that define licenses we accept are the Open Source Initiative the Organization for Ethical Source. Modifying (1), (2), or (3) MUST be done through a 2/3 majority vote of 2i2c staff. What does this commitment mean? # In plain language, here’s what this commitment means:\nWe’ll only use open source licenses that have been approved by standard non-profits that are broadly recognized by the tech industry. For anything we build, we won’t require contributors to give up the rights to their contributions via CLAs, so that it is much harder for 2i2c to change our licenses in the future. Changing this policy will require organization-wide agreement, and in the future we’ll give authority over this policy to a group of people representing our member communities. Why are licenses and CLAs important? # Many organizations claim to be committed to open infrastructure, while retaining the ability to change this commitment in the future when it is in their interests. A classic example of this is a “bait and switch” that looks something like this:\nA company releases software under an open source license and professes to build an open source community around it. However, they retain the rights to all of the code in their projects through a Contributor License Agreement (CLA) with copyright assignment. This generally means that contributors must give up the rights to their contribution in order to make that contribution. Once their product has gained traction and it is in their interests, the company can change the license to whatever they wish (even one that is not open source) because they retain the rights to all contributions in the codebase. They then leverage this new position as owners of a proprietary project to extract business value or grow their position in a market. Think this sounds unlikely? Here are just a few recent examples of companies that have switched their license after many years of releasing their technology under an open source license:\nRedis Hashicorp / Terraform Elastic Search We want to ensure our communities that 2i2c is not headed down this path, in order to give them confidence in treating us as a long-term service partner.\nWhat does this change about 2i2c’s open source commitment? # In short: nothing. These are already the principles that 2i2c was committed to from its inception, and already implied via our Right to Replicate. However, we wanted to make these commitments more formally in order to give ourselves more accountability to sticking with them, and to provide more transparency for our community members and stakeholders.\nWho is this for? # We imagine three audiences for this policy:\n2i2c present and future staff who want to ensure that their organization remains committed to our open principles. This document provides a sense of psychological safety to have bold discussions about structuring our approach to open source. Member communities and 2i2c stakeholders who need to have an understanding of the guarantees that we provide in order to trust 2i2c as a service developer and provider. This is similar to the effect our Right to Replicate has. Open source communities who need to understand our long-term commitment and goals around open technology in order to trust as a peer and collaborator within open source communities. We’d love feedback # We hope that these ideas both clarify our intent and the reason that we think it’s important. We’d love feedback about early refinements to these principles in order to make them more effective, as well as ways that we can provide more community oversight and participation in evolving these policies moving forward. If you …","date":1736899200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1736899200,"objectID":"304f2181b1c0a509a587ba8ed72d28d0","permalink":"https://2i2c.org/blog/2025/community-ownership/","publishdate":"2025-01-15T00:00:00Z","relpermalink":"/blog/2025/community-ownership/","section":"blog","summary":"In this post, we’re sharing our Commitment to Open Technology. It is focused on software licenses for reasons we’ll describe below. We hope that it clarifies what kind of licenses we’ll use, and assures our communities that we will not change our stance towards open source technology in the future.","tags":["open-source"],"title":"Announcing our formal commitment to open technology","type":"blog"},{"authors":["Yuvi Panda"],"categories":[],"content":"A non-exhaustive list of things 2i2c and Development Seed did with the NASA VEDA project last quarter!\nAutomated backups and alerting with jupyterhub-home-nfs # Tracking Issue\njupyterhub-home-nfs is a young project to provide flexible per-user home directory limits on JupyterHub - an important feature for controlling cloud costs. Tarashish Mishra and Sarah Gibson have been leading this project for the last few months. Since we are moving away from AWS Managed EFS here, we had to do some work to recreate some of the benefits EFS gives us out of the box. During this quarter, we:\nSet up automated backups so we can recover files in cases of disaster Set up automated alerting (via prometheus and pagerduty) to know if our backing EBS device is getting full and we need to perform a manual intervention Deployed this to a few other communities ( CryoCloud and NMFS Openscapes) to broaden adoption. We will continue doing work on jupyterhub-home-nfs in the upcoming quarter! If this is functionality you are interested in deploying, please reach out to us to collaborate!\nEnable users to dynamically build environments with jupyterhub-fancy-profiles # Tracking Issue\nWe covered this more extensively in another blog post, so go read that!\nThis work in particular is a good demonstrator of 2i2c’s value - it started off with a grant from GESIS, and now with support from NASA IMPACT we are able to bring it to a lot of communities, not just the ones that funded it.\nOngoing work here will focus on improving the UX as well as better documentation so users can actually use it!\n“Open in QGIS” from VEDA UI # Tracking Issue\nWe had worked in the past with many communities in enabling QGIS on the Cloud, and this quarter we got closer to enabling a contextual ‘Open in QGIS’ button in the VEDA Dashboard! Here is a quick demo:\n(This shows the workflow when user is already logged into the JupyterHub and had started the server)\nYou can play with this in this preview, although you need to have access to the NASA VEDA hub to fully try it out at this point.\nTarashish from Development Seed is again responsible for most of the work here, available in jupyter-remote-qgis-proxy. You can use it to create ‘magic links’ that will open QGIS in a desktop environment in your browser, and add a specific layer to it! Our hope is that this allows primarily GIS folks to better use tools they already are familiar with in cloud based contexts.\nOther updates # We participated heavily in an evaluation process for the authentication and authorization solution to be used across NASA VEDA! Tracking Issue We are very close to rolling out JupyterHub 5.0 and associated changes across all our hubs, which will enable us to eventually offer per-group shared directories! Tracking Issue ","date":1736291917,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1736291917,"objectID":"b4ba367834e7c1c4fb2dec1243c4f217","permalink":"https://2i2c.org/blog/2025/veda-update-q4-2024/","publishdate":"2025-01-07T15:18:37-08:00","relpermalink":"/blog/2025/veda-update-q4-2024/","section":"blog","summary":"A non-exhaustive list of things 2i2c and Development Seed did with the NASA VEDA project last quarter!\nAutomated backups and alerting with jupyterhub-home-nfs # Tracking Issue\njupyterhub-home-nfs is a young project to provide flexible per-user home directory limits on JupyterHub - an important feature for controlling cloud costs.","tags":[],"title":"NASA VEDA \u0026 2i2c Update for Q4 2024 (Oct-Dec 2024)","type":"blog"},{"authors":null,"categories":["impact"],"content":"We are proud to share that several of 2i2c’s community partners are presenting their work at AGU 2024! In each case, 2i2c’s infrastructure plays a part in helping communities create and share knowledge, and grow their community. As an organization rooted in community-centric practices, we are particularly excited to see 2i2c represented “indirectly” at this conference, and to see ourselves as a supporting role enabling the impact of others.\nHere’s a summary and links to all of the sessions. See below for a brief overview of seach one.\nED31G-2272 Breaking down the barriers to Open Science with Project Pythia ED31G-2277 PACE Hackweek: An open community keeping up with PACE IN13A-2147 Including more solutions and more solvers via actionable open science IN34A-01 Beyond Open Data: Ensuring True Accessibility for All (Invited) Introducing GeoLab - An EarthScope JupyterHub for Enabling Collaborative Cloud-Native Geophysical Data Analysis and Skill Development Workshops U13A-2349 Sharing recipes for cloud computing: the Project Pythia Cookbook Initiative U13A-2350 Supporting NASA Earthdata users in the Cloud: NASA Openscapes JupyterHub and User Onboarding \u0026amp; Fledging V31A-08 VICTOR – A new Cyber-infrastructure for Volcanology ED31G-2272 Breaking down the barriers to Open Science with Project Pythia # Link to session\nHall B-C (Poster Hall) (Convention Center)\nAbstract # Project Pythia is an open access educational initiative established with funding from the U.S. National Science Foundation. Its mission is to help students and scientists enhance their skills and adopt best practices using the tools and technologies of open science. As part of the Pangeo community, Project Pythia primarily focuses on the Pangeo stack, which includes cloud computing, Jupyter technologies, GitHub, and various software packages in the Scientific Python ecosystem, centered around Xarray. Project Pythia offers a wide range of open access content, such as datasets, software, tutorials, and annotated real-world workflows presented in the form of Jupyter Books.\nProject Pythia serves as a resource for scientists, promoting and fostering open science. Although it is not a scientific research artifact itself, the development of Project Pythia adheres to many best practices advocated by open science proponents. The Pythia team actively encourages community engagement and collaborates openly with scientists and technologists to create new content. All Pythia resources are freely accessible, and the project follows the FAIR principles (Findable, Accessible, Interoperable, and Reusable) for managing research outputs, including publications, data, and other materials. We support and facilitate open evaluation and peer reviews of content to ensure verifiability and trust. Lastly, we endeavor to openly discuss ideas, designs, and methods before implementation.\nThis presentation will provide an overview of Project Pythia’s extensive educational resources and share our experiences in applying many open science principles to develop this flagship training resource for the geoscience community.\nAuthors # John Clyne - NSF National Center for Atmospheric Research (first author) Drew Camron - University Corporation for Atmospheric Research Orhan Eroglu - NSF National Center for Atmospheric Research Robert Ford - University at Albany State University of New York Julia Kent - NSF National Center for Atmospheric Research Ryan May - University Corporation for Atmospheric Research James Munroe - 2i2c / Code for Science and Society Brian E J Rose - SUNY at Albany ED31G-2277 PACE Hackweek: An open community keeping up with PACE # Link to session\nAbstract # The NASA Plankton, Aerosol, Cloud, ocean Ecosystem (PACE) mission, while bringing NASA’s Earth System Observatory up to speed with aquatic, atmospheric, and terrestrial science capabilities, is also providing data records of the Earth System for the next generation of scientists to grow into. The goal of the PACE Hackweek, supported by the Ocean Carbon \u0026amp; Biogeochemistry program and hosted at the University of Maryland Baltimore County in August 2024, was to enrich and support the practice of open science by both emerging and established researchers. Cloud-compute resources for the event were provided by CryoCloud, a NASA funded collaboration between ICESat-2 and the International Interactive Computing Collaboration (2i2c) to provide cryosphere researchers with a shared JupyterHub. We, the hackweek mentors, were buoyed by the NASA Openscapes program and adopted its mantra of striving toward “a kinder science for future us.” Participants faced two novelties: the “firehose” of data from the PACE instrument array (a hyper-spectral imaging spectrometer, a wide-swath hyper-angular polarimeter, and a narrow-swath spectro-polarimeter), and the distribution of PACE collections through the NASA Earthdata Cloud (a first for the Ocean Biology Distributed Active Archive Center). We present our approach and the challenges …","date":1733702400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1733702400,"objectID":"c2524ff1fb630ba5c8f861550a470f34","permalink":"https://2i2c.org/blog/2024/agu/","publishdate":"2024-12-09T00:00:00Z","relpermalink":"/blog/2024/agu/","section":"blog","summary":"We are proud to share that several of 2i2c’s community partners are presenting their work at AGU 2024! In each case, 2i2c’s infrastructure plays a part in helping communities create and share knowledge, and grow their community.","tags":["geoscience","education"],"title":"2i2c communities at AGU 2024","type":"blog"},{"authors":["Chris Holdgraf"],"categories":["organization"],"content":"2024 has been a busy year for 2i2c, with many highs and lows, a lot of impact, and significant organizational change. As the year comes to an end, I want to reflect on the work we’ve done in 2024, and where we aim to go in 2025.\nIn 2024, 2i2c reached the point in an organization’s lifecycle when a team has grown enough in size and complexity that you must change the ways that you organize. The informal ways that worked as a small group don’t suffice anymore, and you have to put more effort into aligning and coordinating everyone to ensure you have the same impact.\nI call this the “$1M to $2M budget jump”, because organizations seem to hit this point around when your annual budget goes from $1M to $2M. Getting to the other side of this gap with an intact runway and team is hard, and I suspect that 2i2c’s fully distributed nature means that we hit these scaling milestones earlier than many organizations. For us, this has been a major focus of effort all year, and has involved taking a top-to-bottom look at our plans and ways of working as a team. Read on for more details about major updates, challenges, and impact that our team had in 2024.\nOrganizational updates # At an organizational level, this year had a lot of introspection and planning, a few new roles, a few departing team members, a funding crunch, a successful effort to dig out of it, and a new system of work organizing our team. We’ll share more about all of this later, but here are the major implications for our team:\nWe’ve raised another $2.2M in funding to support our efforts in scaling and sustaining our network of community hubs. This gives us roughly another 2 years of projected runway (with some assumptions about revenue from contracts and grants). Below are two posts that describe two major awards we were awarded in Q3 and Q4 of this year:\nA one-year award from the Chan Zuckerberg Initiative. A two-year award from The Navigation Fund. We’ve designed and hired several strategic and systems-level roles to give our team support and direction as it grows. Here’s a brief summary:\nHead of Product, Giuliano Maciocci. Giuliano leads our efforts to define and steward our value proposition and the roadmap of development for products and services that feeds into it. Giuliano has 10+ years experience driving growth in companies, was the ex-Chief Product Officer at Ex Ordo, ex-head of Product at eLife Sciences where he led the open science product Executable Research Article, and contributed significantly to mobile design and innovation at Adobe. Chief of Staff and Delivery Manager, Harold Campbell. Harold leads our delivery and operations efforts, and stewards our system of work and coordination around it to ensure we deliver on our commitments efficiently and reliably. Harold has 15+ years of industry experience spanning companies in Africa and Jamaica, and 10+ years experience in agile consulting and coaching in technical and product teams. People Lead, April Johnson. April leads and stewards our system to support our team as individuals, ensuring that we provide the guidance and support needed to grow our team members in their careers and skills. April has 20+ years growing and guiding technology organizations. She is the ex-Global Head of Transformation at Thoughtworks (Europe, Latin America, India, North America, and Asia), with expertise in human-centered design, agility, people leadership, change, leading remote and asynchronous agile teams, coaching, and non-profit development. We’ve re-organized our team into separate product and business development teams, in order to focus on providing an excellent technical platform and a collection of services that maximizes community impact, as well as sustaining this service for our communities. This has allowed us to more effectively coordinate our service enhancement and development efforts, and increases our ability to deliver improvements to our communities and to upstream projects.\nAs a result, our organization has a much stronger foundation to build upon as we continue to grow and refine our sustainability model in 2025. It has positioned us to more effectively deal with the challenges in reaching our next milestones for scale and impact, and gives us the tools to be more adaptive and responsive to community needs.\nAlong the way, we also generated a lot of impact through our collaborations with communities in our network, and in the upstream projects that we support. For more details about our impact, see the summaries below.\nCommunity impact # 2i2c’s core mission is to support its network of communities that create and share knowledge with open infrastructure. Here are the highlights of how our community network has grown and had impact.\nFirst, we’ve grown our network of hubs and users through several new partnerships. We grew the number of active hubs from ~75 to ~105, and grew our end-of-year Monthly Active Users (MAUs) from ~6000 to ~8000.\nYou can see an interactive version of these numbers in …","date":1733616e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1733616e3,"objectID":"6a8bf5c6ee742e3d5013005eb0e39f43","permalink":"https://2i2c.org/blog/2024/retrospective/","publishdate":"2024-12-08T00:00:00Z","relpermalink":"/blog/2024/retrospective/","section":"blog","summary":"2024 has been a busy year for 2i2c, with many highs and lows, a lot of impact, and significant organizational change. As the year comes to an end, I want to reflect on the work we’ve done in 2024, and where we aim to go in 2025.","tags":["report"],"title":"2024 impact report: new team structure, new funding, and growth in our network","type":"blog"},{"authors":["Chris Holdgraf"],"categories":["organization"],"content":"We are proud to announce that 2i2c has received financial support from The Navigation Fund to assist us in our mission to design and build a sustainable and scalable model for helping communities create and share knowledge with open infrastructure.\nFunding comes from the Open Science Initiative of The Navigation Fund, which is ‘…dedicated to transforming scientific research by enhancing collaboration and innovation. We support tools and approaches that move beyond traditional practices, making scientific knowledge more accessible and impactful.’ The award totals ~$1.5M over 2 years. It provides support for several key strategic roles that are traditionally difficult to fund in a young organization: product management, delivery management, and business development. Here are the key goals this funding works toward:\nGoal #1: Delivery. Develop the operating structure and team skills to efficiently scale our product and service delivery. Goal #2: Product. Develop a product system that continuously improves and delivers value and impact at scale. Goal #3: Sustainability. Build a business model that is competitive and gives us resources to sustain and scale our service. We believe this is a critical step in helping our organization define and build a pathway to sustainability so that our service remains accessible, scalable, and resilient for years to come.\nWe’re incredibly honored to be supported by the Navigation Fund, and excited to continue our work helping communities create and share knowledge with open infrastructure.\n","date":1733616e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1733616e3,"objectID":"21ca59d450904133a27ed4e27ee8b85e","permalink":"https://2i2c.org/blog/2024/funding-navigation/","publishdate":"2024-12-08T00:00:00Z","relpermalink":"/blog/2024/funding-navigation/","section":"blog","summary":"We are proud to announce that 2i2c has received financial support from The Navigation Fund to assist us in our mission to design and build a sustainable and scalable model for helping communities create and share knowledge with open infrastructure.","tags":["funding"],"title":"Financial support from The Navigation Fund for identifying and building a scalable sustainability model","type":"blog"},{"authors":null,"categories":["impact"],"content":"2i2c is pleased to announce the frx-challenges project, a new open source tool to help communities host data challenges on shared infrastructure:\n2i2c-org/frx-challenges\nThis project aims to make it easier for administrators to provide a service that enables users to submit code and data that are evaluated on secure infrastructure with access to private data and resources. It also provides a leaderboard that helps users compare their performance against others.\nAn example leaderboard for a data challenge, taken from the Cellmap Challenge. Users make submissions that are run against secure and private infrastructure and data, and provides feedback about the submission’s performance. Learn more about the FRX challenges project here: 2i2c.org/frx-challenges/ It is designed to be lightweight and flexible, and can be run on a variety of shared infrastructure. For those who wish to run this project on cloud infrastructure, we’ve also published a Helm Chart to help you deploy frx-challenges with Kubernetes.\nWhile it can be run on its own, we believe that it naturally complements other tools and services for interactive computing and data, such as JupyterHub, Jupyter Book, and Binder. More on that below.\nBelow is a brief description of the motivation behind this project.\nWhat are Frictionless Research Exchanges # The project is heavily inspired by David Donoho’s vision of Frictionless Research Exchanges (FRX) as described in Data Science at the Singularity.\nIn this article, Donoho describes three key pillars for Frictionless Research Exchanges:\nThe three initiatives are related but separate; and all three have to come together, and in a particularly strong way, to provide the conditions for the new era. Here they are:\n[FR-1: Data] datafication of everything, with a culture of research data sharing. One can now find datasets publicly available online on a bewildering variety of topics, from chest x-rays to cosmic microwave background measurements to uber routes to geospatial crop identifications. [FR-2: Re-execution] research code sharing including the ability to exactly re-execute the same complete workflow by different researchers. [FR-3: Challenges] adopting challenge problems as a new paradigm powering scientific research. The paradigm includes: a shared public dataset, a prescribed and quantified task performance metric, a set of enrolled competitors seeking to outperform each other on the task, and a public leaderboard. Thousands of such challenges with millions of entries have now taken place, across many fields. We considered the landscape of tools and services, and felt that [FR-1] and [FR-2] were already well-served by a variety of tools and services for community workspace infrastructure (e.g., JupyterHub: jupyterhub.readthedocs.io), sharable computational environments (e.g., BinderHub: binderhub.readthedocs.io), authoring and reading computational narratives (e.g., Jupyter Book: jupyterbook.org and MyST: mystmd.org), and data I/O tools and standards (e.g., Zarr: zarr.readthedocs.io and Intake: intake.readthedocs.io).\nHowever there was a natural missing piece for [FR-3 Challenges], and we could not identify any community-managed infrastructure that facilitated data challenges. This is the goal of frx-challenges.\nWhy facilitate data challenges? # Data challenges are harder than you think! While it is simple enough to run somebody else’s code locally, data challenges require a systematic, secure, and automated approach to accepting and evaluating submissions in a fair and repeatable way. Here are some of the big challenges to tackle:\nSubmissions must retain user and team identity, which means that we must keep track of users and their submissions over time, since data challenges are designed to encourage iterative improvement and optimization. Evaluations must use potentially complex resources and data since many data challenges operate by publicly sharing a small dataset, and then running it against a much more complex dataset. Evaluations must be totally secure, so that submissions can’t do nefarious things like mine cryptocurrency or extract the challenge’s private data in unintended ways. Evaluations must be automated, so that running the challenge does not require extensive human intervention and can scale to many users. Evaluation must be flexible, so that the infrastructure can accept a variety of types of submissions (e.g. code, data, model weights, etc), run them with arbitrary environments designed by the organizers, and run them with the right hardware to get the job done. These are just a few of the major challenges that we’ve tried to address with frx-challenges, and we’re excited to see how it goes with our first assisted community challenge: the Cellmap Challenge.\nIf you’re interested in learning more or participating in this project, follow along at its GitHub repository:\n2i2c-org/frx-challenges\nThis is still the very early stages of the project, and we imagine it will evolve significantly. …","date":1733443200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1733443200,"objectID":"3d52a89e4f97da3cec2101bf57a82bf9","permalink":"https://2i2c.org/blog/2024/frx/","publishdate":"2024-12-06T00:00:00Z","relpermalink":"/blog/2024/frx/","section":"blog","summary":"2i2c is pleased to announce the frx-challenges project, a new open source tool to help communities host data challenges on shared infrastructure:\n2i2c-org/frx-challenges\nThis project aims to make it easier for administrators to provide a service that enables users to submit code and data that are evaluated on secure infrastructure with access to private data and resources.","tags":["open source"],"title":"`frx-challenges`: A new tool to host data challenges for Frictionless Research Exchanges","type":"blog"},{"authors":["Yuvi Panda"],"categories":["impact"],"content":"On most research oriented JupyterHub installations, users would like to customize their server (the environment, resources available, etc) after logging in. In Kubernetes based JupyterHub environments, a profile list provides this functionality.\n(Profile List for the NASA VEDA JupyterHub with the default implementation from KubeSpawner)\nThe profile list is the de-facto “logged in homepage” for these users, as that is what they see after they have logged in.\nIn collaboration with Development Seed, funded by our earlier grant from GESIS as well as the NASA VEDA project, we have been building the jupyterhub-fancy-profiles project to improve this experience.\n(Profile List for the NASA VEDA JupyterHub with jupyterhub-fancy-profiles)\nLast week, we rolled this new experience out to all 2i2c managed JupyterHubs! Here’s a quick rundown of what this enables:\nDescriptions for choices in the dropdowns, making it much easier for users to know what they are getting with each environment (or resource selection).\nFully backwards compatible with the existing KubeSpawner profile list implementation. In our PR to roll this out to all hubs, you notice that we didn’t have to change the structure of any profile lists! So you can safely roll this out to your hubs too without needing to fundamentally change how your profiles are set up.\nIt is a modern web app (built with react), just like the JupyterHub admin panel. This allows us to evolve and satisfy user needs much faster, as well as expanding the pool of people who can contribute to the project!\nSupport for dynamically building images using mybinder.org style repositories! It talks to the binderhub API so users can build reproducible environments as they wish without admin involvement nor needing to fully understand how docker and containers work. Our earlier blog post has more information.\nThis is just the start, and thanks to ongoing funding from the NASA VEDA project, we are going to continue making improvements to this experience.\nUse this in your JupyterHub # As with everything we build at 2i2c (per our right to replicate policy), this project can be used with any JupyterHub installation that uses Kubernetes. There are instructions in the README. Please try it out on yours and let us know what you think!\nCredit # The project was initiated with funding generously provided by GESIS in cooperation with NFDI4DS (project number: 460234259) and CESSDA (see our earlier blog post). Sanjay Bhangar and Oliver Roick from Development Seed for advocating for this project and contributing heavily to it. The NASA VEDA project (in particular, Brian Freitag and Alex Mandel), for continued funding (in the form of engineering time) plus being early adopters! ","date":1731963320,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1731963320,"objectID":"07217fe669e83cba87714f028d2f8744","permalink":"https://2i2c.org/blog/2024/jupyterhub-fancy-profiles-rollout/","publishdate":"2024-11-18T12:55:20-08:00","relpermalink":"/blog/2024/jupyterhub-fancy-profiles-rollout/","section":"blog","summary":"On most research oriented JupyterHub installations, users would like to customize their server (the environment, resources available, etc) after logging in. In Kubernetes based JupyterHub environments, a profile list provides this functionality.","tags":["jupyterhub","open source"],"title":"Improving the logged in home page experience in JupyterHub with `jupyterhub-fancy-profiles`","type":"blog"},{"authors":["Jenny Wong"],"categories":[],"content":"Cross-posted from the Jupyter Book blog. Note that some MyST functionality is not supported on the 2i2c website – please see the original post for previews.\nOver the last ten months, the Jupyter Book team have been hard at work; Jupyter Book has become a Jupyter subproject, and the team1 announced a plan to release Jupyter Book 2. This post announces the alpha release of Jupyter Book 2.0, which has been re-written from the ground up to use the new MyST-MD engine.\nOver the next few months, we will work in preparation for the full release of Jupyter Book 2. Stay tuned for more! The initial documentation for the alpha release can be found at:\nnext.jupyterbook.org/\nInstall the Jupyter Book 2 Alpha # The Jupyter Book 2 alpha is available from PyPI.org. You can install it with pip, using\npip install -U jupyter-book==2.0.0a0 If you use pipx, it’s recommened to run Jupyter Book 2 using\npipx run jupyter-book==2.0.0a0 Jupyter Book 2 needs Node.js installed on your computer. If this is not the case, running jupyter book will prompt you to install it using the nodeenv package that ships with Jupyter Book 2:\n❗ Node.js (node) is required to run Jupyter Book, but could not be found`. ❔ Install Node.js in \u0026#39;...\u0026#39;? (y/N): Press y and Enter to proceed.\nThe Jupyter Book 2 project is a complete re-write of Jupyter Book. We expect there to be bugs and breakages! Please use our support channels to keep us up to date with your findings!\nDiscord\nGitHub Issues\nNew Features in 2.0 alpha # Rich Hover Previews # The new MyST book and article themes provide useful hover previews for links to other MyST content, Wikipedia, GitHub issues, and many more.\nShare \u0026amp; Embed Content # Content from other websites built with the MyST engine can be embedded in your own sites and PDFs:\nCross-referenced content can easily be embedded and re-captioned into other pages and projects, such as this figure to mystmd.org/guide/embed#mylabel. Simple Instant Search # A new client-side search uses a simple, modern algorithm for fast local search that finds the results that you care about.\nClient-side search uses simple, modern, Algolia-inspired search algorithm to provide useful search results. We will be iterating on this in the near future for even richer search results! High Quality PDFs # PDF documents can now be built with Typst, a high-quality typesetting engine that produces readable error messages and beautiful documents. This feature was the basis for the 2024 SciPy proceedings, which is now built on MyST Markdown and will be accepting Jupyter Notebooks in 2025.\nExample of the LaPreprint Typst template for rendering PDFs from Jupyter Book (via the MyST Engine). Coming Soon in 2.0 beta # Custom Styles \u0026amp; Scrips # Jupyter Book 2 will make it easy to tweak your website styles, and add new website behaviors.\nGenerate Markdown from Code Cells # The MyST engine is on-track to support the inclusion of references and other markup features generated by code cells.\nControl Cell Visibility with Tags # In the beta release, Jupyter Book 2 will once-again be able to show and hide content according to cell tags.\nJupyter Book 2 vs MyST-MD # At this early stage, the new Jupyter Book application jupyter book behaves identically to the mystmd engine that it is built upon; as outlined in our Jupyter Book 2 plan, we intend for Jupyter Book to be an “opinionated distribution” of mystmd that shares the same configuration format and CLI. This contrasts with Jupyter Book 1, which was built on top of the Sphinx documentation engine, but offered its own CLI and configuration files. In future, the jupyter book and mystmd CLIs may diverge from one another, but we expect that this will be handled in a graceful manner: mystmd commands should always be compatible with the jupyter book application.\nJupyter Book project has historically been a technical project of the Executable Books organisation. In 2024, the establishment of a Jupyter subproject means that the Jupyter Book project now has its own identity outside of Executable Books. ↩︎\n","date":1731888e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1731888e3,"objectID":"6821097787d4ca65f10ec80fb36d1cb6","permalink":"https://2i2c.org/blog/2024/jupyter-book-2/","publishdate":"2024-11-18T00:00:00Z","relpermalink":"/blog/2024/jupyter-book-2/","section":"blog","summary":"Cross-posted from the Jupyter Book blog. Note that some MyST functionality is not supported on the 2i2c website – please see the original post for previews.\nOver the last ten months, the Jupyter Book team have been hard at work; Jupyter Book has become a Jupyter subproject, and the team1 announced a plan to release Jupyter Book 2.","tags":["open-source"],"title":"Announcing the Jupyter Book 2 alpha","type":"blog"},{"authors":["Jenny Wong"],"categories":["organization"],"content":" Grafana dashboard showing cloud costs broken down by compute, storage and other components for the Openscapes hub. We are pleased to unveil a new feature to track cloud costs within our Grafana dashboards! Community Champions now have the ability to monitor the cost and usage of their 2i2c-managed hubs that displays up to date aggregated costs as well as detailed breakdowns for more granular reports.\nNote that this feature is currently available to AWS hosted hubs only and will be rolled out to other cloud providers in the future. Accessing the cloud cost dashboard # Community Champions can view the Cloud Cost dashboard from their Grafana instance (please see the Service Guide for how to gain access).\nFrom the main menu of Grafana, navigate to Dashboards \u0026gt; Cloud cost dashboards \u0026gt; Cloud cost attribution to view the dashboard.\nUnderstanding the cloud cost dashboard # A typical 2i2c-managed deployment comprises of a staging hub and a production hub, although some other communities may have extra hubs such as a workshop hub. By default, costs are not broken down on a per hub basis unless the community has opted in to this feature.\nThe dashboard is made of several panels:\nDaily costs Daily costs per hub (opt-in only) Total daily costs per component Daily costs per component per hub (opt-in only). For more detailed information on the data that each panel displays, please consult our Service Guide for reference.\nSharing cost reports # The dashboard can be shared with other community members and stakeholders so they can understand usage and cost patterns. Community Champions can export data to a CSV file, or they can generate a snapshot of the Grafana dashboard and share a public link.\nFor instructions on how to export data from the dashboard, please see our Service Guide for reference.\nNext steps # We would love to know whether this feature is useful and how it can be improved. We will be contacting individual communities to share their feedback with us – please share your thoughts with us!\nWe will work on rolling out this service to GCP hosted clusters in future. Stay tuned to know when this feature is available to your community.\nAcknowledgements # Thank you to Erik for spearheading the rollout effort and to the rest of the 2i2c team for their support. We are especially grateful to the Openscapes and Cryocloud communities for providing valuable insights during the prototyping and testing phase.\n","date":1731628800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1731628800,"objectID":"0c9f774a118cb1c8715e2929b9f186e2","permalink":"https://2i2c.org/blog/2024/aws-cost-attribution/","publishdate":"2024-11-15T00:00:00Z","relpermalink":"/blog/2024/aws-cost-attribution/","section":"blog","summary":"Grafana dashboard showing cloud costs broken down by compute, storage and other components for the Openscapes hub. We are pleased to unveil a new feature to track cloud costs within our Grafana dashboards!","tags":[],"title":"Track and manage cloud costs using Grafana","type":"blog"},{"authors":["Jenny Wong"],"categories":["impact"],"content":"Cross-posted from the Catalyst Project blog\nCatalyst Project community partners using accessible cloud infrastructure for open science leadership and training. (clockwise from top-left) NNB-CCG, MUST, CICADA and INER. Photos courtesy of Shirley Alquicira Hernández, Bennett Kankuzi, María Inés Fariello Rico and Yalbi I. Balderas-Martinez. The Catalyst Project is a community-engaged initiative designed to support the adoption of open science principles in under-served bioscientific research communities through the provision of reliable and sustainable cloud computing infrastructure. It’s a project we’ve been working on now for almost two years, which involves staff from seven different organizations: 2i2c, The Carpentries, CCAD, CSCCE, IOI, MetaDocencia, and OLS, and is funded by the Chan Zuckerberg Initiative.\nA key part of the project is engaging with Community Partners in Africa and Latin America: Institutions, organizations, and individuals who are undertaking bioscientific research projects that require cloud computing infrastructure. As collaborators on the Catalyst Project, Community Partners can access and use 2i2c’s open science cloud services, and also receive training from 2i2c, The Carpentries, MetaDocencia, and OLS to support their work. Community Partners also play a vital role in shaping an evolving governance model for the Catalyst Project to help sustain, scale, and maximize impact in Latin America, Africa, and under-served communities around the world.\nIn a new collection of blog posts (that we hope will expand over the next couple of months!) we’re highlighting the work of the Catalyst Project Community Partners. This post is a gateway to learning more about the Catalyst Project and its Community Partners. If you have any questions or feedback about the project, please send an email to the core team.\nHighlighting the Catalyst Project Community Partners # The Catalyst Project currently involves 19 Community Partners, 9 in Africa and 10 in Latin America. Our initial blog post series showcases seven of the Partners, and each post is available in English and Spanish:\nAfrican Institute of Biomedical Science and Technology (AiBST) # At the African Institute of Biomedical Sciences and Technology (AiBST) in Zimbabwe, Zedias Chikwambi and colleagues are working to discover and utilise biomarkers to guide personalized medical treatment.\n“Through the Catalyst Project we are able to bring genomic information interpretation to patient bedsides.” - Zedias Chikwambi\nRead more: EN | ES\nMalawi University of Science and Technology (MUST) # The Catalyst Project Community at the Malawi University of Science and Technology (MUST) is working to popularize the applicability of data science and artificial intelligence in various undergraduate and postgraduate research contexts in Malawi, including health, business, and education.\n“…many staff and students need… a robust and easily accessible platform from which they can efficiently run their machine learning models and do advanced data analysis for their data science research…” - Bennett Kankuzi\nRead more: EN | ES\nMolerHealth # MolerHealth is focused on revolutionizing healthcare in Nigeria by developing an accessible electronic health record (EHR) system aimed at reducing disease misdiagnosis.\n“Access to training, like The Carpentries Instructor Training, has empowered our team with essential skills for effective teaching and collaboration.” - Monsurat Onabajo\nRead more: EN | ES\nNelson Mandela African Institution of Science and Technology (NM-AIST) # The Northern Tanzania One Health Research Group, hosted at the Nelson Mandela African Institution of Science and Technology (NM-AIST), is using the Catalyst Cloud Infrastructure to understand the transmission dynamics, genetic diversity, and antimicrobial resistance of the Mycobacterium tuberculosis complex (Mtb) between humans and livestock in Northern Tanzania.\n“…access to training, particularly through the 2i2c Hub Champion Training, has significantly enhanced our ability to manage and optimize cloud-based resources.\u0026#34; - Beatus M Lyimo\nRead more: EN | ES\nNodo Nacional de Bioinformática (NNB-CCG) # The Nodo Nacional de Bioinformática (NNB-CCG) of the Centro de Ciencias Genómicas (CCG) - Universidad Nacional Autónoma de México (UNAM) is a group that brings together professionals and academics to support, provide services, and maintain the growth of the field of bioinformatics in the country’s research.\n“(Our) goal is to optimize our participation in events, assess the usefulness of the Catalyst Project’s resources, and, in turn, provide the Catalyst Project with guidelines to improve their service by identifying the necessary areas for improvement within the institutions.\u0026#34; - Shirley Alquicira Hernández\nRead more: EN | ES\nInstituto Nacional de Enfermedades Respiratorias (INER) # Collaborators at INER are using the Catalyst Cloud Infrastructure to implement machine learning algorithms that will classify radiology …","date":1730332800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1730332800,"objectID":"743fbf80a517e2a91d4036551ee4f3f6","permalink":"https://2i2c.org/blog/2024/catalyst-partner-highlights/","publishdate":"2024-10-31T00:00:00Z","relpermalink":"/blog/2024/catalyst-partner-highlights/","section":"blog","summary":"Cross-posted from the Catalyst Project blog\nCatalyst Project community partners using accessible cloud infrastructure for open science leadership and training. (clockwise from top-left) NNB-CCG, MUST, CICADA and INER. Photos courtesy of Shirley Alquicira Hernández, Bennett Kankuzi, María Inés Fariello Rico and Yalbi I.","tags":["bioscience"],"title":"Introducing the Catalyst Project Community Partner Highlights","type":"blog"},{"authors":["Chris Holdgraf"],"categories":["organization"],"content":"We are proud to announce that 2i2c has received financial support from The Chan Zuckerberg Initiative to sustain our efforts at helping open science communities create and share knowledge with open infrastructure.\nFunding comes from the Open Science Program at CZI, which aims to ‘…support a diverse scientific community working in the open to accelerate our understanding of human health and disease. We invest in tools, platforms, and organizations that help expand participation and access to the scientific process by making it open and reproducible, and helping scientists build on each others’ work.’ This builds upon previous core support provided by CZI, and provides an additional ~$700K over 1 year to help 2i2c sustain its mission. We are deeply grateful to CZI for their support, and this funding provides key runway for 2i2c to serve its community network and explore a sustainable and scalable model for impact.\n","date":1728777600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1728777600,"objectID":"b3baf5ca0ac2a5d7b3e8a6cf8a1177f1","permalink":"https://2i2c.org/blog/2024/funding-czi/","publishdate":"2024-10-13T00:00:00Z","relpermalink":"/blog/2024/funding-czi/","section":"blog","summary":"We are proud to announce that 2i2c has received financial support from The Chan Zuckerberg Initiative to sustain our efforts at helping open science communities create and share knowledge with open infrastructure.","tags":["funding"],"title":"Support from CZI to sustain 2i2c's mission to help communities create and share knowledge with open infrastructure","type":"blog"},{"authors":null,"categories":["impact"],"content":"","date":1727740800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1727740800,"objectID":"03c0b188c2e2f3b058aa392d00e279df","permalink":"https://2i2c.org/blog/2024/external-earthscope-pancakes/","publishdate":"2024-10-01T00:00:00Z","relpermalink":"/blog/2024/external-earthscope-pancakes/","section":"blog","summary":"","tags":["geoscience"],"title":"Pancakes are the future of geophysical data processing","type":"blog"},{"authors":null,"categories":["impact"],"content":"","date":1727049600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1727049600,"objectID":"2b1bf35dba4e0aa40855e26bfe8515c8","permalink":"https://2i2c.org/blog/2024/external-openscapes-whitehouse/","publishdate":"2024-09-23T00:00:00Z","relpermalink":"/blog/2024/external-openscapes-whitehouse/","section":"blog","summary":"","tags":["open source"],"title":"Openscapes goes to the White House!","type":"blog"},{"authors":null,"categories":["impact"],"content":"","date":1725408e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1725408e3,"objectID":"d18ec00ade1f18360c10c044ccbdc795","permalink":"https://2i2c.org/blog/2024/external-hub-champion-training/","publishdate":"2024-09-04T00:00:00Z","relpermalink":"/blog/2024/external-hub-champion-training/","section":"blog","summary":"","tags":["bioscience"],"title":"Hub Champion Training Reflections (English)","type":"blog"},{"authors":null,"categories":["impact"],"content":"","date":1725408e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1725408e3,"objectID":"73ca37026d8bd99de38273b747a6456f","permalink":"https://2i2c.org/blog/2024/external-hub-champion-training-es/","publishdate":"2024-09-04T00:00:00Z","relpermalink":"/blog/2024/external-hub-champion-training-es/","section":"blog","summary":"","tags":["bioscience"],"title":"Reflexiones sobre la formación de Campeones y Campeonas del Hub (Español)","type":"blog"},{"authors":["Jenny Wong","Angus Hollands","Chris Holdgraf"],"categories":["impact"],"content":" The DeepLabCut Team # Animal pose estimation using deep neural networks. Courtesy of the DeepLabCut Jupyter Book The DeepLabCut team is a group of researchers and developers who are working on open source tools for analyzing animal pose estimation by training deep neural networks on videos.\nChris Holdgraf visited the lab in early August to learn more about how the group were using open-source tools to document and share their work.\nJupyter Book and MyST # Extensive documentation for using the DeepLabCut software package is already available as a Jupyter Book. The group was interested in adopting MyST Markdown to stay ahead of the curve and upgrade their Jupyter Book (see the related announcement Jupyter Book 2 will be build upon the MyST-MD engine).\nChris led a mini-hackathon to introduce the group to MyST and collect feedback on where enhancement features could be made in the future. Here’s a summary of the outcomes:\nMany improvements were made to the MyST documentation 📖 The MyST Quick Start Guide was used to onboard new users. Amendments were upstreamed to the MyST docs directly and were immediately available to all. A tutorial on executable documents was added to the collection of MyST tutorials. MyST-MD installation instructions were simplified using mamba. A bunch of enhancement features were requested ✨ Using cell tags for labelling notebook cells Support for loading user-defined CSS stylesheets for theming Better UX for multi-versioned documentation Bibliography styling in HTML Automatic API documentation generation And we found a bug in the table of contents validation 🐞 Summary # Hackathons are a great way for quickly imparting knowledge and gathering feedback in a short space of time. The event spurred rapid contributions to the MyST ecosystem – embracing reuse of the MyST quick start guides saved time and effort, while engaging with users directly closed a tight feedback loop for enhancements.\nAcknowledgments # We would like to thank the Mackenzie Mathis Lab for hosting Chris Holdgraf at EPFL, Lausanne, Switzerland.\n","date":1725235200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1725235200,"objectID":"df907eb143f38925fbab59062d00583a","permalink":"https://2i2c.org/blog/2024/deeplabcut-myst-hackathon/","publishdate":"2024-09-02T00:00:00Z","relpermalink":"/blog/2024/deeplabcut-myst-hackathon/","section":"blog","summary":"The DeepLabCut Team # Animal pose estimation using deep neural networks. Courtesy of the DeepLabCut Jupyter Book The DeepLabCut team is a group of researchers and developers who are working on open source tools for analyzing animal pose estimation by training deep neural networks on videos.","tags":["bioscience","open source"],"title":"MyST Mini-Hackathon with the DeepLabCut Team","type":"blog"},{"authors":["Ariel Rokem","Noah Benson","Jenny Wong"],"categories":["impact"],"content":"Thank you to Ariel Rokem and Noah Benson for guest writing this blog post!\nGroup photo from NeuroHackademy 2024 What is NeuroHackademy? # Part summer school, part free-wheeling hackathon, all focused on the use of data science methods in neuroscience, NeuroHackademy is an event that was recently hosted by the University of Washington eScience Institute in Seattle, WA, USA. This event, that has been running annually since 2016, aims to provide early-career researchers in Psychology, Medicine, Neuroscience, and other related fields with the skills and knowledge that they need to effectively and rigorously work with open source tools and workflows for analyzing human neuroscience data. This supports the effort to make scientific analysis and results shareable, reproducible, and accessible.\nGlobal and inclusive # In 2020, the event had to rapidly pivot to an online format, and this format was also used in 2021. Through this experience, the organizers ( Ariel Rokem and Noah Benson) realized that many participants preferred the online format. For example, participants who could not afford to travel to Seattle, or participants who had care-taking responsibilities that precluded them from participating in a two-week event away from their homes. In 2022, the event pioneered a hybrid format, where half of the participants are present in-person and half join the event via zoom, slack, GitHub, and of course through a dedicated 2i2c JupyterHub. Taken together, this format allows the participation of students from a larger range of backgrounds and locations. This aspect plays an important part in building a global and inclusive community of practice. See the paper Hands-On Neuroinformatics Education at the Crossroads of Online and In-Person: Lessons Learned from NeuroHackademy to read more on this subject.\nCollaboration with 2i2c # Previous years # NeuroHackademy has been an early adopter of the cloud-based JupyterHub model, setting up its first hub using the zero-to-jupyterhub guide in 2018. NeuroHackademy partnered with 2i2c as soon as it was founded, and 2i2c has operated a JupyterHub for the last 3 years. The hub provides an interactive computing platform for learners, and implements the “digital watering hole” for practical and immediate access to a range of cloud-based datasets in human neuroscience (see blog post announcing support for this year’s event).\nIn terms of the software environment, the following tools and features that have benefited the event over the years include\nnbgitpuller allows students to synchronise lesson content with an organizational GitHub repository that is collaboratively maintained by the lesson instructors. Shared data file storage with read-only access for learners and read-write access for instructors Access to an abundance of neuroimaging data hosted in cloud object storage The Human Connectome Project The Natural Scenes Dataset OpenNeuro The Healthy Brain Network And more. This year # This year 2i2c supported the following tools and features for NeuroHackademy\nA “Bring your own image” option where users can pull any image hosted on a container registry into the hub. See our Integrating BinderHub with JupyterHub: Empowering users to manage their own environments blog post for more details. repo2docker and GitHub actions to build and prototype images from a repository. The support services provided by 2i2c and the ability for instructors to open pull requests on 2i2c infrastructure for speedy resolution. GPU instances to support more compute intensive workloads for machine learning. Next year # One thing we have learned is that 2i2c automatically shuts down a user server after one hour of inactivity by default to ensure efficient resource usage and limit runaway cloud costs. Naturally, we are seeing increasing demand from learners for longer and more complex analyses. In response to this, we are keen to explore how the jupyter-keepalive extension can keep the server alive for long-running processes.\nWe are pleased that learners have made great progress in making use of cloud-native, open-source workflows for analyzing human neuroscience data. We are keen to benefit from lessons learned this year and are looking forward to collaborating with 2i2c once again to deliver the NeuroHackademy Summer School in 2025.\nWatch this space next year!\nAcknowledgements # Funded by grant R25MH112480 from the US National Institute of Mental Health awarded to Ariel Rokem and Noah Benson.\nThe NeuroHackademy Summer School is sponsored by\nUniversity of Washington eScience Institute Gordon and Betty Moore Foundation Alfred P. Sloan Foundation University of Washington The University of Texas at Austin National Institute of Mental Health National Science Foundation. References # NeuroHackademy2024 GitHub Organization Hands-On Neuroinformatics Education at the Crossroads of Online and In-Person: Lessons Learned from NeuroHackademy ","date":1724025600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1724025600,"objectID":"54f59ba8de07c17eb44a7df2ea4ffdc3","permalink":"https://2i2c.org/blog/2024/neurohackademy-summer-school-reflections/","publishdate":"2024-08-19T00:00:00Z","relpermalink":"/blog/2024/neurohackademy-summer-school-reflections/","section":"blog","summary":"Thank you to Ariel Rokem and Noah Benson for guest writing this blog post!\nGroup photo from NeuroHackademy 2024 What is NeuroHackademy? # Part summer school, part free-wheeling hackathon, all focused on the use of data science methods in neuroscience, NeuroHackademy is an event that was recently hosted by the University of Washington eScience Institute in Seattle, WA, USA.","tags":["bioscience","education"],"title":"NeuroHackademy Summer School Reflections","type":"blog"},{"authors":["Jenny Wong"],"categories":["impact"],"content":" (left, b\u0026amp;w) Model inputs and (right, color) model outputs of a simple multi-layer perceptron for detecting cloud cover. PACE is the NASA Plankton, Aerosol, Cloud, ocean Ecosystem mission that focuses on understanding ocean health and its impact on the atmosphere. Together with the Ocean Carbon and Biochemistry (OCB) program, a one-week hackathon ran from Aug 4 to Aug 8 on the 2i2c-hosted CryoCloud hub. The goal of the hackathon was to explore new Earth science data streams provided by the OCI, SPEXone and HARP2 instruments using Python.\nMachine Learning with GPUs # One of the most advanced tutorials delivered during the hackathon was the Machine Learning Tutorial. The tutorial focused on creating a machine learning pipeline to detect cloud cover from satellite imagery. This was done by training a convolutional neural network (CNN) to assign each pixel a binary value to indicate whether the location was covered by cloud or not. To improve the spatial context beyond a single pixel value, as the likelihood of a pixel containing cloud cover increases if its neighbours also contain cloud cover, the CNN needs to be trained on the entire image at once rather than at a single pixel level. This massively increases the training time, but also allows the CNN to learn more complex relationships between pixels.\nGPUs have a far greater number of cores than CPUs that are well-suited for accelerating the massive parallel processing needed to train a neural network on the large amounts of image data in the above scenario. PyTorch is a popular Python library for training CNNs, available for both CPUs and GPUs, and is an ideal tool for performing this kind of work. In terms of the accelerator hardware available on the CryoCloud hub, 2i2c provisions an instance with an NVIDIA Tesla T4 GPU with 4 CPUS, 16GB of RAM and 2,560 CUDA cores.\nManaging shared memory on 2i2c hubs # While developing the above tutorial, tutorial lead Sean Foley (NASA/GSFC/SED \u0026amp; Morgan State University \u0026amp; GESTAR II) noticed that training neural networks was way slower than it should be given the GPUs available to them. They investigated the issue, and with help from the 2i2c engineering team, it was determined that shared memory was the issue. PyTorch uses shared memory via /dev/shm for faster parallel processing, and maximizing use of GPU. However in containerized environments, this is limited to a maximum of 64MB by default.\nYou can check the amount of shared memory available on your hub in a terminal with the command\ndf -h | grep /dev/shm\nAs you might expect, 64 MB of shared memory is not enough for training over 160,000 images in the tutorial. 2i2c was able to remove the limit, making /dev/shm share the memory the user has selected via their profile list, rather than be artificially limited to any particular size. This was done for all users on the CryoCloud hub within an hour of the issue being reported and we upstreamed the change for all 2i2c hubs (see GitHub pull requests for CryoCloud and all 2i2c hubs).\nConclusion # This event demonstrates the economy of how running shared and open infrastructure dynamically solves problems for the benefit of many users, not just for one occasion. Learning experiences such as the above are transferred and embedded upstream into transparent and flexible open source software that impacts not only all users of 2i2c operated hubs, but also generalized for the wider research community at large (case in point, see the Slack thread below from Eli Holmes, operator of the NOAA Fisheries hubs)! We are grateful for the strong partnerships with our communities who help us to co-design impactful solutions that are specific for their needs and accessible to all.\nThe power of open infrastructure beyond 2i2c-operated hubs References and Acknowledgments # Sean Foley (NASA/GSFC/SED \u0026amp; Morgan State University \u0026amp; GESTAR II) Tasha Snow (ESSIC UMD \u0026amp; NASA GSFC \u0026amp; CryoCloud) PACE Hackweek Jupyter Book ","date":1723420800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1723420800,"objectID":"70ef9ea274f3dc7b8c0b0d70d80df4b0","permalink":"https://2i2c.org/blog/2024/pace-hackweek/","publishdate":"2024-08-12T00:00:00Z","relpermalink":"/blog/2024/pace-hackweek/","section":"blog","summary":"(left, b\u0026w) Model inputs and (right, color) model outputs of a simple multi-layer perceptron for detecting cloud cover. PACE is the NASA Plankton, Aerosol, Cloud, ocean Ecosystem mission that focuses on understanding ocean health and its impact on the atmosphere.","tags":["geoscience","education"],"title":"Keeping PACE with GPU enabled compute to detect global cloud cover using satellite data","type":"blog"},{"authors":["James Munroe, Jenny Wong"],"categories":["impact"],"content":" AmeriGEO provides a framework for cooperation in the Americas for the use of Earth data to benefit science and society with data driven decision-making. As part of a virtual workshop held on 1st August 2024, 2i2c provided an interactive computing environment to support the delivery of a NASA TOPST water module.\nThe workshop was facilitated by Kytt MacManus and Juan F. Martinez (both of CIESIN, Columbia University, New York). Juan presented interactive R code, with explanatory content written in Quarto, for hotspot vulnerability analysis for floods and landslides focused on Ecuador using earth observation data and socioeconomic data to develop an index of vulnerability. Check out their GitHub repo and explore interactively yourself on our BinderHub (see our blog post for more details of how to access the BinderHub deployments to provide Ephemeral Interactive Computing for NASA Communities).\nOver 100 participants were able to access the interactive workshop on our infrastructure, with 8 GB of RAM per user to facilitate the processing of large amounts of earth data. We are pleased that the workshop was successful and the platform was able to provide a great experience for participants. After the workshop, Kytt reported that\nThe technology worked as expected and we didn’t run into 1 major technical problem. Thank you so much for that!\u0026#34;.\nAcknowledgements # Funding from Science Mission Directorate’s Open Source Science Initiative, Research Opportunities in Space and Earth Science (ROSES-2022), F.14 Transform to Open Science NASA NSPIRES F.15 High Priority Open-Source Science Award NNH22ZDA001N-HPOSS NASA Socioeconomic Data and Applications Center (SEDAC) Kytt MacManus Juan F. Martinez James Munroe for providing support and assistance for setting up the cyberinfrastructure for this workshop. ","date":1722816e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1722816e3,"objectID":"92ca486d311f63c792bddbdfcade5a35","permalink":"https://2i2c.org/blog/2024/amerigeo-workshop/","publishdate":"2024-08-05T00:00:00Z","relpermalink":"/blog/2024/amerigeo-workshop/","section":"blog","summary":"AmeriGEO provides a framework for cooperation in the Americas for the use of Earth data to benefit science and society with data driven decision-making. As part of a virtual workshop held on 1st August 2024, 2i2c provided an interactive computing environment to support the delivery of a NASA TOPST water module.","tags":["geoscience","education"],"title":"Ephemeral Interactive Computing for the AmeriGEO Workshop","type":"blog"},{"authors":["Yuvi Panda","Jenny Wong"],"categories":["impact"],"content":"Thank you to Sajjad Anwar and Sanjay Bhangar for contributing to this post.\nThe VEDA dashboard The 2i2c team are proud to continue our strong working collaboration with Development Seed, following our previous work on launching the US GHG center (also see the Development Seed blog post). Together with scientists at NASA in our regular sync touchpoints, we have recently delivered a tranche of improvements to the Visualization, Exploration and Data Analysis (VEDA) project.\nThis platform is designed to thread open-source components together to consolidate GIS delivery mechanisms, processing, analysis and visualization tools, and presented in a collaborative interactive computing environment. All code repositories and associated resources stemming from this work are available on the VEDA GitHub page.\nIn the spirit of fully open development, you can see the objectives the combined 2i2c and Development Seed team had for the last quarter. In this blog post, we will describe some of the significant ones!\nBetter image management and testing # The repo2docker-action is a GitHub action simplifying image building and testing for use with JupyterHub, using either a Dockerfile or various configuration files (like requirements.txt, environment.yml, etc) supported by repo2docker. We migrated our image building pipeline from a somewhat homegrown solution to this upstream action, making image updates and testing much easier. In particular, we can automatically run test notebooks on every change we make to the image! This way, we can easily catch any breaking changes in library versions or other package installs without disrupting users. We also debugged and contributed upstream fixes to the testing infrastructure so everyone could benefit from this, rather than just us.\nAutomatically pulling example notebooks on startup # When a user logs into a JupyterHub, it is very helpful if we could have a bunch of example notebooks and other content pre-populated for them so they can get started right away. nbgitpuller is heavily used for this particular use case. However, it requires that nbgitpuller is installed inside the image the user is using - and not all images have it installed. In particular, we wanted to continue using the (wonderful) Rocker images maintained upstream for R users, however they do not have nbgitpuller installed. To solve this problem we built jupyterhub-gitpuller-init, which can be used as an init container to pre-populate user content on persistent home directories regardless of the image used. We also made sure to build this in a way that anyone can use it, and it is not tied into either 2i2c or VEDA infrastructure!\nOpening specific visualizations in QGIS via URL # QGIS is the world’s most used open source GIS software, and previously 2i2c had worked with Openscapes and QGreenland to bring this desktop software to JupyterHub. We had previously worked on a container image that allows users to access large datasets stored in the cloud directly through QGIS on the JupyterHub, allowing users to work with much larger datasets than they could on their desktops by bringing cloud compute adjacent to the data. As a continuation of this work, we developed jupyter-remote-qgis-proxy, which builds QGIS specific features on top of jupyter-remote-desktop-proxy. In particular, it allows creation of shareable links that when clicked, opens specific datasets and layers in QGIS in a JupyterHub! You can see this in action:\nLaunching QGIS on a Linux desktop served by the VEDA JupyterHub This opens up exciting future possibilities. Imagine this exploration of the Camp Fire having an ‘Open in QGIS’ button that enables further exploration of the data without the user needing to download or install anything! Work will continue in the coming quarter towards achieving this vision.\nWe are also excited to see recent work in this space from QuantStack and Simula Labs, and will follow up to ensure an orderly transition to more web native workflows for existing users of QGIS in due time.\nBetter Profile Selection # This is a continuation of our GESIS collaboration. In the path to deploying dynamic image building to end users, we wanted to stabilize jupyterhub-fancy-profiles enough to deploy to users of VEDA (and eventually everyone else). This is the primary interface users see after they log in to JupyterHub, and was ripe for UX improvements. The default interface looks like this:\nThe revamped one is much more streamlined and looks like this:\nRevamped Profile Screen This is currently deployed to a staging hub and has helped us shake out a lot of bugs! We expect the improved interface will be rolled out to all users in the near future. We are also planning further development to make the user experience even better and smoother for everyone.\nSupporting workshops # End users benefiting from our work is what ultimately gives meaning to our work. To that end, we were very happy to support running workshops during this collaboration – see our …","date":1720742400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1720742400,"objectID":"64548987dab9cdd06ec27525262df080","permalink":"https://2i2c.org/blog/2024/veda-devseed-collab/","publishdate":"2024-07-12T00:00:00Z","relpermalink":"/blog/2024/veda-devseed-collab/","section":"blog","summary":"Thank you to Sajjad Anwar and Sanjay Bhangar for contributing to this post.\nThe VEDA dashboard The 2i2c team are proud to continue our strong working collaboration with Development Seed, following our previous work on launching the US GHG center (also see the Development Seed blog post).","tags":["geoscience","open source"],"title":"Collaborating with Development Seed to deliver cyberinfrastructure for NASA VEDA","type":"blog"},{"authors":["Yuvi Panda","Jenny Wong"],"categories":["impact","updates","partnerships"],"content":"Thanks to Brianna Lind, Julia Lowndes and Andy Teucher for contributing to this blog post!\nSurface Biology and Geology: VITALS Workshop Openscapes is a value-based initiative that supports kinder, better science based on open source community. NASA Openscapes is in its fourth year as a project supporting NASA Earth science in the Cloud, co-developed by Julia Lowndes (Openscapes) and Erin Robinson (Metadata Game Changers).\nThe initiative recently supported the Surface Biology and Geology: VITALS Workshop hosted by NASA Land Processes Distributed Activate Archive Center (LP DAAC) and NASA Jet Propulsion Laboratory (JPL).\nInstructors used the 2i2c Openscapes Hub to lead hands-on exercises teaching learners how to manipulate data collected from the ECOSTRESS and EMIT instruments onboard the International Space Station. They used Jupyter notebooks in the Hub to demonstrate how open source tools together with cloud data and compute resources could effectively analyse the the Canopy Water Content and the Land Surface Temperature over the Jack and Laura Dangermond Preserve, Santa Barbara, CA.\nPlot of the Canopy Water Content over the Jack and Laura Dangermond Preserve, Santa Barbara, CA from a VITALS Workshop Jupyter notebook. This event was attended by around 250 participants. An event of this size therefore requires a frictionless login flow so that organizers could focus on the essential complexity of teaching data analysis rather than the accidental complexity of managing Hub authorization. GitHub authentication is the default option for most 2i2c Hubs for research use cases, but for an educational event of this size this option was not fit for purpose since organizers had to\nRetrieve the GitHub usernames of each participant (assuming everyone was familiar with GitHub!) Manually invite GitHub users to a GitHub organization to authorize access to the Hub (invitations would expire within seven days) Repeat the above two steps last-minute for participants who showed up on the day without preparing Manually remove GitHub users from the GitHub organization if they wanted to revoke access to the Hub after the event. In response to this need, we developed a shared password feature so that workshop organizers can simply hand the share password out to learners for access to the Hub. This bypassed the manual labour of managing GitHub accounts while not adding to the learner’s high cognitive load and improving the participant’s learning experience overall.\nOne of the elements that enabled us to recognize and solve this issue effectively is our close partnership with the Openscapes team. We engage in regular 6-weekly catch-ups where we can learn about user requirements and how we can develop our infrastructure to co-create optimal solutions. Together with our Product Delivery Flow, we were quickly able to architect the shared password solution in time for the workshop.\nFeedback from Brianna Lind (LP DAAC) We have documented the technical infrastructure changes required to enable a shared password for the Hub in our Infrastructure Guide and hope to support many future events with this mechanism!\nAcknowledgements # NASA Openscapes NASA LP DAAC NASA JPL NASA ROSES funding ","date":1720483200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1720483200,"objectID":"2d4ae5911aa0c7ee325f64aa793e677e","permalink":"https://2i2c.org/blog/2024/openscapes-sbg-workshop/","publishdate":"2024-07-09T00:00:00Z","relpermalink":"/blog/2024/openscapes-sbg-workshop/","section":"blog","summary":"Thanks to Brianna Lind, Julia Lowndes and Andy Teucher for contributing to this blog post!\nSurface Biology and Geology: VITALS Workshop Openscapes is a value-based initiative that supports kinder, better science based on open source community.","tags":["geoscience","education"],"title":"Openscapes Host a Surface Biology and Geology Workshop with Shared Password Feature","type":"blog"},{"authors":["Jenny Wong"],"categories":["impact"],"content":"Determining Climate Risks with NASA Earthdata Cloud is a ScienceCore curriculum module that comprises part of NASA’s Open Science and Transform to Open Science (TOPS) initiatives. The aim of this module is to deliver a hands-on experience with “data-proximate computing” in the cloud with NASA Earthdata products with content co-developed with MetaDocencia.\nThis module was delivered as a SciPy tutorial at this year’s conference. 2i2c have been working closely with the organizers to provide the hub infrastructure for the tutorial, including enabling a shared password for easy authentication (see our Openscapes post for more about this feature) and operating a small binder service for participants to view content after the event.\nYou can take a look at the tutorial on the NASA ephemeral hub!\nThe event was well-attended, with 40 learners taking part. Special thanks go to the organizers Dhavide Aruliah, Karthik Venkataramani and Patricia A. Loto for leading the tutorial.\nAcknowledgements # NASA F.14 Transform to Open Science Training award NNH23ZDA001N-TOPST MetaDocencia Dhavide Aruliah Karthik Venkataramani Patricia A. Loto ","date":1720396800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1720396800,"objectID":"cf52acab5b0b07f67ae8e6d6af3de79f","permalink":"https://2i2c.org/blog/2024/climaterisk-scipy-tutorial/","publishdate":"2024-07-08T00:00:00Z","relpermalink":"/blog/2024/climaterisk-scipy-tutorial/","section":"blog","summary":"Determining Climate Risks with NASA Earthdata Cloud is a ScienceCore curriculum module that comprises part of NASA’s Open Science and Transform to Open Science (TOPS) initiatives. The aim of this module is to deliver a hands-on experience with “data-proximate computing” in the cloud with NASA Earthdata products with content co-developed with MetaDocencia.","tags":["geoscience","education"],"title":"Determining Climate Risks with NASA Earthdata Cloud at Scipy 2024","type":"blog"},{"authors":["Yuvi Panda","James Munroe","Jenny Wong"],"categories":["impact"],"content":" The HHMI Spyglass tutorial Spyglass # Spyglass is a framework for reproducible and shareable neuroscience research produced by Loren Frank’s lab at the University of California, San Francisco. Check out our blog post about the release of their preprint to read more about the methods.\nThis post focuses on the complex data storage needed for the project, which can be difficult to set up locally or at scale in the cloud. In particular, the analysis needed a MySQL database for reproducibility. This is a fairly common task across many fields. The aim of 2i2c is to enable researchers to focus on the essential complexity of what they were doing, i.e. the science, without managing the accidental complexity of how to do it – in this case, setting up databases.\nWe describe how you can do this too for your own JupyterHubs. Since 2i2c commits to running our infrastructure in line with open-source values as much as possible, you can also directly see the configuration for the hub referenced in the paper.\nWhat is a “sidecar container”? # The Kubernetes definition of a sidecar container is\nSidecar containers are the secondary containers that run along with the main application container within the same Pod. These containers are used to enhance or to extend the functionality of the primary app container by providing additional services, or functionality such as logging, monitoring, security, or data synchronization, without directly altering the primary application code.\nIn this case, the primary app container is the JupyterLab instance where people are interactively running code and doing science. We want to provide a MySQL database as a sidecar so that each user server gets their own independent MySQL server instance (that is not accessible to anyone else). We can then run code such as\n%%bash mysql -h 127.0.0.1 -u root --password=tutorial \u0026lt; path-to-sql-file-with-data to load data into the database. Note the IP address 127.0.0.1 - the MySQL server is listening on localhost, even though it is not running in the same container! Thanks to the magic of Linux Network Namespaces, the sidecar and main app container can share 127.0.0.1. This allows you to write code that works in the exact same way on a user’s local computers as on the JupyterHub, making transitions and replication easier.\nSetting up sidecars in JupyterHub on Kubernetes # We’re leveraging multiple tools from the open-source ecosystem - JupyterHub, Kubernetes, Linux as well as MySQL itself.\nSince this is a Kubernetes feature, we can pass through config to it. There are two layers here, which are\nsingleuser.extraContainers in z2jh configuration KubeSpawner.extra_containers in KubeSpawner configuration The hub configuration looks like\nsingleuser: extraContainers: - name: mysql image: datajoint/mysql:8.0 # following the spyglass tutorial at https://lorenfranklab.github.io/spyglass/latest/notebooks/00_Setup/#existing-database ports: - name: mysql containerPort: 3306 resources: limits: # Best effort only. No more than 1 CPU, and if mysql uses more than 4G, restart it memory: 4Gi cpu: 1.0 requests: # If we don\u0026#39;t set requests, k8s sets requests == limits! # So we set something tiny memory: 64Mi cpu: 0.01 env: # Configured using the env vars documented in https://lorenfranklab.github.io/spyglass/latest/notebooks/00_Setup/#existing-database - name: MYSQL_ROOT_PASSWORD value: \u0026#34;tutorial\u0026#34; By setting this up, we allow users to insert the code snippet above\n%%bash mysql -h 127.0.0.1 -u root --password=tutorial \u0026lt; path-to-sql-file-with-data into their Jupyter Notebooks, which gives access to their MySQL database in the hub!\nHowever, this configuration does not include permanently store the database itself between hub server sessions. Thanks to a pilot in a prior collaboration with University of Texas, Austin, we do have some documentation on how you can enable that as well!\nAcknowledgements # Howard Hughes Medical Institute National Institute of Mental Health (NIMH), grant number RF1MH130623 kubespawner zero-to-jupyterhub-k8s ","date":1720137600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1720137600,"objectID":"605ce158c1588c91aeabfc41f8bd7aa1","permalink":"https://2i2c.org/blog/2024/hhmi-spyglass-mysql/","publishdate":"2024-07-05T00:00:00Z","relpermalink":"/blog/2024/hhmi-spyglass-mysql/","section":"blog","summary":"The HHMI Spyglass tutorial Spyglass # Spyglass is a framework for reproducible and shareable neuroscience research produced by Loren Frank’s lab at the University of California, San Francisco. Check out our blog post about the release of their preprint to read more about the methods.","tags":["bioscience","open source"],"title":"Enabling neuroscience in the cloud with HHMI Spyglass and MySQL on JupyterHub","type":"blog"},{"authors":["Chris Holdgraf","Jenny Wong"],"categories":["organization"],"content":"As an organization committed to broadening access to interactive computing for global communities, we believe that a team embedded with diverse insights and lived experiences can more effectively advocate for underrepresented voices in our socio-technical partnerships. A diversity of team experiences helps us deliver a service that broadens and empowers participation in open-source science for all communities and leads to more effective teams that make better decisions.\nAs a young and growing organization, we have had mixed success in building diversity within our team. We’ve leaned into the values of our service that build trust and attract a broad coalition of community partners (and potential employees). For example, we’ve used the following pillars in describing our service:\nTransparency – our transparent and participatory model keeps our incentives aligned with community needs. Empowerment – our service gives communities agency to design the service they need, and to manage it without 2i2c if they wish. Partnership – our communities are partners working towards shared impact, not customers to grow revenue. Sustainability – our service should have a self-sustaining model that ensures continuity, growth, and funder independence. We’ve also invested in creating an inclusive organizational culture via documents like our Team Compass and our Code of Conduct1. We’ve experimented with inclusive hiring practices to encourage a diverse pool of applicants for our open positions, such as running open office hours for job postings in the hopes that this would encourage more people to apply who might otherwise have been hesitant (something that often correlates with people from historically marginalized communities).\nThe importance of diverse leadership # However, over the past few months, we have reflected on our organization’s structure and future plans. In particular, we recognize that there is a worrying lack of women in staff leadership roles. This imbalance does not live up to our values of diversity in our team and service.\nWe need to do better.\n2i2c is at a moment of maturation and growth as an organization, kicked off by our organizational audit from 2023 as well as our three-year retrospective. We believe that improving the diversity of leadership throughout the organization is a necessary part of that maturation over the next three years.\nBelow are a few ideas for how we aim to make improvements, and we invite feedback from others who are interested in helping us improve this aspect of our organization.\nWhat we plan to do # Over the next few months, we will work on a long-term DEI strategy in tandem with our sustainability strategy as we work towards scalable and sustainable networks of community hubs.\nHere are some steps we aim to take to improve the diversity of our leadership across the organization:\nDefine our goals for diversity. First, we need a better understanding of the most important axes of diversity that we wish to design around. Gender is clearly a critical gap to cover, but there are many other important axes of diversity as well. For example, as an organization that serves a global community, it is important that we have global perspectives represented in our leadership. Define mechanisms for leadership and governance that includes representation along these axes. Leadership at a staff level is one way to ensure representation of diverse perspectives, but there are many other ways to bring voices into the conversation. We aim to explore new ways of bringing diverse voices into the strategic direction of the organization and provide mechanisms for holding us accountable to our values. For example, we intend to grow a board to guide 2i2c’s strategy and hold its Executive Director accountable for achieving impact - this is another opportunity to bring diverse perspectives into our leadership. Make a plan for improving leadership diversity within our team. Whatever mechanisms we create for diverse leadership, we know that one of them needs to be improving our diversity at a staff leadership level. Our staff are the ones that spend the most time working on - and have the most leverage over - our strategy and mission, and it’s important that our staff leadership is a good representation of the diverse perspectives of the communities we serve. This might mean investing more heavily in reaching broad applicant pools for new positions, seeking external consultation for how we can avoid unintentionally sending exclusionary signals to others in our communications and outreach and developing incentives to retain our talent over time. Continue improving our systems of delivery and work. Finally, we believe that a crucial aspect of improving the diversity in our organization is to continue transforming our systems for delivery, reliability, and accountability across the organization. This effort is a crucial step for fostering an inclusive and equitable culture. We have made a lot of progress in …","date":1719532800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1719532800,"objectID":"f99034b7f242c392a7f4181f151b568b","permalink":"https://2i2c.org/blog/2024/dei-leadership-strategy/","publishdate":"2024-06-28T00:00:00Z","relpermalink":"/blog/2024/dei-leadership-strategy/","section":"blog","summary":"As an organization committed to broadening access to interactive computing for global communities, we believe that a team embedded with diverse insights and lived experiences can more effectively advocate for underrepresented voices in our socio-technical partnerships.","tags":["culture"],"title":"We need to improve the diversity of our leadership","type":"blog"},{"authors":["Jenny Wong"],"categories":["impact"],"content":"We are pleased to announce that we have deployed two ephemeral hubs for NASA communities!\nWhat did we do? # As part of the deliverables for our NASA High Priority Open-Source Science (HPOSS) award, we deployed two new ephemeral hubs:\na public small BinderHub that offers a “reader” experience where learners can interactively view GitHub repositories that deliver light scientific content with small compute and no barriers to authentication a big BinderHub that offers an “explorer” experience where learners can log in to access more substantial compute resources to interactively investigate large datasets and run large workflows from any GitHub repository. These services enrich the interactive computing ecosystem for NASA communities by\nimproving the shareability and reproducibility of scientific information broadening participation for historically excluded and under-resourced science communities enabling activities such as hackathons, demonstrations or training, during workshops and conferences. How did we do it? # Ephemeral interactive computing services benefited from some of our previous development work in collaboration with GESIS (see our detailed blog post for more information). The research and development of this project achieved wide-reaching impact across many NASA communities we currently serve, including TOPST ScienceCore, Openscapes, US Greenhouse Gas Center, VEDA and CryoCloud; as well as networks beyond the NASA scope, such as the NSF-funded Project Pythia and HHMI-funded Spyglass projects.\nWhat next? # We will focus on bolstering the community- and knowledge-building needed for making the best use of these binder services in the next phase of our HPOSS work to accelerate broader participation in science. This includes opportunities such as running workshops and tutorials, as well as disseminating best practices for collaborative research. Further engineering developments will proceed in collaboration with the NASA VEDA project to set up a binder service, improve the sharing of custom environments, and refine QGIS integrations for analysing geospatial data.\nCan I use this ephemeral hub service? # The answer is yes!\nFor the public small BinderHub anyone can view GitHub repositories that deliver light scientific content with small compute and no barriers to authentication For the big BinderHub you will need to be member of a NASA community. This requires a GitHub account for membership of the GitHub Team 2i2c-nasa-binder-access:big-binder-team for authorization. Please send us an email at binder-requests@2i2c.org to be added to the GitHub Team. Acknowledgements # NASA NSPIRES F.15 High Priority Open-Source Science Award NNH22ZDA001N-HPOSS ","date":1719446400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1719446400,"objectID":"b020d2ad605f841c65305ab0697f1b07","permalink":"https://2i2c.org/blog/2024/nasa-ephemeral-hubs/","publishdate":"2024-06-27T00:00:00Z","relpermalink":"/blog/2024/nasa-ephemeral-hubs/","section":"blog","summary":"We are pleased to announce that we have deployed two ephemeral hubs for NASA communities!\nWhat did we do? # As part of the deliverables for our NASA High Priority Open-Source Science (HPOSS) award, we deployed two new ephemeral hubs:","tags":["geoscience","education"],"title":"Ephemeral Interactive Computing for NASA Communities","type":"blog"},{"authors":["Jenny Wong"],"categories":["impact"],"content":" Neurohackademy Summer School 2i2c are pleased to support the Neurohackademy Summer School in neuroimaging and data science again!\nFollowing the success of our collaboration in previous years (see the event page for 2023), this year’s course will be held July 29th – August 10th, 2024 and will be hosted by the University of Washington eScience Institute.\nWe provide an interactive computing platform for participants to get hands on experience in data pipelining, machine learning and data visualization techniques. Take a look at the following links to learn more about the neurohackathon:\nHack week: Study supports collaborative, participant-driven approach for researchers to learn data science from their peers NeuroHackademy debuts successfully Hackathon Combines Neuroscience and Data Science NeuroHackademy participants offer perspectives Participants offer insight on Neurohackademy Acknowledgements # Funded by grant R25MH112480 from the US National Institute of Mental Health awarded to Ariel Rokem and Noah Benson.\nThe Neurohackademy Summer School is sponsored by\nUniversity of Washington eScience Institute Gordon and Betty Moore Foundation Alfred P. Sloan Foundation University of Washington The University of Texas at Austin National Institute of Mental Health National Science Foundation ","date":1718928e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1718928e3,"objectID":"16a67df20fe5a1cb0082cfee886f198f","permalink":"https://2i2c.org/blog/2024/neurohackademy-summer-school/","publishdate":"2024-06-21T00:00:00Z","relpermalink":"/blog/2024/neurohackademy-summer-school/","section":"blog","summary":"Neurohackademy Summer School 2i2c are pleased to support the Neurohackademy Summer School in neuroimaging and data science again!\nFollowing the success of our collaboration in previous years (see the event page for 2023), this year’s course will be held July 29th – August 10th, 2024 and will be hosted by the University of Washington eScience Institute.","tags":["bioscience","education"],"title":"Neurohackademy Summer School in Neuroimaging and Data Science 2024","type":"blog"},{"authors":["Jenny Wong"],"categories":["impact","updates","partnerships"],"content":" Summer school for inverse modeling of greenhouse gases 2024 The Cooperative Institute for Research in the Atmosphere ( CIRA) is an interdisciplinary cooperation between NOAA research scientists and Colorado State University. CIRA is hosting a summer school for inverse modeling of greenhouse gases using atmospheric data assimilation techniques. The US Greenhouse Gas Center is supporting the workshop by providing 40+ attendees access to their interactive computing hub operated by 2i2c (see our blog post about their launch).\nHub administrators have built a customized software environment with container technology for use at the workshop. In doing so, this bypasses the need for participants to individually install software on their own machines and the online hub provides a consistent and reproducible interactive computing environment that is easily accessible and scalable.\nLogin screen of the GHG hub showing the custom built SSIM-GHG image option. Acknowledgements # 2i2c would like to credit the following individuals for their great efforts supporting this workshop:\nSanjay Bhangar (Development seed) Slesa Adhikari (NASA IMPACT) ","date":1718841600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1718841600,"objectID":"359285341adb9ee283e99471397f154e","permalink":"https://2i2c.org/blog/2024/ghg-summer-school/","publishdate":"2024-06-20T00:00:00Z","relpermalink":"/blog/2024/ghg-summer-school/","section":"blog","summary":"Summer school for inverse modeling of greenhouse gases 2024 The Cooperative Institute for Research in the Atmosphere ( CIRA) is an interdisciplinary cooperation between NOAA research scientists and Colorado State University.","tags":["geoscience","education"],"title":"US Greenhouse Gas Center supports summer school at CIRA","type":"blog"},{"authors":["Jenny Wong","James Munroe","Angus Hollands"],"categories":["impact"],"content":" Photo courtesy of Dr Debanjana Das What is Project Pythia? # Project Pythia is the education working group for Pangeo, a community platform for Big Data geoscience in which 2i2c operates a cloud hub. The core aim of Project Pythia is to spearhead the creation and curation of community-driven, open-source documentation, in the form of “cookbooks”, to enable the adoption of open, scalable and reproducible workflows for geoscientists.\nWhat did 2i2c do? # Jenny, James and Angus from the 2i2c team participated in the annual Project Pythia Cook-off 2024, a hackathon where cookbook authors and collaborators can spend dedicated time on creating and maintaining their content using Jupyter Book and deploying their cookbooks with GitHub actions.\n2i2c teamed up with the infrastructure breakout group during the hackathon, led by Katelyn FitzGerald (UCAR) and Kevin Tyle (University at Albany), and members of the Curvenote team also joined the group.\nDay 1 # 2i2c deployed and demonstrated a dedicated BinderHub service for Project Pythia that allowed hackathon participants to “self-serve” images of their software environment, which were specified by including a list of packages in an environment.yml file placed in their GitHub cookbook repository. Participants could then pull the image from a container registry into their 2i2c hub (or indeed, any other JupyterHub server) to share and reproduce their computational environments with ease.\nDay 2 # During the first half of the day, we quickly identified a number of issues that were proving to be a maintenance headache for the Project Pythia infrastructure group:\nConfiguration files for each cookbook were difficult to update at scale. Project Pythia currently have a gallery of over 30 cookbooks! Changes to Sphinx-based themes inherited from upstream were prone to breaking custom Project Pythia branding downstream. Executable content was not able to run on the Project Pythia’s dedicated BinderHub hosted on JetStream2 (operated by NSF). Cookbooks frequently cross-referenced materials from other cookbooks to build upon pre-existing knowledge, but this was not easy to author and the reader experience was not as smooth as it could be. Following the announcement that Jupyter Book 2.0 will use MyST last month, Rowan (Curvenote) and Angus (2i2c) delivered a compelling demonstration of the MyST ecosystem centered around modern web-first technologies (JavaScript/TypeScript) that offers improved interactivity and accessibility.\nIn the second half of the day, we decided to use the hackathon to explore migrating the Pythia cookbooks from using a Sphinx-based to a MyST-based document structure and engine. Within one afternoon, the group migrated four cookbooks to use MyST MD\nPythia Foundations High Resolution Rapid Refresh on AWS Radar Cookbook Advanced Visualization. This moment was palpably exciting! It was evident that MyST MD supported backwards compatible content out of the box, which alleviated fears of sunk cost into existing Sphinx-based cookbooks. The migration workflow was as simple as executing the following commands\nconda install mystmd\nmyst.\nDay 3 # We spent this day tackling support for managing a gallery of Project Pythia cookbooks at scale. See the Executable Books blog post for technical details on how we\nCentralized configuration Prototyped a gallery plugin in Python Fixed a number of bugs related to integrated computation with Binder and JupyterLite Embraced the referencing and reuse of content with simple markdown syntax for hover-references. Day 4 # Looking to the future, we spent time reflecting on our experiences and discussing the potential, transformative impact MyST MD tooling could have in the hands of the scientific community at large, including the communities served by 2i2c. Knowledge-sharing based on static figures and PDFs would fall obsolete and give way to a dynamic, web-first approach to sharing interactive narratives backed by compute from a Jupyter server.\nThroughout the course of the hackathon, the rate of iterated development for both end users of the community cookbook and the developers of the open-source tooling was astounding. For example, we were able to quickly expose small bugs ( e.g. support for HTML video tags) in the MyST MD tooling, which were immediately fixed upstream and released within minutes. The feedback loop that connected the user experience with the software tooling was incredibly synergistic, with immediate impact both upstream and downstream that 2i2c hopes to continue replicating across many facets of their operations.\nBeyond the Project Pythia Cook-off, the breakout group will continue conversations around strengthening their community of practice and hopefully advocating for wider adoption of MyST MD amongst the scientific community (say hello to some of our group members at SciPy 2024 in July!).\nAcknowledgements # University at Albany (NSF award 2324302): Led the funding acquisition, helped organize and facilitate the event …","date":1718668800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1718668800,"objectID":"fc3f258e0a3863ceb0cb6e0d66ec641a","permalink":"https://2i2c.org/blog/2024/project-pythia-cookoff/","publishdate":"2024-06-18T00:00:00Z","relpermalink":"/blog/2024/project-pythia-cookoff/","section":"blog","summary":"Photo courtesy of Dr Debanjana Das What is Project Pythia? # Project Pythia is the education working group for Pangeo, a community platform for Big Data geoscience in which 2i2c operates a cloud hub.","tags":["open source","Jupyter Book","geospatial"],"title":"Hacking the Project Pythia Cook-off with MyST Markdown","type":"blog"},{"authors":["Chris Holdgraf"],"categories":["organization","service"],"content":"Over the past several years, 2i2c has built a platform for serving community-centric hubs that provide a digital home for workflows in creating and sharing knowledge. See our three-year retrospective for a report about the growth and impact this service has had.\nDuring that time, we’ve experimented with several models for funding and sustaining this infrastructure. We’ve tried everything from direct cost-recovery from individual communities, to institutional contracts that cover several hubs, to grant-based models that fund many communities at the same time.\nThere are pros and cons associated with each, and we believe that a combination of all of them is important for a long-term service sustainability model for 2i2c. However, with this post we’d like to share the community funding model that strikes the right balance between short-term sustainability and scalability.\nIn short: 2i2c aims to serve networks of communities that are joined by a domain or workflow, and fund the network at once rather than through one-on-one contracts.\nA model of the funding and service relationships we aim to build. We believe that this model strikes a balance between “scalable and very simple hubs” (which require a lot of administrative toil) and “fully bespoke hubs” (which are expensive and unscalable). By using a single funding contract to serve many communities, we can reduce the amount of sales and contracting toil for each community. This will let us raise funds more quickly, and focus more of our time on delivering service.\nWe are seeking community leaders to collaborate # If you’re part of one or more communities that would benefit from cloud infrastructure for creating and sharing knowledge, and believe a network like this would benefit you, please reach out! We are seeking leaders collaborate in designing service for networks like the ones described above, and identifying potential funding sources for it.\nIf you’re interested in collaborating on this, send an e-mail to partnerships@2i2c.org.\nLearn more # You can find more information about this fundraising and service strategy in our Team Compass documentation.\n","date":1718668800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1718668800,"objectID":"778d786f72c8f47613284a2d5650bab7","permalink":"https://2i2c.org/blog/2024/funding-community-networks/","publishdate":"2024-06-18T00:00:00Z","relpermalink":"/blog/2024/funding-community-networks/","section":"blog","summary":"Over the past several years, 2i2c has built a platform for serving community-centric hubs that provide a digital home for workflows in creating and sharing knowledge. See our three-year retrospective for a report about the growth and impact this service has had.","tags":["sustainability"],"title":"Towards scalable and sustainable networks of community hubs","type":"blog"},{"authors":["Jenny Wong"],"categories":["impact"],"content":" The UToronto hub landing page 2i2c has operated The University of Toronto hub since 2021 and this hub supports over 6000 educators and learners in a day! With a community of this size, file storage can quickly grow out of control and cause issues.\nThe 2i2c engineering team have implemented a low storage alerting system for Microsoft Azure, so that they can pre-emptively take remedial action before the filesystem is about to run out of diskspace.\nGreat job team 🚀\nUToronto hub usage ","date":1718323200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1718323200,"objectID":"995e434955e5e4182f24fd1ae4d780d7","permalink":"https://2i2c.org/blog/2024/utoronto-storage-monitoring/","publishdate":"2024-06-14T00:00:00Z","relpermalink":"/blog/2024/utoronto-storage-monitoring/","section":"blog","summary":"The UToronto hub landing page 2i2c has operated The University of Toronto hub since 2021 and this hub supports over 6000 educators and learners in a day! With a community of this size, file storage can quickly grow out of control and cause issues.","tags":["education"],"title":"Low storage alerting for the UToronto cluster","type":"blog"},{"authors":["Jenny Wong"],"categories":["impact"],"content":" Spyglass landing page Spyglass is a framework for reproducible and shareable neuroscience research produced by Loren Frank’s lab at the University of California, San Francisco. They recently released a preprint about their toolbox, and are using a 2i2c hub to provide accessible interactive cloud environments that demonstrate its functionality and helps researchers get started.\nAcknowledgements # This work was supported by National Institute of Mental Health (NIMH), grant number RF1MH130623.\n","date":1716249600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1716249600,"objectID":"21934f7bb262e0f91229041f9885156f","permalink":"https://2i2c.org/blog/2024/hhmi-spyglass/","publishdate":"2024-05-21T00:00:00Z","relpermalink":"/blog/2024/hhmi-spyglass/","section":"blog","summary":"Spyglass landing page Spyglass is a framework for reproducible and shareable neuroscience research produced by Loren Frank’s lab at the University of California, San Francisco. They recently released a preprint about their toolbox, and are using a 2i2c hub to provide accessible interactive cloud environments that demonstrate its functionality and helps researchers get started.","tags":["bioscience"],"title":"Howard Hughes Medical Institute publishes preprint on Spyglass, a framework for reproducible and shareable neuroscience research","type":"blog"},{"authors":["Angus Hollands","Chris Holdgraf","Rowan Cockett"],"categories":["impact"],"content":"See the Executable Books blog for a post on the future directions of the Jupyter Book project, which will be built on top of the MyST Markdown engine.\n","date":1716249600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1716249600,"objectID":"db6f343c8a73a07841ec11a7718e2f53","permalink":"https://2i2c.org/blog/2024/myst-jupyter-book/","publishdate":"2024-05-21T00:00:00Z","relpermalink":"/blog/2024/myst-jupyter-book/","section":"blog","summary":"See the Executable Books blog for a post on the future directions of the Jupyter Book project, which will be built on top of the MyST Markdown engine.","tags":["open source","Jupyter Book"],"title":"Jupyter Book 2.0 will use MyST","type":"blog"},{"authors":["Jenny Wong"],"categories":["impact"],"content":" Figure from the preprint showing large and small scale air-sea fluxes are separated. By Julius Busecke et al., licensed under CC BY 4.0 Julius Busecke et al. of the LEAP-Pangeo1 hub, have recently published a preprint2 that investigates “The Overlooked Sub-Grid Air-Sea Flux in Climate Models” using 2i2c infrastructure.\nSee Julius’ social media post for a more bite-sized outline of the work done.\nWell done all! 🎉\nNSF Science and Technology Center (STC) Learning the Earth with Artificial intelligence and Physics (LEAP) (Award # 2019625) ↩︎\ndoi.org/10.31223/X5WQ47 ↩︎\n","date":1716249600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1716249600,"objectID":"b200749d9f926d902fa7e2293f759749","permalink":"https://2i2c.org/blog/2024/leap-pangeo-paper/","publishdate":"2024-05-21T00:00:00Z","relpermalink":"/blog/2024/leap-pangeo-paper/","section":"blog","summary":"Figure from the preprint showing large and small scale air-sea fluxes are separated. By Julius Busecke et al., licensed under CC BY 4.0 Julius Busecke et al. of the LEAP-Pangeo1 hub, have recently published a preprint2 that investigates “The Overlooked Sub-Grid Air-Sea Flux in Climate Models” using 2i2c infrastructure.","tags":["geoscience","community"],"title":"Researchers at LEAP-Pangeo investigate overlooked sub-grid air-sea heat flux in climate models","type":"blog"},{"authors":["Chris Holdgraf"],"categories":["organization","service"],"content":"2i2c recently finished it’s three year retrospective after closing out its original seed grant. As part of this process, we’re revisiting our organizational strategy, structure, and overall plan, in order to incorporate the learning that we’ve done over our first three years.\nOur value proposition is a key framing for 2i2c’s intended impact, key stakeholders, and platform strategy. We recently completed a team exercise to refine this statement for 2i2c, and are excited to share it with you below:\nA global network of community hubs for interactive learning and discovery Our interactive computing platform gives your community a digital home to create and share knowledge, and a global network of communities to learn from. This is an exciting direction that leans into and builds upon the way we’ve described our service so far. It recognizes that the value in our service doesn’t end with simple access to an interactive computing environment, but lies in how that environment’s tools empower a community to create and share knowledge with one another.\nWe believe that this is an exciting direction to build towards, because it is based in the value of the collection of communities we serve, and the way that this network can be greater than the sum of its parts. We’re excited to lean into this direction in how we shape our platform, what open source contributions we make, and where we aim to have impact in the coming years.\nTo begin, we’ve interwoven some ideas from this value proposition into 2i2c.org, and the way that we describe our service. We’d love feedback from anyone who has an idea, a critique, or “yes, and” to share.\nA recent talk with this value proposition # As part of this work, 2i2c’s Executive Director, Chris Holdgraf, gave a talk about 2i2c to the Incentivizing Open and Collaborative Research (ICOR) community. Here are some links in case others are interested:\nSlides for viewing More information for the talk Video link Here’s the video below for quick reference:\nData Sharing and Analysis in Collaborative Open Research Environments from Michael Markie on Vimeo.\n","date":1714953600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1714953600,"objectID":"da52f16079db53f897ddd141995924f2","permalink":"https://2i2c.org/blog/2024/value-proposition/","publishdate":"2024-05-06T00:00:00Z","relpermalink":"/blog/2024/value-proposition/","section":"blog","summary":"2i2c recently finished it’s three year retrospective after closing out its original seed grant. As part of this process, we’re revisiting our organizational strategy, structure, and overall plan, in order to incorporate the learning that we’ve done over our first three years.","tags":["product"],"title":"An update to 2i2c's value proposition","type":"blog"},{"authors":["Chris Holdgraf","Harold Campbell"],"categories":["organization"],"content":"This is a follow-up to our 2023 report of organizational strengths and weaknesses, describing some improvements we’ve made on our team’s coordination and delivery.\nIn 2023, we released a report describing our organizational strengths and weaknesses. This uncovered a key challenge for our team: improving our coordination and delivery. Over the previous two years, our service had grown significantly in its scope and complexity. We were working on more than 7 active grants and were serving more than 70 active communities with around 7,000 monthly active users.\nThis was taxing our small team, and we found ourselves struggling to efficiently deliver on our work. For example, a collaboration with GESIS to bring image building functionality to JupyterHub took longer than we wished, and we felt that our planning and execution was not transparent enough to their team. In addition, in a collaboration to serve communities in Latin America and Africa we felt that 2i2c was not responsive enough to onboarding and deploying infrastructure for new communities.\nSteps we’ve taken to improve delivery # At the beginning of 2024, we hired our first Delivery Manager and Chief of Staff role as well as our first Product Lead role. Both of these roles are meant to develop systems and team practices that improve our planning and delivery.\nIn Quarter 1 of 2024, we designed and initiated an organizational transformation with the following goals:\nProvide clarity about our overall organizational goals and strategy. Define our near-term goals and major projects that drive our work. Define and prioritize the major work items that feed into these goals. Break this major work items into actionable items that our team can work on from day to day. Provide visibility for all of this information across the entire organization. Below is a brief description of the major changes that we’ve made. These are still a work in progress, and organizational transformation takes months, if not years, but we hope that this provides a useful snapshot in time as we kick off this process.\nOur system of work # Our team-wide system of work can be found in the Team Compass at the link below:\ncompass.2i2c.org/cross-functional/workflow/\nThis system of work attempts to link our strategic goals with concrete chunks of work to deliver. You can see an overview of this system below:\nOur work system shows how initiatives are made up of lists of actions that accomplish them. These actions are distributed across our team’s operational boards for delivery. It is roughly broken down into these major areas:\nOur value proposition: Our system of delivery starts with a value proposition. This is a north-star statement for the value that 2i2c aims to provide to our communities in order to achieve our mission. It is a guiding principle for where we prioritize our time and improve our service.\nWhile updating our delivery model, we decided it was time to update the value proposition we’d been informally using. We’re in the process of validating this value proposition with communities, and will share a draft for public comment soon!\nStrategic goals and major projects: Next we define strategic goals that describe the most important progress we must make as an organization. This considers our current capabilities and challenges, as well as the major projects that we’re already committed to (like grants). Our initiatives (described below) should each represent progress towards one or more of our goals and major projects.\nStrategic initiatives: These are major thrusts of work that represent progress towards our goals. They range in time from weeks to months, and generally require coordination and action across each of 2i2c’s functional areas. Initiatives exist in a dedicated board, where we shape and scope them with enough information to understand them and prioritize. Once an initiative is in progress, it begins driving work on a two-week planning cycle. All in-progress initiatives should make up a significant percentage of 2i2c’s total work allocation.\nOperational boards: Operational boards are used to track our day-to-day workstreams. We organize into two-week sprints, with a collection of work pulled into each sprint according to in-progress initiatives and the other types of reactive and operational work on our plate (for example, responding to support tickets is reactive work). Within each initiative, we coordinate across our teams in order to understand the next steps needed and who is responsible for doing it. This helps teams plan the work for their next iteration.\nThis system is very much still a work in progress, and we’ve already identified a number of ways that we’d like to improve it moving forward. For example, we’d like to find more efficient ways of coordinating across our team, and encouraging team members to own their own work.\nChanges to our team culture # In addition to our system around planning work, we’ve also identified a number of ways that we can improve our …","date":1713139200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1713139200,"objectID":"affa08ea5c8b3279786b5cd50f8bc84b","permalink":"https://2i2c.org/blog/2024/delivery-improvements/","publishdate":"2024-04-15T00:00:00Z","relpermalink":"/blog/2024/delivery-improvements/","section":"blog","summary":"This is a follow-up to our 2023 report of organizational strengths and weaknesses, describing some improvements we’ve made on our team’s coordination and delivery.\nIn 2023, we released a report describing our organizational strengths and weaknesses.","tags":["culture"],"title":"Improvements to our team's planning and delivery","type":"blog"},{"authors":["Chris Holdgraf"],"categories":["impact","service"],"content":" What happened? # A few weeks ago, the JupyterHub team discovered a security vulnerability in the jupyter-server-proxy package that would allow potential unauthenticated access to a JupyterHub via WebSockets, allowing unauthenticated users to run arbitrary code on the JupyterHub. jupyter-server-proxy is used by many communities to provide alternative user interfaces like RStudio and remote desktops.\nThis vulnerability was detected by the JupyterHub team, with leadership from 2i2c’s engineers. It was resolved through upstream contributions to the JupyterHub project, and we have deployed a fix that mitigates this vulnerability for all the hubs 2i2c manages.\nDoes this impact my 2i2c community hub? # We do not believe that any of 2i2c’s communities were impacted by this vulnerability, and a patch has now been pushed to all community hubs to resolve this issue.\nIf your community was vulnerable to this problem, you might experience slightly slower startup latency while we work out a long-term solution.\nSince this is a vulnerability in the docker image used by our communities, we will be reaching out over the next few weeks to put a more permanent fix in place.\nWhere can I learn more? # See the JupyterHub security advisory for CVE-2024-28179 for more information about the security vulnerability, including details on the mitigation we have put in place to protect our communities.\nConclusion # We’re grateful that the JupyterHub community was quick to acknowledge, respond, and resolve this security vulnerability after it was brought to their attention. We’re also proud that 2i2c’s engineers helped the JupyterHub team throughout the process.\nThis allowed our team to resolve the problem before it impacted any of 2i2c’s communities. Because 2i2c community infrastructure is managed in a central location, we were able to resolve this for over 80 communities with a single team rather than expecting each community to learn about and fix this problem on their own.\nWe also believe this reflects the healthy upstream relationships that we hope to encourage with our team’s Open Source strategy and practices. By working with the JupyterHub community and pushing changes upstream, we’ve resolved this issue for any user of jupyter-server-proxy, not just 2i2c’s own ecosystem. In particular, because of 2i2c’s position running hubs for many communities via Kubernetes, we were able to identify a solution that did not require every user image to be updated (as described in section For JupyterHub admins of Z2JH installations).\nWe believe that all of these lead to a healthier, safer ecosystem of open source tools ❤️.\n","date":1710806400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1710806400,"objectID":"9b65af0a3c3fc20b796ab16baa5c7110","permalink":"https://2i2c.org/blog/2024/cve-jupyter-server-proxy/","publishdate":"2024-03-19T00:00:00Z","relpermalink":"/blog/2024/cve-jupyter-server-proxy/","section":"blog","summary":"What happened? # A few weeks ago, the JupyterHub team discovered a security vulnerability in the jupyter-server-proxy package that would allow potential unauthenticated access to a JupyterHub via WebSockets, allowing unauthenticated users to run arbitrary code on the JupyterHub.","tags":["open source","security"],"title":"Security report for jupyter-server-proxy: CVE-2024-28179","type":"blog"},{"authors":["Chris Holdgraf"],"categories":["organization"],"content":"We’re pleased to share a three-year retrospective report that was created to close-out 2i2c’s original seed funding grant provided by the Chan Zuckerberg Initiative.\nSee the Zenodo entry here: See the MyST website for the report at 2i2c.org/report-czi-2021. Download a PDF version generated by MyST here. This report was written with the new MyST Markdown document engine and shows off some of the functionality that we’ve been working on in collaboration with the MyST team.\nWe’re incredibly grateful for the seed funding that CZI provided to kickstart 2i2c’s mission and operations, and excited about more impact to come!\n","date":1709251200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1712793600,"objectID":"74aa80756eba5914eabcf720a6945927","permalink":"https://2i2c.org/blog/2024/report-czi/","publishdate":"2024-03-01T00:00:00Z","relpermalink":"/blog/2024/report-czi/","section":"blog","summary":"We’re pleased to share a three-year retrospective report that was created to close-out 2i2c’s original seed funding grant provided by the Chan Zuckerberg Initiative.\nSee the Zenodo entry here: See the MyST website for the report at 2i2c.","tags":["sustainability"],"title":"A three year retrospective report of 2i2c's impact","type":"blog"},{"authors":["Yuvi Panda"],"categories":["impact"],"content":"Thanks to Arnim Bleier, Jenny Wong, Georgiana Elena, Damián Avila, Jim Colliander and James Munroe for contributing to this blog post\nmybinder.org is a very popular service that allows end users to specify and share the environment (languages, packages, etc) required for their notebooks to run correctly by placing configuration files they are already familiar with (like requirements.txt or environment.yml) along with their notebooks. While not without its own set of challenges, this is extremely powerful because it puts control of the environment in the hands of the people who write the code. They can customize the environment to fit the needs of their code, instead of having to fit their code into the environment that admins have made available.\nBut, mybinder.org (and the BinderHub software that powers it) is built for sharing your work after you are done with it, not for actively doing work. BinderHubs often do not have persistent storage nor persistent user identity, and UX is centered around ephemeral interactivity that can be shared with others (via a link), rather than persistent interactivity that a single user repeatedly comes back to. JupyterHub is more commonly used for this kinda workflow, but doesn’t currently have the ability for users to easily build their own environments. Admins who are running the JupyterHub can make multiple environments available for users to choose from, but this still puts admins in the critical path for environment customization.\nOur collaboration with GESIS, NFDI4DS, and CESSDA, aims to bring this flexibility to JupyterHub directly. We aim to empower users to decide for themselves which applications and dependencies are installed on a per-project basis. Our work enables communities with heterogeneous requirements to share a single Hub. Our approach frees administrators from being overwhelmed by installation requests and transforms the JupyterHub platform into a platform for collaborative computational reproducibility. In this update, we report on our progress and upcoming steps in this project.\nWhat does a BinderHub do, exactly? # It is helpful to understand that BinderHub primarily has 3 responsibilities:\nPresent a UI to the end user for them to provide details on what to build (this is what you see when you go to mybinder.org) Call out to repo2docker in a scalable way to actually build and push an image containing the environment for the given repository, and show the user logs as this build process happens. This also allows users to debug issues with their build more easily. Talk to a JupyterHub instance to launch a user server with the built docker image, and redirect the user to this. (2) is really the core feature of BinderHub, and we settled on figuring out how to make that available to JupyterHub users. It was really important to us that this was also done in a way that can be sustainably used by everyone, not just 2i2c. This blog post discusses the various improvements to the broad ecosystem of projects in the Jupyter ecosystem to get this done.\nDemo # But first, a very quick demo of how this looks like right now now!\nThis is very much a work in progress, but the basic flow can be seen clearly. Users see a Server Options menu after they log into JupyterHub. They can specify the two primary things that determine the server configuration:\nThe resources allocated (RAM, CPU and maybe GPU)\nThe environment (container image) used, which can be specified in one of 3 ways:\na. A pre-selected list of environments (container images), provided by the administrators who set up this JupyterHub b. A blank text box where you can enter any publicly available docker image they want c. A mybinder.org style way to specify a GitHub repository, which will be then dynamically built into a docker image for the user!\nSo what did we need to do to accomplish this, in a way that’s very upstream friendly and usable by everyone (and not just 2i2c)?\nA Standalone binderhub-service helm chart # The default upstream BinderHub helm chart includes a JupyterHub as a dependency, and configures itself to be used primarily in a manner similar to mybinder.org. As the person who helped make that choice early on, I can tell you why it was made - for convenience! And it was very convenient, as it allowed us to get mybinder.org going fast. However, it makes it difficult to install a BinderHub service alongside an existing JupyterHub. To this end, we have created a standalone BinderHub helm chart, designed to be installed alongside an existing JupyterHub, so we can use it purely to build images. This allows the BinderHub instance to be used as a JupyterHub Service, which is what we want.\nWhile this helm chart is currently under the 2i2c GitHub org, the hope is that it can eventually migrate to a jupyterhub-contrib organization (once it is created), or it can become the upstream helm chart for BinderHub if enough work can be done in BinderHub to allow it to serve use cases like mybinder.org.\nAs part of …","date":1704329774,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1705090315,"objectID":"c9a2f2b9d4451cdafd606c391e5b036e","permalink":"https://2i2c.org/blog/2024/jupyterhub-binderhub-gesis/","publishdate":"2024-01-03T16:56:14-08:00","relpermalink":"/blog/2024/jupyterhub-binderhub-gesis/","section":"blog","summary":"Thanks to Arnim Bleier, Jenny Wong, Georgiana Elena, Damián Avila, Jim Colliander and James Munroe for contributing to this blog post\nmybinder.org is a very popular service that allows end users to specify and share the environment (languages, packages, etc) required for their notebooks to run correctly by placing configuration files they are already familiar with (like requirements.","tags":["jupyterhub","open source"],"title":"Integrating BinderHub with JupyterHub: Empowering users to manage their own environments","type":"blog"},{"authors":["James Colliander"],"categories":["impact"],"content":" Abstract\nThe International Interactive Computing Collaboration ( 2i2c.org), working with NASA VEDA, Development Seed and other partners, operates an interactive computing platform for The U.S. Greenhouse Gas Center. The U.S. GHG Center, announced yesterday at the 28th annual United Nations Climate Conference (COP-28) in Dubai, is an interagency collaboration of the Environmental Protection Agency (EPA), the National Aeronautics and Space Administration (NASA), the National Institute of Standards and Technology (NIST), and the National Ocean and Atmospheric Administration (NOAA). This note places the launch of the U.S. GHG Center in a scientific, international, and national context and argues that similar digital public goods are needed for humanity to understand and manage the Earth system.\nScientific Context # It was controversial in 1827 when Joseph Fourier (the discoverer of the law of heat conduction) argued 1 that the atmosphere keeps the Earth warm, like a puffy down comforter, but it’s not now. Gases in the atmosphere trap heat near Earth. How much heat is trapped depends on the gas mixture. Putting more heat-trapping gases in is like putting a wool blanket on top of the down comforter. Human activity since industrialization is injecting lots more heat-trapping gas into the atmosphere and changing the Earth’s climate.\nThe science is clear. The up-to-date consensus view of the global scientific community is expressed in the Sixth Assessment Report of the Intergovernmental Panel on Climate Change (IPCC):\nInternational Context # The international community officially recognized human-influenced climate change at the World Climate Conference (WCC-1) 2 in 1979. The 1979 declarationis remarkably prescient and detailed. A complex and interconnected collection of scientific and diplomatic activities were catalyzed by WCC-1. Some important milestones from this history are captured in the chart and numbered list below.\ngantt\rdateFormat YYYY-MM-DD\rtitle International Climate Change Milestones\rsection Study\rWCC-1 (1979) :crit, done, admin0, 1979-02-12, 1979-02-23\rWCP :crit, adminA, 1979-06-01, 2025-12-31 CMIP1: crit, done, adminT, 1995-01-01,1995-12-31\rCMIP2: crit, done, adminR, 1997-01-01, 1998-12-31\rCMIP2+: crit,done,adminS, 2000-05-09, 2001-12-31\rCMIP3 :crit, done, adminP, 2004-10-01, 2006-12-31\rCMIP5 :crit, done, adminO, 2008-09-01, 2013-03-15\rCMIP6 :crit, done, adminQ, 2014-02-01, 2024-12-31\rIPCC :crit, admin1, 1988-12-06, 2025-12-31\rIPCC-AR1 :crit, done, adminH, 1990-08-01, 1992-06-30\rIPCC-AR2 :crit, done, adminI, 1995-01-01,1995-12-31\rIPCC-AR3 :crit,done, adminJ, 2001-01-01, 2001-12-31\rIPCC-AR4 :crit, done,adminK, 2007-01-01,2007-12-31\rIPCC awarded Nobel Prize :crit, done, adminN, 2007-10-12, 2007-11-12\rIPCC-AR5 :crit,done,adminL, 2014-01-01,2014-12-31\rIPCC-AR6 :crit,done,adminM,2023-01-01,2023-12-31\rsection Treaties\rRio Earth Summit (1992) :crit, done, adminC, 1992-06-03, 1992-06-14\rUNFCC :crit, admin2, 1994-03-21, 2025-12-31\rBerlin (COP-1) :crit, done, adminE, 1995-03-28, 1995-04-07\rByrd-Hagel Resolution :crit, done, adminX, 1997-07-25, 1997-07-30\rKyoto (COP-3) :crit, done, adminD, 1997-12-01, 1997-12-10\rKyoto Protocol :crit, done, admin3, 1997-12-11, 2020-12-31 Paris (COP-21) :crit, done, adminF, 2015-11-30, 2015-12-12\rParis Agreement :crit, adminG, 2016-11-04, 2025-12-31\rGlasgow (COP-26) :crit, done, adminV, 2021-10-31, 2021-11-12\rDubai (COP-28) :crit, adminW, 2023-11-20, 2023-12-12\rETF :crit, adminU, 2024-01-01, 2025-12-31 The table above describes a subset (for a more systematic review see 3, 4) of key milestones in global efforts to understand and address climate change. A glossary of acronyms and additional background:\nThe First World Climate Conference (WCC-1) 2 was held in 1979. The World Climate Programme ( WCP), an activity overseen by the World Meteorological Organization was established after WCC-1. WCP, in partnership with other organizations, operates programs (e.g. the World Climate Research Program (WCRP)) that organize and integrate international scientific efforts to understand the climate. The WMO also operates the Integrated Global Greenhouse Gas Information System (IG3IS), a natural partner for the emerging work described below. WCRP manages the Common Model Intercomparison Project (CMIP). CMIP serves as a kind of league for intercomparing models of the Earth’s climate system developed by teams who approach the problems with different methods and designs. Intercomparison, an approach that enables finding the consensus views of teams with divergent approaches to problems, is used in other modeling scenarios. Research papers on the climate are rapidly produced by scholars from essentially all knowledge disciplines. This overwhelming stream of content, like snowflakes in a blizzard, is coalesced into coherent and carefully scrutinized IPCC Assessment Reports by the Intergovernmental Panel on Climate Change (IPCC). The Earth Summit held in Rio de Janeiro in 1992 led to the United …","date":1701734400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1701734400,"objectID":"439872a921884aafee39428ebea3e093","permalink":"https://2i2c.org/blog/2023/us-ghg-center-launches/","publishdate":"2023-12-05T00:00:00Z","relpermalink":"/blog/2023/us-ghg-center-launches/","section":"blog","summary":"Abstract\nThe International Interactive Computing Collaboration ( 2i2c.org), working with NASA VEDA, Development Seed and other partners, operates an interactive computing platform for The U.S. Greenhouse Gas Center. The U.","tags":["geoscience"],"title":"Digital public goods for Earth system management: U.S. Greenhouse Gas Center launches","type":"blog"},{"authors":["Chris Holdgraf","Yuvi Panda"],"categories":["impact"],"content":"The Jupyter Docker Stacks project provides a collection of ready-to-use Docker images for Jupyter environments. These images are used by many in the Jupyter community, including 2i2c which uses them as base images for our JupyterHub deployments.\nThe project recently began publishing ARM-compatible images alongside the standard x86 images, making it easier for users with ARM-based systems (like M1 Macs) to use these environments. However, building and hosting these ARM images comes with additional cloud computing costs that were being personally covered by @mathbunnyru, one of the project’s maintainers.\nA part of 2i2c’s mission is supporting upstream communities that we rely on, especially where the upstream project has limited resources. For this reason, we’ve decided to support Jupyter Docker Stack’s ARM building costs, with a total budget of $2000 (approximately $150 per month). As a regular user and beneficiary of the Jupyter Docker Stacks, we believe it’s important to contribute to the maintenance and sustainability of this crucial piece of infrastructure that benefits the entire Jupyter community.\nWe hope this support helps the Docker Stacks project remain healthy, and continue providing high-quality, multi-architecture images that work across different computing platforms. We’ll revisit this decision as the landscape of technology providers changes and other options arise.\n","date":1701388800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1701388800,"objectID":"b2be8c726ac8ff3bf5fc88b21747f051","permalink":"https://2i2c.org/blog/2023/docker-stacks-support/","publishdate":"2023-12-01T00:00:00Z","relpermalink":"/blog/2023/docker-stacks-support/","section":"blog","summary":"The Jupyter Docker Stacks project provides a collection of ready-to-use Docker images for Jupyter environments. These images are used by many in the Jupyter community, including 2i2c which uses them as base images for our JupyterHub deployments.","tags":["open source"],"title":"2i2c supports Jupyter Docker Stacks ARM builds","type":"blog"},{"authors":["Chris Holdgraf"],"categories":["organization"],"content":"Over the past few months, we’ve been investigating ways to improve our reporting both internally and externally. We’ve decided to experiment with a monthly community update to create a regular cadence of transparency and highlights from 2i2c for our broader community. This is the first such update, so bear with us as we work out the kinks!\nOur goal with these updates is to share what stands out at 2i2c - what we’ve learned, what we’re proud of, where we’ve struggled, and where we’ve had an impact. We hope this can be a historical record of “what stands out” to our team and that it is useful for our broader community to see. We also want this to be relatively short and to the point to make it sustainable to both write and read.\nWe’d love feedback on what else you’d like to see. If you have any ideas, please send an email to hello@2i2c.org.\nRough Numbers # First off, a few numbers on the scale and status of our interactive computing hub service:\nWe are currently running around 73 JupyterHubs that are collectively averaging more than 4000 average monthly users. We have several communities in the educational sector, so October was a peak in the Fall semester of activity.\nWe’re recovering roughly 40% of our monthly staffing costs through recurring service revenue. The remainder we’re making up with a combination of grants and more focused development contracts.\nAssuming minimal growth in our service and fundraising, our runway is roughly until August 2025 - however, we anticipate this to shrink in the short-term once we make critical new hires in the coming months.\nOrganization Updates # This section describes some major organization-wide efforts we’ve started or progressed over the last month.\nImproving Our Quarterly Sprints and Goals # This month our team kicked off the second round of our new quarterly sprints and goals process. This is an attempt to focus our team around a few goals and sub-teams dedicated to them throughout each quarter. Our hope is that this allows us to make strategic “pushes” in directions that feel important for 2i2c’s operations and the communities we serve.\nThis quarter, we incorporated a lot of learning that took place after our first iteration in Q3 2023. We are hoping to sharpen up the timing of events throughout the process, including communicating internally and externally about our status (thus, this blog post series).\nIn the next quarter, we aim to build off of this work, and to identify where our future new hires of Delivery Manager / Interim Chief of Staff and our Product Lead will fit in.\nThree New Jobs Posted # In October, we began a short hiring push to address many of the organizational challenges noted in our organizational structure and strategy audit. We aim to have each of these positions filled by the end of the year and begin incorporating new team members into our organization. Here’s a list of the three job postings:\nDelivery Manager / Interim Chief of Staff Product Lead Open Source Infrastructure Engineer: Cloud Engineering Product Strategy Work # We kicked off a collaboration with Richard Pope to provide us with some short-term product strategy work. In Q3, our team took stock of the many different kinds of services and technology that we deploy, aiming to refine this into a long-term product model.\nRichard will join us for several months to take these outputs and help us craft them into a model for where 2i2c is delivering value that we can build upon for the coming years. We’ll provide more updates for the community as this work continues.\nContinued Onboarding of Communities in Our Catalyst Project Collaboration # We continued onboarding communities onto infrastructure managed by 2i2c as part of a CZI-funded project to serve communities in Latin America and Africa. The grant team began its operations last April and spent the first several months creating an onboarding pipeline and rubric for identifying and connecting with communities. As of October, we’ve onboarded our first few communities - there is still a lot of content, training material, and documentation to create, and we will begin iterating on this in collaboration with our early-adopted communities in Q4 2023 and Q1 2024.\nPartnerships and Impact # This section describes notable new partnerships and developments with communities in our interactive computing hub service.\nWe began several new partnerships with communities in the research space this month.\nThe NASA Visualization, Exploration, and Data Analysis (VEDA) project is an open-source science cyberinfrastructure for data processing, visualization, exploration, and geographic information systems (GIS) capabilities.\nThe US Greenhouse Gas Center provides a cloud-based system for exploring and analyzing U.S. government and other curated greenhouse gas datasets.\nIn addition, we’ve celebrated considerable growth in one of our partner communities: CryoCloud. This community focuses its work around studying the Cryosphere using satellite imagery data. …","date":1699574400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1699574400,"objectID":"eb4bed1d078424b0423eb1005a0937aa","permalink":"https://2i2c.org/blog/2023/update-october/","publishdate":"2023-11-10T00:00:00Z","relpermalink":"/blog/2023/update-october/","section":"blog","summary":"Over the past few months, we’ve been investigating ways to improve our reporting both internally and externally. We’ve decided to experiment with a monthly community update to create a regular cadence of transparency and highlights from 2i2c for our broader community.","tags":[],"title":"Community Update: October 2023","type":"blog"},{"authors":["Chris Holdgraf"],"categories":["organization"],"content":"Over the last several months 2i2c has been working with an organizational consulting group called Difference Digital to help us identify the major opportunities and challenges in our organizational structure and strategy. The result of this work is a report that describes in detail the major strengths, weaknesses, challenges, and opportunities that 2i2c faces. It also recommends major actions to take as an organization.\n2i2c values organizational transparency and a willingness to be honest about where you’re struggling. Stress is a natural part of both individuals and organizations, and should be embraced with the goal of learning and improving. Moreover, as a young organization 2i2c has benefitted heavily from the documents and learning that other organizations have made publicly available. We wouldn’t be where we are without building on the backs of others who are willing to share what they’ve learned.\nSo, we are making this organizational audit and report public for anyone to see. We hope that it provides transparency into 2i2c’s current status, and that it serves as a useful resource for other non-profits that are growing and facing similar challenges.\nHere’s a link to the report on Zenodo.\nFor more background on this report, check out the short description below.\nIn April of this year we had our first in-person team meeting. We were excited and grateful to have the opportunity to speak to each other face-to-face. We also learned that many people on our team were stressed out! Our service had grown slow-but-steadily over the previous year, and we were feeling the tension that comes with growing your partnerships without significantly changing your team’s capacity or structure.\nSo, we decided to work with an organizational consulting group called makeadifference.digital to help us identify where we need to make improvements. They spent several weeks having one-on-one conversations with each member of the team, as well as doing a broader organizational analysis and comparison to other technical organizations at a similar stage of their lifecycle.\nThe result of this work was a report that outlines the major opportunities and strengths, as well as challenges and gaps in capacity, that our team currently faces. It makes a number of recommendations for how we should shift our practices, and importantly it also notes that the only way to gain that capacity is by hiring for new people and skills.\nHere’s a link to the report on Zenodo.\nThe immediate result of this work is that we currently have three jobs posted:\nA Product Lead role to help us build a “product function” within 2i2c’s team. A Delivery Manager / Chief of Staff role to oversee and manage 2i2c’s system of work. A cloud and operations engineering role to grow our cloud engineering team’s capacity in serving communities. Our next steps are to fill these positions, and to then begin the work of implementing many of the recommendations that are contained in the report. We’re confident that this is a natural part of being a small and growing organization, and we are grateful for the expertise of makeadifference.digital in guiding us through this work.\nNote: if you’d like to work with makeadifference.digital, you can reach out to them at hello@makeadifference.digital.\n💡 Follow our work! Sign up for our mailing list for updates about 2i2c. Send us an e-mail about collaborating or partnering on a project. See our Service Documentation or our Team Compass to learn about our service and organization.\n","date":1699401600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1699401600,"objectID":"59480fc276a9d788565555c7b0b50d1c","permalink":"https://2i2c.org/blog/2023/organizational-report/","publishdate":"2023-11-08T00:00:00Z","relpermalink":"/blog/2023/organizational-report/","section":"blog","summary":"Over the last several months 2i2c has been working with an organizational consulting group called Difference Digital to help us identify the major opportunities and challenges in our organizational structure and strategy.","tags":[],"title":"Open organizational report: Strengths and challenges for 2i2c's team","type":"blog"},{"authors":["Chris Holdgraf"],"categories":["organization"],"content":"It’s been two quarters since our last major update - this isn’t quite as frequent as we’re hoping to post updates from our team, but we’re making adjustments to have more regular communication for reasons that will hopefully be a bit clearer below! In that time, we’ve been hard at work serving and growing our interactive computing service, as well as doing some introspection as a team and identifying major next steps moving forward. More on that in the following sections, but first a short service update.\nHow has our service evolved over the past few months? # New partnerships and service growth # Our service has grown several new partner communities over the last two quarters. A few notable communities are the NASA VEDA project, a team at the Smithsonian, a team at NCAR, and the U.S. Greenhouse Gases Center. We are running about 71 hubs across 24 clusters, with about 4000 weekly users ( more usage stats here).\nWe also began operations on a major collaboration to serve communities in Latin America and Africa, called the Catalyst Project. This team met together for the first time in April, and we’ve been laying a foundation for service growth in the first several months. We are just onboarding our first communities and hope to grow that service in the coming year.\nFinally, we’ve been fortunate to receive some grants around creating content and designing workflows that utilize cloud infrastructure. For example, a NASA TOPS grant and an upcoming collaboration with Project Pythia around geospatial workflows.\nFinancial picture # At this point, we’re recovering roughly 40% of our operating costs through recurring fees of our managed hub service (making up the remainder in development contracts and grants), and we’ve currently got around 2 years of runway.\nHowever, both of these will be lowered soon because we are about to hire for several more positions. Improvements to our product model will allow us to estimate and recover our service costs more effectively, but we also intend to raise some funds next year to support our efforts in making our service more robust, sustainable, and valuable to communities.\nIt’s always difficult to strike a proper balance of team (and cost) growth against the financial buffer needed to assure your partners you’ll stick around, but we’re confident that the new hires described below will serve critical needs for our team and mission.\nFor more context on why and how we’re trying to make up that capacity, read on…\nHow service growth can lead to team stress # Over the past year we’ve had a slow-but-steady stream of new communities interested in working with 2i2c for managing cloud infrastructure for interactive computing. We’ve taken a “let’s make it work somehow” approach to all of our community partnerships thus far, with the idea that we must use these partnerships to learn what communities want and identify common patterns.\nThis is exciting, and we’re fortunate to see the interest and growth in our service. It suggests to us that something about our model is fundamentally right. Communities really love the Right to Replicate, and our participatory service model based around upstream contributions, transparency, and shared responsibility is attractive to many in research and education.\nHowever, each new community is also a new set of stresses on the technical and social infrastructure of our team. Without the capacity to manage the demands of the service, you run the risk of over-extending – and in a worst case scenario, burning out – your team.\nThis became clear in our first in-person team meeting last May. At that meeting, we realized that many on the team were spending too much of their time “reacting” to demands from the service. We also learned that the scope and complexity of our various workstreams had gotten to a size where our informal team structures of work prioritization were no longer adequate.\nGrowing the complexity of our team to match the complexity of our service # So, for the past several months we’ve been working on a plan to evolve 2i2c’s team structure in order to more effectively manage the complexity of our service, and balance long- and short-term thinking.\nThis began with an organizational audit carried out by makeadifference.digital, a consulting group that focuses on tech-for-good and non-profit products and services. They conducted interviews with everybody on the team, and concluded that we have a few key functions missing that were creating or compounding the stresses people felt.\nWe hope to make some of their key findings public soon (Update: this is now available at this blog post about the organizational report), and in the meantime here is an overview of some highlights:\nWe need a dedicated product functionality # First, we realized that we have a number of new “signals” pushing our service in many different directions. Some are external - from communities we work with or from funders. Some are internal - from different team member visions of where …","date":1698710400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1698710400,"objectID":"56a2060396fd8fc0261559080a80c3b2","permalink":"https://2i2c.org/blog/2023/2023-q3-update/","publishdate":"2023-10-31T00:00:00Z","relpermalink":"/blog/2023/2023-q3-update/","section":"blog","summary":"It’s been two quarters since our last major update - this isn’t quite as frequent as we’re hoping to post updates from our team, but we’re making adjustments to have more regular communication for reasons that will hopefully be a bit clearer below!","tags":[],"title":"Community update Q3 2023: Service growth and growing pains","type":"blog"},{"authors":["Chris Holdgraf"],"categories":null,"content":"We’re looking for a Product Lead who will be instrumental in shaping 2i2c’s product vision, strategy, and execution. You’ll own the product vision, align it with user needs, and translate it into a clear product roadmap which defines cross-functional priorities and guides our partnerships and engineering teams, enabling efficient product delivery and continuous improvement.\nFor more information and to apply, see our Greenhouse application page for this job.\n❌❌❌\nThis posting is closed to new applications.\nSee the jobs page for our open positions.\n❌❌❌\nAbout the position\nSalary: $95,000-125,000 Location: Remote, preference for working hours that maximizes overlap in time zones with the existing team (currently distributed from UTC-7 through UTC+3) Deadline: We will begin reviewing applications around November 5th, and will accept them on a rolling basis until the position is filled. Major duties\nDefine and own the product vision and strategy assuming ‘the voice of the user’, and doing so collaboratively and inclusively.\nCreate a clear product roadmap that guides the engineering and partnerships teams.\nCollaborate closely with our engineers and users in partner organizations to translate the product roadmap into actionable plans and tasks.\nFor more general information about 2i2c, see the links below:\nOur Team Compass Our Code of Conduct Our Mission and Values What it’s like to work at 2i2c Click here to Apply ","date":1698537600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1698537600,"objectID":"736fcc5a2324d7fcb50c9ab3612b5455","permalink":"https://2i2c.org/jobs/2023/product-lead/","publishdate":"2023-10-29T00:00:00Z","relpermalink":"/jobs/2023/product-lead/","section":"jobs","summary":"We’re looking for a Product Lead who will be instrumental in shaping 2i2c’s product vision, strategy, and execution. You’ll own the product vision, align it with user needs, and translate it into a clear product roadmap which defines cross-functional priorities and guides our partnerships and engineering teams, enabling efficient product delivery and continuous improvement.","tags":null,"title":"Product Lead","type":"jobs"},{"authors":["Chris Holdgraf"],"categories":null,"content":"Please see the Product Lead page.\n","date":1698537600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1698537600,"objectID":"35ad88621447764f761311ccc25df1ae","permalink":"https://2i2c.org/jobs/2023/product-operations-lead/","publishdate":"2023-10-29T00:00:00Z","relpermalink":"/jobs/2023/product-operations-lead/","section":"jobs","summary":"Please see the Product Lead page.","tags":null,"title":"Product Lead","type":"jobs"},{"authors":null,"categories":["impact"],"content":"","date":1698019200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1698019200,"objectID":"153b4965f46c0d39d10dfe43ea495ab5","permalink":"https://2i2c.org/blog/2023/external-unitefa-catalyst/","publishdate":"2023-10-23T00:00:00Z","relpermalink":"/blog/2023/external-unitefa-catalyst/","section":"blog","summary":"","tags":["bioscience","education"],"title":"UNITEFA forms the first community of the Catalyst Project at UNC, through the CCAD (in Spanish)","type":"blog"},{"authors":["Chris Holdgraf"],"categories":null,"content":"We’re looking for a Delivery Manager who will serve as a key facilitator in ensuring the successful and efficient delivery of our product. Acting as a servant leader, you’ll guide our engineering team, promote collaboration, and eliminate obstacles to deliver high-quality results that are aligned with our mission and goals.\nFor more information and to apply, see our Greenhouse application page for this job.\n❌❌❌\nThis posting is closed to new applications.\nSee the jobs page for our open positions.\n❌❌❌\nAbout the position\nSalary: $85,000 - $107,000 Location: Remote, preference for working hours that maximizes overlap in time zones with the existing team (currently distributed from UTC-7 through UTC+3) Deadline: We will begin reviewing applications around October 23rd, and will accept them on a rolling basis until the position is filled. Major duties\nEnsure the successful and efficient delivery of our product ( 2i2c.org/service/)\nOrganize and oversee cross-functional work across the team\nDetailed planning and day-to-day management of engineering tasks\nFor more general information about 2i2c, see the links below:\nOur Team Compass Our Code of Conduct Our Mission and Values What it’s like to work at 2i2c Click here to Apply ","date":1697155200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1697155200,"objectID":"fcf8bb83f949901857455696d58d36bf","permalink":"https://2i2c.org/jobs/2023/delivery-manager/","publishdate":"2023-10-13T00:00:00Z","relpermalink":"/jobs/2023/delivery-manager/","section":"jobs","summary":"We’re looking for a Delivery Manager who will serve as a key facilitator in ensuring the successful and efficient delivery of our product. Acting as a servant leader, you’ll guide our engineering team, promote collaboration, and eliminate obstacles to deliver high-quality results that are aligned with our mission and goals.","tags":null,"title":"Delivery Manager / Chief of Staff","type":"jobs"},{"authors":["Damián Avila"],"categories":null,"content":"We are looking for an experienced Open Source Infrastructure Engineer who will help shape the future of data-intensive scientific research and make a big impact on democratizing the design and access to cloud-based resources for research and education purposes. This engineer will be part of an awesome engineering team pushing forward the development and reliable operations of our cloud-based infrastructure.\nFor more information and to apply, see our Greenhouse application page for this job.\n❌❌❌\nThis posting is closed to new applications.\nSee the jobs page for our open positions.\n❌❌❌\nAbout the position\nSalary: $121,600 - $130,500 Location: Remote, required overlapping for US Pacific timezones Deadline: We will begin reviewing applications around October 16th, and will accept them on a rolling basis until the position is filled. Major duties\nCloud infrastructure management and operations\nSite Reliability Engineering\nDevelopment of open source infrastructure for hosted JupyterHub service\nFor more general information about 2i2c, see the links below:\nOur Team Compass Our Code of Conduct Our Mission and Values What it’s like to work at 2i2c Click here to Apply ","date":1696896e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1696896e3,"objectID":"6b65905fcd83c557ed5980f2cb93e8c8","permalink":"https://2i2c.org/jobs/2023/23qq4-open-source-infrastructure-engineer/","publishdate":"2023-10-10T00:00:00Z","relpermalink":"/jobs/2023/23qq4-open-source-infrastructure-engineer/","section":"jobs","summary":"We are looking for an experienced Open Source Infrastructure Engineer who will help shape the future of data-intensive scientific research and make a big impact on democratizing the design and access to cloud-based resources for research and education purposes.","tags":null,"title":"Open Source Infrastructure Engineer","type":"jobs"},{"authors":["Chris Holdgraf","Zack Adell"],"categories":["organization"],"content":"We are thrilled to announce a revitalized visual brand for 2i2c. As we continue to grow and evolve, it’s essential that our branding communicates who we are, what we stand for, and how we envision our future. We hope that this new design will unify our visual style across the many places where 2i2c operates.\nIn pursuit of these objectives, we teamed up with Zack Adell, a designer based in Nairobi who has worked with several similar projects over the years (having most-recently overhauled the Invest in Open Infrastructure brand design). After several rounds of brainstorming, design reviews, and fine-tuning, we’ve landed on a visual identity that resonates with our organization.\nMeet Our New Logo and design system # Zack has created a set of Brand Guidelines that will guide our use of color and visual style in 2i2c’s materials.\nBelow is our new logo in square and wide form:\nOur logo comprises the International Interactive Computing Collaboration wordmark, characterized by our interactive i. We can fly it just about anywhere. A mark of constant progress \u0026amp; community-driven technology, it isn’t stuck to the borders that separate people. It brings us closer together.\nOur primary and secondary color palette is below:\nColor is the first visual thing we remember and a powerful asset in building brand recognition. Our color is blue. Our community blue says the sky is not the limit. It’s energetic and vibrant, just like the community we serve. And it’s our primary colour, supported by a lively secondary palette that’s as at home on digital platforms as it is on billboards.\nWe’ve chosen two fonts to use in the majory of the text that we write. Poppins for big, bold sentences, and Work Sans for more versatile and everyday use.\nFinally, you might notice these curving, criss-crossing strands in some of our materials. For example, in our new social media header:\nThey’re the strands that intersect and show how our work and values are interconnected to our community. We like them because they represent 2i2c’s core mission, which is to build connections between people, computation, and data in order to share open knowledge. We’ll try and think of creative ways to incorporate them into our visual style.\nWe believe our new visual identity is more than just a fresh coat of paint. It’s a reaffirmation of our commitment to our stakeholders and an exciting milestone in our ongoing journey. We can’t wait for you to see it in action, and are excited to hear what you think about it!\n❗ Note\nIf you’d like to get in touch with Zack Adell, please reach out on his LinkedIn profile, or his Instagram account.\n","date":1694044800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1694044800,"objectID":"7f71c8ae3d34bd6f8c813b9ef11e46d4","permalink":"https://2i2c.org/blog/2023/new-design/","publishdate":"2023-09-07T00:00:00Z","relpermalink":"/blog/2023/new-design/","section":"blog","summary":"We are thrilled to announce a revitalized visual brand for 2i2c. As we continue to grow and evolve, it’s essential that our branding communicates who we are, what we stand for, and how we envision our future.","tags":[],"title":"A new design and logo for 2i2c","type":"blog"},{"authors":["Yuvi Panda","Jenny Wong"],"categories":["impact"],"content":" The QGreenland Researcher Workshop JupyterHub is a versatile platform that can serve a desktop with Geospatial Information Systems (GIS) software in the cloud. This was demonstrated by the QGreenland Researcher Workshop that was hosted by the NASA CryoCloud hub. The hands-on workshop trained 25-30 researchers, from Germany, India, France, Canada, Poland and the United States, on how to work with geospatial data in an open science framework.\nQGreenland Overview # QGreenland is an open-source geospatial data package designed for QGIS, a community-owned GIS platform. It focuses on Greenland, offering researchers and educators a comprehensive toolset for FAIR (findable, accessible, interoperable and reproducible) data analysis. The package integrates a variety of datasets into a single, easy-to-use data-viewing and analysis platform, supporting both offline and online use. This makes it particularly valuable for remote fieldwork and areas with limited internet access.\nWorkshop Success # The QGreenland workshop demonstrated several key benefits of using JupyterHub for cloud-based GIS:\nAccessibility: Participants from across the world could access the same powerful GIS tools through a web browser, eliminating the need for complex local installations while enhancing reproducibility Cloud block storage: Using a JupyterHub in the cloud allowed for faster data access than a traditional NFS file store by provisioning each user with an elastic block store disk, reducing load times from 5 minutes to under 3 seconds. Cost Efficiency: Utilizing the CryoCloud JupyterHub instance managed by 2i2c drastically cut down setup costs and time, with only minimal cloud operating expenses of roughly $1/person/day. Conclusion # The success of the QGreenland workshop underscores the potential of integrating interactive software applications in JupyterHub. This approach not only democratizes access to advanced geospatial tools but also fosters a collaborative research environment. We look forward to supporting more workshops for QGreenland in the future!\nWant to know more? Check out the companion post by QGreenland on the Jupyter Blog\nAcknowledgements # Trey Stafford (CIRES) Matthew Fisher (CIRES) *Fisher, M., *T. Stafford, T. Moon, and A. Thurber (2023). QGreenland (v3) [software], National Snow and Ice Data Center. Snow, Tasha, Millstein, Joanna, Scheick, Jessica, Sauthoff, Wilson, Leong, Wei Ji, Colliander, James, Pérez, Fernando, James Munroe, Felikson, Denis, Sutterley, Tyler, \u0026amp; Siegfried, Matthew. (2023). CryoCloud JupyterBook (2023.01.26). Zenodo. 10.5281/zenodo.7576602 * Denotes co-equal lead authorship\n","date":1691193600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1691193600,"objectID":"a40fcb60d6880359e5bd1920e68ae031","permalink":"https://2i2c.org/blog/2023/qgis-greenland/","publishdate":"2023-08-05T00:00:00Z","relpermalink":"/blog/2023/qgis-greenland/","section":"blog","summary":"The QGreenland Researcher Workshop JupyterHub is a versatile platform that can serve a desktop with Geospatial Information Systems (GIS) software in the cloud. This was demonstrated by the QGreenland Researcher Workshop that was hosted by the NASA CryoCloud hub.","tags":["geoscience","open source"],"title":"A QGIS desktop in the cloud with JupyterHub","type":"blog"},{"authors":["James Munroe"],"categories":null,"content":"2i2c manages, supports, and builds community-centric infrastructure for interactive computing in the cloud with partner communities in research and education.\nWe’re looking for a Technical Content Specialist that will create and curate documentation that supports interactive computing and cloud based open science. It intersects job titles such as “technical writer” and “content creator” while emphasizing previous experience working with open source science and related tools and a desire to share that knowledge.\n❌❌❌\nThis posting is closed to new applications.\nSee the jobs page for our open positions.\n❌❌❌\nAbout the position\nSalary: $75,000 - $85,000 Location: Fully remote Deadline: We will begin reviewing applications around August 2, 2023, and will accept them on a rolling basis until the position is filled. Major duties\nCreate documentation for cloud-based interactive computing.\nCurate documentation and resources from open source and open science projects.\nFor more general information about 2i2c, see the links below:\nOur Team Compass Our Code of Conduct Our Mission and Values What it’s like to work at 2i2c Click here to Apply If you’re interested in advancing your career at an impact-driven non-profit that is dedicated to open communities and public knowledge, then read on…\nAbout you… # Below are several skills that will make somebody well-suited for this role. You should apply even if you do not have all of these skills. We expect any new hires to learn and grow into this role over time. If you aren’t sure whether you have the right skills for this job, you should just apply! This is a fully remote role with a preference for working hours that overlap timezones with the existing team (currently distributed from UTC-7 through UTC+3).\nNecessary qualities # Demonstrated excellence in communicating complex technical information to learners with a different levels of background and experience Demonstrated experience in using open-science tools (e.g. Python or R) in a scientific or scholarly domain Willingness to continually learn and share emerging technologies and techniques in the interactive computing and open science ecosystems Useful qualities # Experience with open source workflows, research and educational contexts, and an understanding of the value that cloud-based infrastructure provides Experience with the Jupyter ecosystem and other tools for interactive computing Experience working with distributed service teams that use asynchronous methods of communication Experience collaborating and coordinating work via online platforms and distributed revision control Ability to communicate in Spanish, Portuguese, or French What you’ll do… # As a Technical Content Specialist, you’ll be responsible for…\nWorking as part of the 2i2c Partnerships Team towards Community Success Creating documentation (tutorials, how-tos, explainers, and reference materials) that are shared across our communities using cloud-based interactive computing Curating documentation resources from open source and open science projects Developing training materials for communities such as Version control for collaborative cloud-based workflows Environment management for hub administrators Best practices for analysis-ready cloud optimized data Assisting the 2i2c Engineering Team by editing technical documentation and documenting solutions from our support desk Authoring content for 2i2c for use in marketing, blog posts, and website copy. Our benefits and compensation # We believe it is important for mission-driven non-profits to also provide competitive benefits and compensation packages. See our compensation philosophy page for more information about our compensation and benefits.\nHow to apply # 2i2c is committed to hiring processes that are inclusive of people with many lived experiences and qualities. We try to structure our hiring process so that it is predictable, doesn’t take too long, and doesn’t take too much effort.\nIf you’d like to apply for this position, please upload your resume and cover letter using this application form. We will begin reviewing applications after August 2, 2023 and will fill this position on a rolling basis once we find a candidate with the right fit for the job.\n","date":168912e4,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":168912e4,"objectID":"b55c651cd683fdce6e20940d91bbdaf8","permalink":"https://2i2c.org/jobs/2023/technical-content-specialist/","publishdate":"2023-07-12T00:00:00Z","relpermalink":"/jobs/2023/technical-content-specialist/","section":"jobs","summary":"2i2c manages, supports, and builds community-centric infrastructure for interactive computing in the cloud with partner communities in research and education.\nWe’re looking for a Technical Content Specialist that will create and curate documentation that supports interactive computing and cloud based open science.","tags":null,"title":"Technical Content Specialist","type":"jobs"},{"authors":["Georgiana Dolocan"],"categories":["impact"],"content":"","date":1688083200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1688083200,"objectID":"8c280e2adecd7cb1b2b85030e5aa725a","permalink":"https://2i2c.org/blog/2023/external-jupyter-georgiana-mentor/","publishdate":"2023-06-30T00:00:00Z","relpermalink":"/blog/2023/external-jupyter-georgiana-mentor/","section":"blog","summary":"","tags":["open source"],"title":"On the Jupyter Blog: From intern to mentor.","type":"blog"},{"authors":["Chris Holdgraf"],"categories":["organization"],"content":"It’s a month after the end of Q1 2023, and we’d like to share a belated update about what we were up to in the first quarter of this year (we have good excuses for being late, including new tiny humans, I promise).\nThis quarter we grew our engineering team significantly, and started to refine our team processes and structures to accommodate this extra complexity. We expanded our managed cloud service with new community partners, and made a number of improvements to our technical infrastructure and organizational processes for managing this service.\nRead on below to learn more about what we’ve been up to!\nNew community partnerships # We added several new community partnerships to our managed hub service. We’ve deployed new hub infrastructure for each of the following groups:\nOur University of Toronto Jupyter service now has a dedicated R hub. We ran an event hub for the Drakkar Ocean project We deployed a hub for the NASA Visuaslization Exploration and Data Analysis (VEDA) project. We deployed a hub for the QuantifiedCarbon organization. We ran an event hub for OceanHackWeek 2023. We onboarded several new community colleges to our “JupyterHubs Education in Community Colleges” collaboration with CloudBank and UC Berkeley CDSS. Service improvements # Below are a few highlights for ways in which we improved our Managed Cloud Service for our partner communities.\nWe simplified our authentication workflow with CILogon # Authentication services allow us to identify a user when they log onto a hub, which determines their ability to access hub resources. Previously we had used a combination of Auth0, CILogon, or GitHub for authentication.\nHowever, over the past year we’ve been happy with our use of CILogon so far, especially because of its non-profit status and alignment with many research and education institutions that we work with. This quarter, we decided to streamline our authentication process by dropping the use of Auth0 and grow our partnership with CILogon.\n💡 Learn more\nSee CILogon’s write up about it’s partnership with 2i2c See our blog post about our use of CILogon We exposed user activity dashboards in JupyterHub so communities know how many people are using the service # We tend to work with leaders of communities that utilize our service and infrastructure for many others in their network. For example, a teacher with a classroom of students, or a researcher with a global network of collaborators.\nIn these cases, it’s useful to track how many users are actively using a platform over various metrics of time. This can tell you whether your community finds a service useful, and whether this is growing or shrinking.\nWe use Grafana to automatically generate dashboards of activity for all of our community hubs and clusters. However, tracking daily, weekly, and monthly active users was not part of JupyterHub’s core functionality.\nSo, we decided to upstream this functionality into JupyterHub and expose it via the JupyterHub Grafana project. All 2i2c hubs now track daily, weekly, and monthly unique active users. And importantly, anybody else deploying the Zero to JupyterHub for Kubernetes can use this feature now too.\n💡 Learn more\nSee Yuvi’s blog post about this feature.\nWe made our support process more structured with a new support widget # We’ve added a support widget to our service documentation site. This will allow users to provide structured support requests directly to our team, allowing us to triage and respond more quickly.\nHere’s our support button and widget in action:\nOur fancy new support button! We upgraded Kubernetes across all of our AWS clusters # Kubernetes is at the core of our cloud infrastructure and scalability. We use either a shared or a dedicated Kubernetes cluster for each of our community partners, and it is the foundation upon which all of their Jupyter infrastructure rests.\nOne of the biggest challenges with managing an ongoing cloud service is keeping the underlying infrastructure upgraded. This brings in new stability and functionality, but also often involves manual steps and toil. This quarter, we upgraded each of our AWS JupyterHubs to Kubernetes 1.24 and will continue this effort with other providers in the coming quarters.\nWe streamlined our hub uptime checks to be more efficient # The best kinds of failures are ones that your operations team recognizes and solves before any users run into the problem themselves. We use the Google Cloud Platform HTTP uptime checker to run regular uptime checks for each of the community hubs that we use. This allows us to get quick alerts if any of our community hubs is down for some reason.\nWe made several optimizations to this process so that we can more efficiently monitor hub uptime and trigger alerts to our engineering team if action is needed.\nOrganizational updates # We made a number of broader improvements to our team processes and policies, and even got a shout-out from a few community partners!\nWe defined organizational principles …","date":168264e4,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":168264e4,"objectID":"837ca10f75690da78e1f6c20c1eef6d2","permalink":"https://2i2c.org/blog/2023/2023-q1-update/","publishdate":"2023-04-28T00:00:00Z","relpermalink":"/blog/2023/2023-q1-update/","section":"blog","summary":"It’s a month after the end of Q1 2023, and we’d like to share a belated update about what we were up to in the first quarter of this year (we have good excuses for being late, including new tiny humans, I promise).","tags":[],"title":"Community update Q1 2023: Growing our community partner network and our team","type":"blog"},{"authors":["Georgiana Dolocan"],"categories":["impact"],"content":" About CILogon # CILogon is an open source service provider that allows users to log in against over 4000 various identity providers, including campus identity providers. The available identity providers are members of InCommon, a federation of universities and other organizations that provide single sign-on access to various resources.\nCILogon and 2i2c # For the past year, 2i2c has been successfully using CILogon for more than fifteen of the hubs it manages.\nCurrently, most of the hubs that use it are hubs for communities in education that want to manage their hub access through their own institutional providers.\nWith using a tool like CILogon, we allow hub access to be managed both through the communities’ institutional providers, but also through social providers like GitHub and Google. Because both authentication mechanisms can coexist, there’s no need to provide specific credentials for 2i2c staff in order to have access to the hub. This reduces both the burden on institution’s IT departments, but also the complexity of a hub deployment.\nMoreover, as we migrate away from our current Auth0 setup, the number of hubs using CILogon will further increase in the following year.\nThe setup # The setup that 2i2c uses, is based on two important tools, the CILogon administrative client and the JupyterHub CILogonOAuthenticator.\nThe CILogon administrative client # The 2i2c administrative client provided by CILogon allowed us to automatically manage the CILogon OAuth applications needed for authenticating into the hub.\nFor each hub that uses CILogon, we dynamically create an OAuth client application in CILogon and store the credentials safely, using the script at cilogon_app.py. The script can also used for updating the callback URLs of an existing OAuth application, deleting a CILogon OAuth application when a hub is removed or changes authentication methods, getting details about an existing OAuth application, getting all existing 2i2c CILogon OAuth applications.\nThe JupyterHub CILogonOAuthenticator # For CILogon’s integration with JupyterHub’s authentication workflow, we’re using the CILogonOAuthenticator, which is part of the JupyterHub OAuthenticator project. This is what allows JupyterHub to use common OAuth providers for authentication, and it’s also a base for writing other Authenticators with any OAuth 2.0 provider.\nAs part of this 2i2c integration with the JupyterHub CILogonOAuthenticator some important upstream fixes and enhancements to the oauthenticator were identified and performed. For example, the GHSA-r7v4-jwx9-wx43 vulnerability was reported and fixed, and a migration guide containing a description of the breaking changes that were made, together with a step by step guide for the users on how to update their usage of JupyterHub CILogonOAuthenticator was provided.\nRead more about how CILogon is setup for use at 2i2c from the docs.\nCelebration # Thanks to the 2i2c - CILogon partnership, during this past year we were able to integrate CILogon into 2i2c’s infrastructure and to observe its importance, usefulness and great support for 2i2c and the communities we server.\nWe are now happy to announce that the 2i2c - CILogon partnership has been expanded to another year!\nAcknowledgements: The upstream jupyterhub-oauthenticator project mentioned in this post as being used at 2i2c is a JupyterHub package, kindly developed and maintained by the JupyterHub community and the 2i2c integration described was developed by the 2i2c engineering team. Also, this post was edited by Jim Basney.\n","date":1677196800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1677196800,"objectID":"ddff52adb91f9fcfcb7d4985bc349b33","permalink":"https://2i2c.org/blog/2023/cilogon-integration/","publishdate":"2023-02-24T00:00:00Z","relpermalink":"/blog/2023/cilogon-integration/","section":"blog","summary":"The following is a summary of how CILogon is used at 2i2c, how the integration works and a celebration of the partnership.","tags":["open source"],"title":"CILogon usage at 2i2c","type":"blog"},{"authors":["Chris Holdgraf"],"categories":["organization"],"content":"This is a brainstorm to consider the principles and guidelines that 2i2c should follow in defining its strategy towards open source communities. See our open source policy documentation for the product of this brainstorm.\nOver the past year the 2i2c team has focused its efforts on deploying, configuring, running, and managing cloud infrastructure that supports open source workflows in research and education. We’ve also done a lot of upstream contribution as a part of our work.\nHowever, we have shied away from taking direct funding for direct development work in open source projects. This is for two primary reasons:\nOur focus has been on managing cloud infrastructure, not developing it. We want to facilitate access to open workflows in interactive computing, which is a different skillset and kind of work than creating those tools. While 2i2c is aligned with the interests of open communities, we are still a distinct organization with our own mission and strategy. We want to be conscious that 2i2c team members have more than one hat, and that their 2i2c hat is necessarily not the same thing as their open source hat. As such, we don’t want to leverage our “other hats” to drive resources to 2i2c without being thoughtful about it. In the last year we’ve found that running infrastructure for research and education gives us great visibility into the kinds of things that these communities want to do, and ways to improve the infrastructure. It also means we can potentially be a conduit of resources from those communities into open source development workflows. For example, we recently partnered with GESIS to make improvements in Binder and JupyterHub.\nSo, this post is a brainstorm to identify some of the major considerations that we should take before agreeing to this kind of work. Its goals is to drive policy that streamlines our ability to seek and accept funding for open source work. It tries to answer this question:\nHow can a stakeholder accept funding on behalf of an open source community in a way that is inclusive, equitable, and effective.\nSome assumptions # First off I want to note that this only applies to open source projects that I’d call “Open communities”. For example, those that follow the principles of open scholarly infrastructure. The ideas here don’t apply to open source projects that are run by single organizations or people. You can assume I’m talking about projects that:\nHave inclusive multi-stakeholder governance and operations. Care about having a broad contributor and leadership base, and want to follow best-practices in inclusive and equitable operations. Need funding to drive major new efforts, or to sustain pre-existing maintenance and community management work. Why is this important? In short, because open projects should care about good governance, and about building sustainable and diverse multi-stakeholder communities around their operations and strategy. While it’s easy to ignore these considerations and just bring in money however you can (open source is perpetually under-funded, after all), it’s crucial that we think about how to do so in a way that aligns with the values of open communities, and that doesn’t simply propagate a “rich get richer” dynamic. Ultimately, the unique value of open communities is not in the technology they create, but in the way that they create it.\ntl;dr: An overview of major considerations # After working with several open source projects over the years, there are a few issues that I’ve seen come up again and again. Here’s a quick summary and I’ll note each in more detail below.\nGovernance: funding should follow major decisions, not make them. It should represent the interests of the project rather than those of a single stakeholder or payer. Transparency: stakeholders that accept funding should be transparent in their accounting (the sources of funding, deliverables attached with it, and operational costs), their plans (the work they plan to do and how they want to do it) and in their strategy (the reason they’re applying for funding in the first place, and how the work fits in with their other operations). Accountability: stakeholders that accept funding should be accountable to the open communities that they are supporting. There should be mechanisms for open communities to provide feedback about and influence their operations, ideally in a powerful position like a board seat. Equity: funding should be shared with others in the project, particularly those that need it or that couldn’t get funding on their own. Moreover, people should be paid for their time - if funding requires work from others, they should be compensated somehow. Inclusion: funding opportunities should be shared with others in a project, particularly those from historically disadvantaged communities. Stakeholders with funding “connections” should use them to boost others in the community as partners, not just as contractors Here is a more in-depth discussion of each below.\nGovernance: …","date":1673136e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673136e3,"objectID":"cb1504c087ebf49007ba3a9d79b5b280","permalink":"https://2i2c.org/blog/2023/open-source-funding-principles/","publishdate":"2023-01-08T00:00:00Z","relpermalink":"/blog/2023/open-source-funding-principles/","section":"blog","summary":"This is a brainstorm to consider the principles and guidelines that 2i2c should follow in defining its strategy towards open source communities. See our open source policy documentation for the product of this brainstorm.","tags":["funding","community","open culture","sustainability"],"title":"Principles and considerations for ethically accepting funding for open source","type":"blog"},{"authors":["Chris Holdgraf"],"categories":["organization"],"content":"2022 was a busy year for 2i2c - we not only grew our operations as well as our organization, but also grew our understanding of our mission and where we can have impact. This is a brief reflection on this experience, and an attempt to identify our opportunities for impact and growth in 2023.\nOur major goals in 2022 # We wrapped up 2021 with two major new changes. We had just finished moving fiscal sponsors and had just finished a prototype of our alpha service offerings.\nOur 2x2 matrix of service offerings and prices created at the end of 2021. See the documentation for more details. Our biggest challenge in 2022 was to identify the bottlenecks in this service model, and to begin building the infrastructure to operate and scale it. This included team infrastructure, technical infrastructure, and administrative infrastructure.\nLet’s see what we did to accomplish this goal.\nHighlights from 2022 # In 2022, we thoughtfully grew the number of communities we worked with, and used this to make iterative improvements in our model. As a result, we learned some important things and made significant improvements to our service model and infrastructure. Here are a few highlights.\nWe grew the number of our partner communities # As noted above, we needed to grow the number and diversity of communities we worked with to understand where our model needed to change. At the end of 2022, we now have 43 community partner hubs across 17 clusters (and at least one on AWS, Azure, and Google Cloud). This amounts to roughly ~2,500 active users each week. We also ran more dedicated infrastructure for more than 11 workshops and events.\nWe grew our revenue from community partnerships # One of our goals is to reach self-sustainability without requiring grant funding for most of the communities we serve. In 2022 we built administrative infrastructure to more efficiently recover monthly costs, and were able to bring in funding for our team from community partnerships. Here’s a plot of our monthly non-grant revenue over the last several months:\nOur monthly non-grant revenue over the last several months. June is much larger because we filled a backlog of invoices from previous months that weren’t billed yet. We got grant funding to serve communities in Latin America and Africa # We also learned that some partnerships may require subsidization from a third party, such as historically marginalized communities and those without dedicated resources. To explore sustainable ways to serve these communities, we applied for and received a new grant to serve communities in Latin America and Africa! Here’s the blog post announcing this grant and our open grant narrative from the proposal.\nWe improved our continuous integration and deployment system # Our ability to sustainably grow our service requires being able to technically serve many communities from a relatively small team. We centralized and standardized configuration and operations of many community hubs in one transparent space for all of our partner communities. This allowed us to more easily grow the number of communities we served from one repository. You can read a write-up about these improvements in this blog post.\nWe defined a Shared Responsibility Model # Our goal is to frame each community hub as a partnership with a clear breakdown of responsibility to give communities more agency over the infrastructure and service. The Shared Responsibility Model provides a framework for assigning responsibility for various tasks with our partner communities. See our Shared Responsibility Model docs here.\nWe defined a formal Incident Response process # Cloud infrastructure inevitably degrades over time, and running ongoing services is largely about quickly responding to issues and resolving them quickly. To do so, we need clear processes to follow in order to quickly identify and respond to major incidents in the infrastructure. Our Incident Response process defines formal team roles and alerting mechanisms that are served by PagerDuty, following best-practices in industry. This will make our service more reliable and make our processes more transparent for our partner communities. Here’s our current incident response process.\nWe expanded our service offerings to include community and workflow guidance # We recognized that many communities need more than just infrastructure running in the cloud - they will also benefit from usecase and community guidance. We’re exploring a new range of roles that we could fill, starting with hiring a new team member to help us lead these efforts. Here’s a blog post about the Product and Community Lead.\nWe began a collaboration with GESIS to develop environment building in JupyterHub # This marks our first efforts into development-focused work as opposed to operating cloud infrastructure. We will use this experience to learn how to pair focused development with cloud operations (more on that below). It will also make it more likely that we can implement …","date":1672790400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672790400,"objectID":"c0e3dbdaffd9239e9fd35b5e05629012","permalink":"https://2i2c.org/blog/2023/2022-year-in-review/","publishdate":"2023-01-04T00:00:00Z","relpermalink":"/blog/2023/2022-year-in-review/","section":"blog","summary":"2022 was a busy year for 2i2c - we not only grew our operations as well as our organization, but also grew our understanding of our mission and where we can have impact.","tags":["year-in-review"],"title":"2022 in review: growing our partner communities and expanding our operations","type":"blog"},{"authors":["Chris Holdgraf"],"categories":["impact"],"content":"We are excited to announce that the team and proposal described in this blog post has been awarded funding by the Chan Zuckerberg Initiative!\nThis announcement may be cross-posted on the websites of several collaborating organizations of this grant. Para leer este post en español, vea el blog de MetaDocencia.\nOur goal is to create a collaborative cloud infrastructure service that enables community-based cloud-native workflows in the biosciences. We will promote values of open and inclusive community practices, infrastructure that enables these practices, and a “train the trainers” approach that empowers community leaders to share expertise in cloud infrastructure with others in their communities. Our focus will be on communities in Latin America and Africa, and we hope to learn how this model could be extended to other global communities that are historically marginalized from large-scale scientific infrastructure projects.\n2i2c will be providing cloud infrastructure operation and support for the communities that we partner with in this effort. We will also assist with creating content to teach cloud-native workflows and assist community leaders in learning this content so that they can share these skills with others.\nThis is a collaborative effort between 2i2c, The Carpentries, CSCCE, Invest in Open Infrastructure, MetaDocencia, and Open Life Science. For more detailed information, see the blog post with our full grant narrative.\nWe are hiring # As a part of this effort, we will also hire several new team members! There are currently two job postings open. Here are links for more information in case you are interested:\nCloud infrastructure engineer to join 2i2c’s Site Reliability Engineering team that will operate and support the cloud infrastructure in this project. Programme manager role to join Open Life Science and support this project via project management and operational support. We may be hiring other positions related to this effort, so please stay tuned for more information if you are interested.\nWhere to follow along # If you’d like to follow along with this work, please share your e-mail address in this short form. We’ll send updates as we work out longer-term spaces for communication or documentation.\n💡 Follow our work! Sign up for our mailing list for updates about 2i2c. Send us an e-mail about collaborating or partnering on a project. See our Service Documentation or our Team Compass to learn about our service and organization.\n","date":1671494400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1671494400,"objectID":"26124d90c14d8aa219d01a1a27ef7a9b","permalink":"https://2i2c.org/blog/2022/czi-global-communities-announcement/","publishdate":"2022-12-20T00:00:00Z","relpermalink":"/blog/2022/czi-global-communities-announcement/","section":"blog","summary":"We are excited to announce that the team and proposal described in this blog post has been awarded funding by the Chan Zuckerberg Initiative!\nThis announcement may be cross-posted on the websites of several collaborating organizations of this grant.","tags":["bioscience"],"title":"New project: Open science cloud infrastructure and training for communities in Latin America and Africa","type":"blog"},{"authors":["Damián Avila","Arnim Bleier","Chris Holdgraf"],"categories":["impact"],"content":" Introduction # Mybinder.org enables researchers across the world to replicate computational environments in the cloud. It allows researchers to turn static code into interactive literate coding environments with a click of a button within seconds. The mybinder.org service is powered by BinderHub, an open-source tool developed by the Jupyter Project that many organizations have deployed for their own communities. It does this by _dynamically building _the software environment needed to reproduce a computation (using a tool called repo2docker), and making this environment available to users.\nBinderHub was developed for use-cases that are temporary and fully open by design. BinderHub sessions are destroyed after a fixed amount of time and there is no persistent storage or authentication. However, many research institutions also need more “standard” service features like authentication and persistent storage.\nOver the past several years, the GESIS Notebooks team made the first steps towards bridging this gap through their Persistent BinderHub implementation. This was a modified and authenticated BinderHub that included persistent storage across sessions. The Persistent BinderHub service was very successful at GESIS and with its partner communities, and the team wishes to build this functionality into the JupyterHub community’s core technology so that these features can be enjoyed for more use-cases and by many communities.\nTo enable this vision, we have partnered with GESIS in cooperation with NFDI4DS (GAN: 460234259), CESSDA, and members of the JMTE project. This collaboration has three primary goals:\nGeneralize the Persistent BinderHub functionality/experience to run on cloud-agnostic infrastructure, so that other stakeholders in NFDI, CESSDA, and the broader scientific community may benefit from this functionality and experience. Upstream this functionality by making contributions into Jupyter community projects, so that it will be maintained and improved by a community moving forward, thus improving its reliability and sustainability. Improve the implementation and user experience around Persistent BinderHub, in order to make it more reliable, scalable, productive, and enjoyable to use. We began this collaboration several months ago, and have focused our efforts on exploring potential implementation pathways for this functionality. We believe that we now have a path forward for this functionality, and this blog post is a brief report of our efforts and future plans as we undertake this effort. See this GitHub Projects Board for issues that implement this effort.\nExploration 1: Adding persistent storage directly into BinderHub # Our initial intention was to incorporate persistent storage and authentication from the GESIS Persistent BinderHub into the BinderHub codebase. We began by holding a series of meetings to discuss technical requirements from our experience in the JupyterHub/BinderHub ecosystem, and also conducted an audit of the Persistent BinderHub codebase. The Persistent BinderHub implementation is a modified Helm Chart that configures a JupyterHub to expose its authentication and persistent storage functionality, overriding the BinderHub default behavior. We were concerned that building this functionality natively into BinderHub would be challenging given that the BinderHub codebase was designed for ephemeral user sessions.\nSo, we decided to take another approach:\nExploration 2: Add dynamic image building to JupyterHub # We realized that there is a way to make this functionality more broadly useful and more maintainable, while still achieving the end-user experience that the GESIS team needed. Instead of modifying BinderHub to incorporate JupyterHub’s storage and authentication features, we would give JupyterHub the ability do dynamically generate user environments using repo2docker.\nThis would give JupyterHub users more flexibility over the environments served by their hub, and expose Binder-style workflows to the “typical” JupyterHub workflow. BinderHub could then be simplified to re-use JupyterHub’s image building functionality as a part of its own service. We also identified a prototype of this functionality in the tljh-repo2docker project that QuantStack had built for the PlasmaBio project. This implementation was seen as successful, and something others in the community had wanted to generalize for some time.\nOur implementation plan # Two phases of implementation # With this alternative implementation route in place, we identified two major steps to accomplish this project:\nBuild a back-end for dynamic environment building. JupyterHub needs to understand how to call repo2docker’s image generation from a Docker-based environment. It needs to expose this ability via APIs that others can build interfaces on top of. **Build a front-end that is user-friendly and accessible. **Once the back-end is functional, we must build a front-end experience that feels familiar to BinderHub users and is easy …","date":1669593600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1669593600,"objectID":"6a55a575b40906e55bc3821000992da8","permalink":"https://2i2c.org/blog/2022/gesis-2i2c-collaboration-update/","publishdate":"2022-11-28T00:00:00Z","relpermalink":"/blog/2022/gesis-2i2c-collaboration-update/","section":"blog","summary":"Introduction # Mybinder.org enables researchers across the world to replicate computational environments in the cloud. It allows researchers to turn static code into interactive literate coding environments with a click of a button within seconds.","tags":["open source"],"title":"GESIS - 2i2c collaborate to build a persistent BinderHub experience","type":"blog"},{"authors":null,"categories":["impact"],"content":"","date":1668643200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1668643200,"objectID":"523058533978aea593ad3f2396e2decc","permalink":"https://2i2c.org/blog/2022/external-openscapes-corn/","publishdate":"2022-11-17T00:00:00Z","relpermalink":"/blog/2022/external-openscapes-corn/","section":"blog","summary":"","tags":["geoscience","open source"],"title":"The why, what, and how of our NASA Openscapes cloud infrastructure: 2i2c JupyterHub and corn environment","type":"blog"},{"authors":["Chris Holdgraf"],"categories":["impact"],"content":"We recently completed a progress report for Year 2 of our primary CZI funding grant. This funding covers some core operations of 2i2c as well as engineering capacity to run our cloud infrastructure for JupyterHubs.\nBelow is a link to the 3-page grant narrative that summarizes some of our major progress and milestones from year two:\nzenodo.org/record/7319289\n","date":1668297600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1668297600,"objectID":"fdb1d1be20547d95ad76ddc8a5154853","permalink":"https://2i2c.org/blog/2022/czi-year2-progress-report/","publishdate":"2022-11-13T00:00:00Z","relpermalink":"/blog/2022/czi-year2-progress-report/","section":"blog","summary":"We recently completed a progress report for Year 2 of our primary CZI funding grant. This funding covers some core operations of 2i2c as well as engineering capacity to run our cloud infrastructure for JupyterHubs.","tags":["bioscience"],"title":"Grant progress report: CZI Foundational grant year 2","type":"blog"},{"authors":["Chris Holdgraf"],"categories":["organization"],"content":"Quarter 3 of 2022 has wrapped up, and the 2i2c team has been busy making improvements across our infrastructure, organization, and operations. This is a quick post to celebrate the work we’ve done over the past three months, and to briefly share what we’re working on next.\nBelow we’ll provide a brief update about major developments this quarter, broken down by functional areas of 2i2c.\nThese are the main highlights from this quarter - if you’d like to check out more of the work that we’ve done, see:\nAll the PRs we’ve merged in Q3\nAll closed issues in Q3\nCommunity impact # These are a few ways in which we’ve collaborated with communities and demonstrated impact over the last few months.\nNew JupyterHubs for communities. We’ve deployed JupyterHubs for several new partner communities. Here’s a quick list:\nPaleoCube and PaleoHack Hubs infrastructure#1418 NeuroHackademy 2022 infrastructure#1505 Alabama Water Institute CIROH hub infrastructure#1444 OceanHackWeek 2022 infrastructure#1515 COESSING Pangeo-Style Hub infrastructure#1516 Temple University Education Hub infrastructure#1648 Callysto Hub infrastructure#1439 London Interdisciplinary School infrastructure#1485 We also ran hubs for several community events:\nNeuroHackademy: infrastructure#1300 OceanHackWeek 2022 infrastructure#1576 COESSING workshop: infrastructure#1516 Eddy Symposium: infrastructure#467 Allen Institute Summer Workshop on the Dynamic Brain infrastructure#1621 For a recap of one of these events, see our recent blog post on the Jack Eddy symposium.\nIf you are interested in partnering with 2i2c to have your own managed JupyterHub, please contact us at partnerships@2i2c.org. We have a shared cluster on Google Cloud, with plans to deploy one on AWS soon, and dedicated clusters can be run on any major cloud provider. Please see our service documentation for more details.\nOrganization wide updates # These are large-scale organizational and strategic efforts that impact all of 2i2c.\nWe applied for a CZI Grant: In partership with The Carpentries, CSCCE, MetaDocencia, Invest in Open Infrastructure, and OpenLifeScience, we applied for a CZI grant to provide cloud infrastructure services to global communities.\nWe grew our team: We’ve hired two new team members to lead new major efforts with 2i2c. James Munroe will lead efforts around community guidance and product design, and Jim Colliander will lead efforts around partnerships and sustainability. We also updated our Hiring and Candidate Search documentation in the process.\nWe’re refining our strategy: We’ve begun a process of revisiting and refining our strategy after a year of major operations, see our strategic update blog post for more information.\nWe completed the CSCCE community management training. Two of our team members (James and Sarah) both completed a several-week community management course that was offered in partnership with CZI.\nOur team member Sarah began a part-time role as the JupyterHub Community Strategic Lead. Sarah will be leading community strategy efforts within JupyterHub for the next two years thanks to a grant to the JupyterHub team from CZI. Check out this issue to follow our progress.\nService improvements # We made a number of improvements to our cloud infrastructure and the processes around our service. Here’s a brief breakdown:\nWe expanded our shared clusters to new cloud providers and regions. We now have shared clusters already deployed on Google Cloud Platform on us-central1-b and europe-west2.\nWe defined an incident commander process. This will allow us to coordinate and respond to major outages in our cloud infrastructure more efficiently. See our incident response documentation for more information.\nWe improved our cloud usage monitoring infrastructure. We’ve deployed a centralized Grafana Dashboard that aggregates cloud usage across all of our partner communities, and allows us to keep track of any unexpected behavior or outages across them all.\nWhere we’re focusing next # In the final quarter of this year, we’ve decided to focus our efforts on growing capacity across all of the aspects of our team. Now that we have brought on several more partner communities into our Managed JupyterHub Service, it has shown us where we have bottlenecks in our technology, process, and structure. In 2023 we hope to significantly grow the number of communities we work with, and so we must grow our capacity to be able to take on these new partnerships.\nWe aim to accomplish this in a few ways:\nMake technical improvements to our cloud infrastructure that reduces the amount of human labor associated with regular actions. This will make our cloud infrastructure more scalable and reliable. Improve our invoicing and partnership leads pipeline so that we can reduce the amount of administrative toil for ourselves and for the communities we work with in billing and cloud cost pass-through. Refine our organizational strategy and structure so that we are better-able to agree on our most important …","date":1665878400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1665878400,"objectID":"034121fa0c6758b2d545cbf6ae5d813c","permalink":"https://2i2c.org/blog/2022/q3-update/","publishdate":"2022-10-16T00:00:00Z","relpermalink":"/blog/2022/q3-update/","section":"blog","summary":"Quarter 3 of 2022 has wrapped up, and the 2i2c team has been busy making improvements across our infrastructure, organization, and operations. This is a quick post to celebrate the work we’ve done over the past three months, and to briefly share what we’re working on next.","tags":[],"title":"Celebrating our progress in Q3 2022","type":"blog"},{"authors":["Damián Avila"],"categories":null,"content":"2i2c manages, supports, and builds community-centric infrastructure for interactive computing in the cloud with partner communities in research and education.\nWe’re looking for an Open Source Infrastructure Engineer that will join our Site Reliability Engineering team and make our cloud infrastructure more reliable, scalable, and efficient. It will help build a future of data-intensive scientific research and democratize the design and access to cloud-based resources for research and education purposes.\nIf you’re interested, learn more about 2i2c at the links below, and more about this job posting on the rest of this page.\n❌❌❌\nThis posting is closed to new applications.\nSee the jobs page for our open positions.\n❌❌❌\nAbout the position\nSalary: $120,000 - $135,000 Location: preferred at the US/Pacific time zone Deadline: We will begin reviewing applications around November 17th, and will accept them on a rolling basis until the position is filled. Major duties\nSite Reliability Engineering\nCloud infrastructure management, operations, and support.\nDevelopment of open source infrastructure for hosted JupyterHub service\nFor more general information about 2i2c, see the links below:\nOur Team Compass Our Code of Conduct Our Mission and Values What it’s like to work at 2i2c Click here to Apply Who we are # 2i2c is a non-profit organization with a mission to make interactive computing more accessible, scalable, and powerful for research and education: 2i2c.org/organization/.\nWe accomplish this mission by providing managed cloud services for interactive computing, by providing development and technical leadership to researchers and educators that utilize this infrastructure for specific communities, and by providing support for open source tools and communities in this ecosystem.\nWe have deep ties to the open source community, and have been leaders and core contributors across dozens of projects - in particular in the Jupyter ecosystem. We also have deep ties to research and education - our team has spent years deploying infrastructure for universities, community colleges, and research teams, and now we’re bringing this experience to a wider audience with 2i2c.\nWe believe strongly in communities that are inclusive, transparent, equitable, effective, and diverse, especially 2i2c itself. We believe that our values should permeate everything about 2i2c, including the work we do, the communities we serve, and our own organizational culture.\n2i2c is a fiscally sponsored project of Code for Science and Society, a registered US 501(c)(3) nonprofit corporation.\nWhat you’ll do # Ensure the reliable operation of the 2i2c infrastructure (leveraging production-ready cloud-based tools such as JupyterHub, BinderHub and Dask). Address support issues Explore emerging technologies in the Cloud / DevOps space, design and implement cloud computing architecture in partnership with our team. Participate in upstream open source communities we rely on (such as JupyterHub, BinderHub, Dask, etc) in partnership with the established leaders of those communities and collaborate with the Community Lead in the education and outreach around cloud computing. Work with a distributed and global team - team members are given a lot of autonomy, and expected to be proactive at communicating with one another and working with others to allocate effort that will maximize our impact. Essential requirements # Experience deploying applications on cloud infrastructure. Experience deploying and developing with Linux container-based technologies, such as Docker and Kubernetes. Experience with continuous integration services (e.g. Circle CI, GitHub workflows). Experience developing tools in a general purpose programming language (eg. Python). Experience collaborating and coordinating work via online platforms, such as GitHub, GitLab, or BitBucket, and distributed revision control. Experience working with distributed service teams that use asynchronous methods of communication Desirable requirements # Experience with major cloud providers. Experience in programming and software engineering with a track record of leadership in open, collaborative projects with broad community adoption. Experience working on geographically distributed open-source projects. Experience with the Jupyter ecosystem and other tools for interactive computing. Evidence of existing connections and relationships in the worldwide ecosystem of open source software for data-intensive research and ability to establish new ones. Experience with common data science methods, platforms, workflows, and infrastructures; with data management systems, practices, and standards; and the capacity to gain familiarity with new related topics. Experience engaging with highly technical researchers across a variety of methodological fields, research domains, and computational platforms. Experience building and maintaining continuous deployment pipelines. Interpersonal skills to work with researchers and students, …","date":1665705600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1665705600,"objectID":"fadeab2639f3679bd21677cc03d303a3","permalink":"https://2i2c.org/jobs/2022/open-source-infrastructure-engineer/","publishdate":"2022-10-14T00:00:00Z","relpermalink":"/jobs/2022/open-source-infrastructure-engineer/","section":"jobs","summary":"2i2c manages, supports, and builds community-centric infrastructure for interactive computing in the cloud with partner communities in research and education.\nWe’re looking for an Open Source Infrastructure Engineer that will join our Site Reliability Engineering team and make our cloud infrastructure more reliable, scalable, and efficient.","tags":null,"title":"Open Source Infrastructure Engineer: Site Reliability Engineering and Cloud Infrastructure","type":"jobs"},{"authors":["Chris Holdgraf"],"categories":["organization"],"content":"This post is an exploration of 2i2c’s current strategy and direction after a year of major operations. It is a brainstorm from the Executive Director, shared as a blog post to invite feedback and provide transparency into our current thinking. Its goal is to explore the context of 2i2c’s stakeholders and their needs, and identify an opportunity and plan for having a positive impact with these communities. It is not a concrete proposal but a snapshot of thinking in time meant to trigger reflection. Over time we will incorporate some of these ideas into our Team Compass.\nWhen we founded 2i2c, we largely did so from the “bottom up” - we identified several patterns around hosted infrastructure that were useful at UC Berkeley, Pangeo, and similar communities, and we wished to make them more generalized, accessible, and scalable.\nWe defined our mission as the following:\nOur mission is to make research and education more impactful, accessible, and delightful by developing, operating, and supporting infrastructure for interactive computing.\nAnd a description about our immediate activities to make things a bit more concrete:\n2i2c designs, develops, and operates JupyterHubs in the cloud for communities of practice in research \u0026amp; education. It builds and supports open source infrastructure that serves these communities.\nAround a year ago we began our pilot JupyterHubs project to learn more about our biggest challenges and opportunities in making interactive computing more accessible and useful for research and education. While both of these statements are still accurate, over the past year we’ve also learned more about the value that 2i2c provides. This post is an exploration of how these statements and our strategy may evolve in the near future.\nWhat did we miss with our original strategy? # In short: it is too-focused on actions rather than impact.\nWhile running JupyterHubs is a key part of what 2i2c does, it is a means to an end rather than our end-goal. Infrastructure is only useful if it changes workflows in a way that aligns with the goals and values that we wish to achieve. We’ve historically defined these in a few scattered places. For example, here are the values listed on our website:\n2i2c values fairness and justice as requirements for successful communities. 2i2c values learning and discovery for all people. 2i2c values collaborating and connecting to foster environments for learning and discovery. However, it is difficult to tie our operations directly to values and goals without making them concrete, and without defining a plan that ties them to our work.\nThrough our JupyterHubs pilot, we’ve learned how our actions-focused approach was missing some important aspects of these broader goals. For example, we came to understand that a big part of 2i2c’s value isn’t just providing a JupyterHub, it is de-risking cloud native workflows for communities that are inherently skeptical of what cloud infrastructure offers. Doing this entails many things: teaching, making decisions on behalf of others, supporting and answering questions, building trust, and yes, managing infrastructure.\nRefining our strategy # With this in mind, we’d like to make our strategy more clearly-defined and tied to our operational choices. Here are a few ways we’d like to do this:\nDefine our organization’s values and vision for the impact we wish to have. Define the key stakeholder communities that we wish to serve, the context of tools and services that are relevant to these stakeholders, and the assumptions we’re making. Define the problems these stakeholders have, the ways in which their current workflow could be improved, and the opportunity to help them. Describe our strategy to positively impact these stakeholders with our work. Define a collection of goals and objectives to carry out this strategy in the near-term. The rest of this post will take a crack at answering a few of these questions. It is intentionally messy, and meant both as a public snapshot of my thinking at this moment, and fodder for discussion and more specific proposals in the future.\nContext: Our key stakeholders and the impact we wish to have # 2i2c’s key stakeholders are communities of practice that are dedicated to creating and sharing public knowledge. These are primarily made up of researchers and educators in the global community.\nFor these stakeholders, we wish to catalyze and support a transformation in their data workflows that allows them to be more collaborative, inclusive, efficient, and powerful in the impact they wish to have.\nAssumptions we make about our stakeholders # There are a few unique things about these communities that are important for us:\nResearchers and educators see their job as creating and sharing knowledge with a heterogeneous and global community. They can’t make many assumptions about the organizational context or resources of this community, or their work will become inaccessible to others. They work at vertically-oriented …","date":1665273600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1665273600,"objectID":"6f97410cb47b43db748265b2c83455a3","permalink":"https://2i2c.org/blog/2022/strategic-update/","publishdate":"2022-10-09T00:00:00Z","relpermalink":"/blog/2022/strategic-update/","section":"blog","summary":"This post is an exploration of 2i2c’s current strategy and direction after a year of major operations. It is a brainstorm from the Executive Director, shared as a blog post to invite feedback and provide transparency into our current thinking.","tags":[],"title":"One year later: an update of 2i2c's mission, strategy, and impact","type":"blog"},{"authors":["Chris Holdgraf"],"categories":["organization"],"content":"We recently submitted a grant to Chan Zuckerberg Initiative and wish to share some details about it as well as the grant narrative for others to read and re-use.\nGo to Zenodo record Read on for a quick overview of the proposal.\nCollaborators # This grant is a collaboration between several leading organizations in open infrastructure, community, and global leadership:\n2i2c The Carpentries Center for Scientific Collaboration and Community Engagement Invest in Open Infrastructure MetaDocencia Open Life Science Problem statement # Cloud infrastructure is a powerful way to broaden access to workflows and infrastructure across the globe. However, it is also inaccessible to many for a variety of reasons:\nThere is a large, diverse, and messy ecosystem of open source tools to facilitate cloud infrastructure. Most communities don’t already have skills in utilizing cloud workflows. Running infrastructure in the cloud takes dedicated time and expertise that many communities lack. Many communities do not have organized communities of practice around cloud infrastructure. These issues are true for most scientific communities, but they are exacerbated in countries that are often marginalized in the global scientific community.\nOur proposed work # For this reason, our goal in this grant is to provide human and technical services to facilitate learning and knowledge transfer of cloud workflows for communities in Latin America and Africa.\nIt defines four major areas of collaboration:\nCloud infrastructure management - to facilitate access to cloud resources via managed cloud services that integrate open source tools. Application guidance and training - to provide community leaders with the skills to utilize this infrastructure for their needs. This includes language-localized content and training materials. Training for trainers - to provide community leaders with skills to share these workflows with others in their communities. Community leadership and management - to provide community leaders with skills to sustain and grow healthy communities of practice. If this proposal is funded, over the course of two years the team will provide a combination of the services described above for communities in Latin America and Africa, with the goal of understanding how such services can be most useful for these communities, how we can structure them to provide community representation in the direction of these services, and how we can sustain and scale this model of community-focused services for a global community.\nImportantly, we wish to do this work in a way that centers the communities we work with as co-leaders and collaborators in these services. We will explore ways to run these services and workshops so that they are transparent, inclusive, and give agency to the communities they support. Ultimately, we hope that this can be an extensible model for many more communities in the future.\nIf you’re interested in this work, would like to discuss its ideas, or think something similar might be useful for your community, please reach out!\nSend us an email ","date":1661644800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1661644800,"objectID":"5ccaad99757bb2ca2ec3362260d77d89","permalink":"https://2i2c.org/blog/2022/czi-global-communities-proposal/","publishdate":"2022-08-28T00:00:00Z","relpermalink":"/blog/2022/czi-global-communities-proposal/","section":"blog","summary":"We recently submitted a grant to Chan Zuckerberg Initiative and wish to share some details about it as well as the grant narrative for others to read and re-use.\nGo to Zenodo record Read on for a quick overview of the proposal.","tags":["bioscience"],"title":"Open grant narrative: A Collaborative Interactive Computing Service Model for Global Communities","type":"blog"},{"authors":["James Colliander"],"categories":["impact"],"content":" Reflections on the Jack Eddy Symposium # 2i2c supported and participated in the 3rd Eddy Cross Disciplinary Symposium held recently in Vail Colorado. The event was hosted by the Cooperative Programs for the Advancement of Earth System Science ( CPAESS) team at the University Corporation for Atmospheric Research ( UCAR) with support from NASA.\nContext # The Symposium was framed by the interesting and interdisciplinary scientific career of the late Jack Eddy. Eddy’s legacy was highlighted and his influence has been extended by dynamic leadership from NASA Program Officer Madhulika Guhathakurta (Lika). Lika helped launch and has sustained NASA’s Living with a Star (LWS) program over the past two decades. Prior to LWS, NASA had a variety of siloed efforts focused on near-Sun and near-Earth behavior. The LWS program led to an integration of these efforts under “system science” or “systems engineering” approaches and an expressed desired to connect LWS research activities with impacts on Earth (society, biology, culture, etc.). The program has expanded to include explorations of similar questions arising around other planets in our solar system and the recently discovered collection of exoplanets. Scientists from diverse disciplines (plasma physics, stellar evolution, atmospheric chemistry, space weather, planetary science,…) work together on “cross disciplinary” research that helps us understand our lives near our star.\nThe Symposium focused on three disciplinary areas (Exoplanets; Sun-Climate and Star-Climate interactions; Risk and resilience of space weather) unified under the cross-cutting thread of open science. Frequent references were made to the upcoming 2023 Year of Open Science and NASA’s Transform to Open Science (TOPS) mission. Symposium attendees listened to talks surveying the four areas in the morning and participated in hackathon-style breakout projects during the afternoons. Work on the projects launched at the Eddy Symposium continues. The space weather group is investigating ways to make the power grid more resilient. The Sun-climate group is exploring plans to establish an institute focused on Sun-climate interactions and improve connections between climate and heliophysics research communities. The exoplanets team is developing tools to programmatically compare Sun-Earth and star-exoplanet interactions.\n2i2c’s role # 2i2c, with input from Symposium CoChair’s Dan Marsh and Ryan McGranaghan, rapidly deployed a cloud-hosted JupyterHub for use during the event. The hub provided a shared space for participants to explore data, run analyses, and collaborate with one another using modern tools including Zarr, Xarray and Dask Gateway. Access to the interactive computing platform was granted to any member of the Symposium’s GitHub organization. The work to set up that hub, openly chronicled in this GitHub issue ( 2i2c-org/infrastructure#1329 ), included swapping out a Pangeo-style software environment for a heliophysics-specific resource developed by HelioCloud with special thanks to Brian Thomas!\n2i2c co-founder Fernando Pérez gave a talk on how he is “living la vida nube”. Fernando described the ways he, research collaborators, and students are using the Jupyter ecosystem. Diverse and curated tools in Jupyter hubs for the Jupyter Meets the Earth Project and Berkeley’s data science programs were highlighted. The talk showcased how these tools have been integrated to support individuals and communities of practice in data-driven research. In response to requests from the organizers and participants, Fernando gave a demonstration on how to use the hub 2i2c set up for the Symposium and an introduction to version control using git.\n2i2c co-founder Jim Colliander gave a talk titled Governing the Science Commons. Three key points from Jim’s talk were: the virtue that should guide the improvements to the scientific enterprise is intellectual generosity; implementation of intellectual generosity into science requires commons-based governance; the convergence of open source tools that support data-intensive collaborative research and learning (as showcased by Fernando) and agency interest ( NASA TOPS, UNESCO) in open science is an inflection point for global change. The talk ended with a call to action for the diverse communities represented at the Symposium to improve the ways we do science.\nThings we learned # Our experience with the Symposium taught 2i2c a few things.\nWe learned that our engineering team can rapidly deploy interactive computing resources to support a research and education community. Along the way, we confirmed what we’ve been learning from Pangeo and the neuroscience communities: flexible methods to customize the software environment are necessary. We confirmed that our developing shared responsibility model, enabling domain-specific experts to provide curated toolchains for their communities while leveraging 2i2c’s infrastructure expertise, is the right approach.\nWe learned that …","date":1657756800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1657756800,"objectID":"5d36d9cc84a68609f47fb32b7b8d0f39","permalink":"https://2i2c.org/blog/2022/eddy-symposium-report/","publishdate":"2022-07-14T00:00:00Z","relpermalink":"/blog/2022/eddy-symposium-report/","section":"blog","summary":"Reflections on the Jack Eddy Symposium # 2i2c supported and participated in the 3rd Eddy Cross Disciplinary Symposium held recently in Vail Colorado. The event was hosted by the Cooperative Programs for the Advancement of Earth System Science ( CPAESS) team at the University Corporation for Atmospheric Research ( UCAR) with support from NASA.","tags":["geoscience"],"title":"Reflections on the Jack Eddy Symposium","type":"blog"},{"authors":["Sarah Gibson"],"categories":["organization","service"],"content":"2i2c manages the configuration and deployment of multiple Kubernetes clusters and JupyterHubs from a single open infrastructure repository. This is a challenging problem, as it requires us to centralize information about a number of independent cloud services, and deploy them in an efficient and reliable manner. Our initial attempt at this had a number of inefficiencies, and we recently completed an overhaul of its configuration and deployment infrastructure.\nThis post is a short description of what we did and the benefit that it had. It covers the technical details and provides links to more information about our deployment setup. We hope that it helps other organizations make similar improvements to their own infrastructure.\nOur problem # 2i2c’s problem is similar to that of many large organizations that have independent sub-communities within them. We must centralize the operation and configuration of JupyterHubs in order to boost our efficiency in developing and operating them, but must also treat these hubs independently because their user communities are not necessarily related, and because we want communities to be able to replicate their infrastructure on their own.\nA year ago, we built the first version of our deployment infrastructure at github.com/2i2c-org/infrastructure. Over the last year of operation, we identified a number of major shortcomings:\nWithin a Kubernetes cluster, we deployed hubs sequentially, not in parallel. This grew out of a common practice of Canary deployments that allowed us to test changes on a staging hub before rolling them out to a production hub. We used a single configuration file for all hubs within a cluster, which led to confusion and difficulty in identifying a hub-specific configuration. Moreover, any change to a hub within a cluster caused a re-deploy of all hubs on that cluster. This is because we did not know whether a given change touched cluster-wide configuration or hub-specific configuration. Our goal # So, we spent several weeks discussing a plan to resolve these major problems - here were our goals:\nWe should be able to upgrade a specific hub alone, by inspecting which configuration files have been added or modified. Production hubs should be upgraded in parallel when they are effectively run independently. We should use staging hubs as “canary” deployments and not continue upgrading production hubs if the staging hub fails. An overview of our changes # To accomplish this, we needed to identify which hub required an upgrade based on file additions/modifications. This took a lot of discussion and iteration on design, and so we share it below in the hopes that it is helpful to others!\nImprovements to our code and structure # We made a few major changes to the infrastructure repository to facilitate the deployment logic described above. Here are the major changes we implemented:\nWe separated each hub’s configuration into its own file, or set of files. For example, here is 2i2c’s staging hub configuration. We created a separate cluster.yaml file that holds the canonical list of hubs deployed to that cluster and the configuration file(s) associated with each one. For example, here is 2i2c’s GKE cluster configuration, which contains a reference to the previously mentioned staging hub. We updated our deployer module to do the following things: Inspect the list of files modified in a Pull Request. From this list, calculate the name of a hub that required an upgrade, and the name of its respective cluster. Trigger a GitHub Actions workflow that deploys changes in parallel for each cluster/hub pair. In addition to these structural and code changes, we also developed new GitHub Actions workflows that control the entire process.\nA GitHub Actions workflow for upgrading our JupyterHubs # We defined a new GitHub Actions workflow that carries out the logic described above. These are all defined in this deploy-hubs.yaml configuration file. Here are the major jobs in this workflow, and what each does:\ngenerate-jobs: Generate a list of clusters/hubs that must be upgraded, given the files that are changed in a Pull Request.\nEvaluate an input list of added/modified files in a PR Decide if the added/modified files warrant an upgrade of a hub Generate a list of hubs and clusters that require upgrades, and some extra details: Does the support chart that is deployed to the cluster also need an upgrade? Does a staging hub on this cluster require an upgrade? This produced two outputs to be used in subsequent steps:\nA human-readable table including information on why a given deployment requires an upgrade (using the excellent Rich library). JSON outputs that can be interpreted by GitHub Actions as sets of matrix jobs to run. Our staging and support hub job matrix tells GitHub Actions to deploy staging and support upgrades that act as canaries and stop production deploys if they fail. upgrade-support-and-staging: Update the support and staging Helm charts on each cluster. These are …","date":1650326400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1650326400,"objectID":"91264ab8963bcd7c30384d1bd6f92b1a","permalink":"https://2i2c.org/blog/2022/ci-cd-improvements/","publishdate":"2022-04-19T00:00:00Z","relpermalink":"/blog/2022/ci-cd-improvements/","section":"blog","summary":"2i2c manages the configuration and deployment of multiple Kubernetes clusters and JupyterHubs from a single open infrastructure repository. This is a challenging problem, as it requires us to centralize information about a number of independent cloud services, and deploy them in an efficient and reliable manner.","tags":[],"title":"Tech update: Multiple JupyterHubs, multiple clusters, one repository.","type":"blog"},{"authors":["Chris Holdgraf"],"categories":["organization"],"content":"Quarter 1 of 2022 just wrapped up, and the 2i2c team has been busy making improvements across our infrastructure, organization, and operations. This is a quick post to celebrate the work we’ve done over the past three months, and to briefly share what we’re working on next.\nThese are the main highlights from this quarter - if you’d like to check out more of the work that we’ve done, see:\nAll the PRs we’ve merged in Q1 All closed issues in Q1 Infrastructure improvements # This quarter we did a deep dive into a number of core infrastructure improvements for our Managed JupyterHubs Service. Here are a few highlights:\nInfrastructure reliability and efficiency. We improved the resiliency, reliability, and efficiency of our deployment infrastructure. For example, we refactored our hub configuration so that each community is better-able to track it, we implemented validation steps to ensure that we don’t accidentally push incorrect config to the hubs, and we’ve significantly improved our CI/CD pipeline to push deployments out to our hubs more efficiently. Automatic deployments to commercial cloud. With the ICESat hackweek as a test-case for AWS, we’ve finished automating the deployment of clusters and hubs to each major commercial cloud. (there’s not a specific issue for this as it has been a multi-month effort over many PRs and issues!) CILogon authentication. CILogon is a non-profit organization that provides “single-sign on” authentication services for the same communities that 2i2c serves. We’ve partnered with them to prototype using CILogon for 2i2c’s hubs, which should make it much easier for communities to user their own institutional sign-ons. Communities we’ve served and lessons learned # As described in our Managed Hub Services strategy, our goals for this phase of our organization are to balance serving communities of practice and learning where we can improve our infrastructure and practices. With that in mind, here are a few highlights of communities we’ve served, and what we’ve learned from it:\nWe grew a hub for the University of Toronto to around 4000 monthly users. This has taught us a lot about where our support and operations can and cannot scale, and where we have gaps in our sustainability / pricing model. We deployed CILogon on a hub for a class at Australian National University. This gives us an opportunity to work out any UX issues and improvements to be made before a deeper CILogon integration. We deployed a dedicated database per user for a databases course at UT Austin. This is helping us learn more about how to pair slightly more customized per-user infrastructure with our standard hub setups, as well as how our Right to Replicate model could be followed for more complex setups like a database. We ran an event hub for the ICESat2 HackWeek at the University of Washington. This helped refine our infrastructure and expertise with AWS, as well as improved our event “ready mode” practices. We deployed a new hub for the LEAP project. This has given us an opportunity to prototype new processes for pass-through cloud costs to simplify our deployments. Organizational improvements\nBeyond our technical and community impact work, we’ve made a lot of significant organizational improvements as well.\nWe designed a new role in Product and Community Management. We’re excited for this new hire to spearhead efforts in guiding and developing relationships with the communities we serve, as well as guiding and collaborating with our engineering team in developing our services. We designed a new Project Manager role. Our engineering team had been operating as a largely autonomous and independent group, but we’ve realized that we would benefit from someone to help coordinate our actions and plans, especially as we balance more operations/support issues in addition to new development. This new role is an experiment at growing this capacity within our team, in the hopes that we can dedicate a team member to it in the future. What’s next # We are still working out our major priorities for the oncoming quarter, but have a few major projects in the works that we’re hopeful to make progress on quickly. Here are a few major examples:\nImprove our process and operations around supporting our users. We are discussing first- and second-line support processes to make our team more responsive and effective at resolving incidents. Improve our invoicing and contracting process. We are discussing how to reduce toil associated with invoicing in order to make this practice more reliable and efficient, along with our fiscal sponsor Code for Science and Society. Improving our reporting and monitoring infrastructure. We’d like to boost our ability to monitor activity on each of our hubs in order to identify when something abnormal is happening and get ahead of any potential problems (e.g., to avoid unintentionally large cloud bills). We’d also like to improve our usage reporting to more create more accurate cloud bills for hubs …","date":1649030400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1649030400,"objectID":"454c4a8fe4f63e69b69c0d288694eaad","permalink":"https://2i2c.org/blog/2022/q1-update/","publishdate":"2022-04-04T00:00:00Z","relpermalink":"/blog/2022/q1-update/","section":"blog","summary":"Quarter 1 of 2022 just wrapped up, and the 2i2c team has been busy making improvements across our infrastructure, organization, and operations. This is a quick post to celebrate the work we’ve done over the past three months, and to briefly share what we’re working on next.","tags":[],"title":"Celebrating our progress in Q1 2022","type":"blog"},{"authors":["Chris Holdgraf"],"categories":["people"],"content":"Yesterday we had a quick “drop-in” session to take questions about 2i2c’s job posting for a Product and Community Lead. We spent the hour discussing a number of questions that others had about the position. Below is a short overview of the questions and some responses, for those who were not able to attend. These responses are a bit rough, since they are mostly off-the-cuff based on the questions asked.\nUpdate 2022-03-24: We’ve added extra questions and answers below from our latest drop-in meeting.\nWhat does success look like in the short and long term? # This is an important question, with a few different kinds of answers.\nAs noted, this is the first hire of its kind inside of 2i2c, and it should bring a strategic and organization-building eye to the work that it does. To some extent, this role will be tasked with coming up with their own answers to these questions. This person should build a near- and long-term strategy for how Product and Community Engagement should evolve to be most-effective in accomplishing our mission. This will also mean defining goals and a strategy to meet these goals over time.\nWith that in mind, here are a few ideas we have in mind for goals that will drive this role:\n6 month goals for this role might be:\nBecome familiar with 2i2c’s organization, culture, mission, and team. Define an early strategy for how you’d like to incorporate Product and Community engagement into 2i2c’s operations, and set some Objectives or Key Results that we should use to measure success. This should include a plan for the two major objectives of this role: guiding and connecting with the communities we serve, and building design and planning processes that bring this perspective into our engineering and services. A few iterations on the execution of this strategy, with some demonstration of impact as well as some documented lessons learned. 2 year goals for this role might be:\nAn organizational strategy and structure has been created, defining the various roles that make up this division of 2i2c and their functions. Clearly defined team processes for major programs efforts that this role oversees, as well as interconnections with other major divisions of 2i2c (e.g. engineering or sales). For example, a framework for training community leaders and mechanisms or platforms for communication and engagement with our communities. A team exists that carries out these efforts, led by the Product and Community Lead. Clear demonstrated impact in the communities we serve, according to the OKRs and goals that have been set in this division. How does 2i2c provide mentorship/onboarding? # You can find our onboarding process in our Team Compass. This roughly comes down to choosing an “Onboarding Champion” for the new team member, to help walk them through our team processes and get them access to the right information and accounts. However, 2i2c is quite young, so has only had a few iterations in onboarding new team members. We look forward to improving this process further via this new hire.\nWhat are the largest challenges that someone might face in their first year in this position? # The largest challenge is largely related to ambiguity and fluidity of this role, due to the fact that 2i2c is small and relatively young. As noted above, this position will have a great deal of autonomy, and will be expected to show leadership in defining the nature of this work within 2i2c. This can either be exciting or scary depending on your comfort level with ambiguity! We recognize that it is an anti-pattern to have roles without clearly-defined measures of success, so we’re committed to defining this quickly in partnership with the new hire. However, we don’t want to be overly-prescriptive in this role, because we want it to have space to lead these efforts within 2i2c.\nHow do you hope to protect the “business” aspects of 2i2c, if all the tech is open source? # 2i2c is to some extent committing to a limiting business model: by respecting the Right to Replicate, we encourage other organizations to perform the exact same kinds of services that 2i2c offers. However, we believe this is in-line with 2i2c’s mission, and would consider this to be a measure of impact rather than a sustainability problem. In short: our goal is not to become a tech giant or start-up unicorn, we want to sustain a team with competitive pay, and we want to scale as there is more opportunity to serve new communities. We believe that the complexity of integrating tools and managing cloud services means that there will always be enough of an opportunity to bring in ample funding for this model. We also hope that our mission-driven nature and focus on research and education will bring in new kinds of funding opportunities that can sustain 2i2c and its mission.\nHow would applying the “1000 true fans” approach work in terms of advocacy? # The 1000 true fans approach suggests that it is enough to leverage the support of “1000 true fans” to sustain a product or …","date":1647907200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1647907200,"objectID":"a610fec4ca5e5927b338d93661fa3039","permalink":"https://2i2c.org/blog/2022/product-community-lead-drop-in-notes/","publishdate":"2022-03-22T00:00:00Z","relpermalink":"/blog/2022/product-community-lead-drop-in-notes/","section":"blog","summary":"Yesterday we had a quick “drop-in” session to take questions about 2i2c’s job posting for a Product and Community Lead. We spent the hour discussing a number of questions that others had about the position.","tags":[],"title":"Notes from our drop-in meeting about the Product and Community Lead role","type":"blog"},{"authors":null,"categories":null,"content":"We are looking for a Product and Community Lead to ensure that the communities that 2i2c serves are empowered to have the most impact with our infrastructure.\n❌❌❌\nThis posting is closed to new applications.\nSee the jobs page for our open positions.\n❌❌❌\nAbout the position\nSalary: $120,000 - $130,000 Location: anywhere (prefer a time zone between US/Pacific and Central European) Deadline: We will begin reviewing applications around March 21st, and will accept them on a rolling basis until the position is filled. Major duties\nGuide and learn from our user communities.\nGuide our team to build services and infrastructure for these communities\nLead strategic efforts to grow this work within 2i2c.\nFor more general information about 2i2c, see the links below:\nOur Team Compass Our Code of Conduct Our Mission and Values What it’s like to work at 2i2c Click here to Apply Position summary # This role will guide and empower the communities that we serve, learn from them, and bring their perspective to guide our service and product development. It is similar to a mixture of product management and community and developer advocacy in a tech firm, but adjusted for research, education, and open source contexts. It is also similar to a Research Applications Manager, but with a focus on using and developing infrastructure.\nThe skills required are a combination of communication, teaching, learning, service design and delivery, and technical acumen. The person that fills this role should feel comfortable learning and sharing ideas, empowering and guiding others, and communicating clearly and collaboratively with a variety of stakeholders including end-users and engineers.\nThis is a leadership role for a strategy-minded practitioner. 2i2c is a young organization, and this role will have a large degree of autonomy and flexibility. We have defined the starting point, but we seek someone who can bring a strategic eye to this position. Over time we hope that the role will grow to define and lead this style of work within 2i2c more broadly.\nWhat you’ll do # This role is a combination of connecting, guiding, leading, learning, communicating, and empowering stakeholders in the communities we serve, as well as the 2i2c engineering team. Here are some key focus areas with core responsibilities under each:\nGuiding and learning from communities we serve # Our users are often not “power-users” with Jupyter, open source workflows, or cloud-native workflows. This role should work with users of these communities to guide them in using our infrastructure for maximal impact. Below are a few example responsibilities:\nUnderstand the goals and needs of the communities we serve, as well as the major pain points and problems that they have. This understanding may not be directly communicated and will be gained through active observation. For example:\nCreate and engage in spaces for sharing information with users. For example, online forums and live community discussions. Engage in community-specific spaces. This role may monitor and participate in community spaces in either research or education (e.g., the Pangeo forum, the Jupyter forum, or forums for education communities) to track relevant conversation and provide guidance as-needed. Guide communities and their leaders for the use-cases that 2i2c wishes to enable, and how our infrastructure (Jupyter, JupyterHub, open source tools, etc) can be used to have the most impact. For example:\nDevelop user-facing materials (documentation, workshops, talks, etc) that demonstrate the basic use-cases that we support, and the best ways that the infrastructure can be used to accomplish community goals. For example “Teaching with Jupyter” or “An Introduction to Scalable Computing with Dask.” Provide one-on-one or group guidance to our user communities (particularly leaders in those communities) with the goal of transferring knowledge that they can then share within their peers. Foster deeper external relationships and engagements with key communities of practice and partners that are important for 2i2c’s strategy, such as the Pangeo Project (which is a key stakeholder for this role).\nEngage with potential communities and stakeholders, with a focus on demonstrating the use-cases we hope to support and generating new service contracts with these communities. Communicate externally to demonstrate impact. For example, by participating in meetings, conferences, and other events where we have an opportunity to highlight the work that 2i2c does. Interact extensively with open source communities that underlie our infrastructure, potentially serving in leadership roles and doing significant work to support these communities. There will be a particular focus on the Jupyter and PyData ecosystems. Guide product and service design and implementation # This role should understand the perspectives of our users and the use-cases we wish to enable, and bring this perspective to guide the evolution of our services and …","date":1646006400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1646006400,"objectID":"2ebe6e02e323565512fb237dc54713cb","permalink":"https://2i2c.org/jobs/2022/product-community-lead/","publishdate":"2022-02-28T00:00:00Z","relpermalink":"/jobs/2022/product-community-lead/","section":"jobs","summary":"We are looking for a Product and Community Lead to ensure that the communities that 2i2c serves are empowered to have the most impact with our infrastructure.\n❌❌❌\nThis posting is closed to new applications.","tags":null,"title":"Product and Community Lead","type":"jobs"},{"authors":["Chris Holdgraf"],"categories":["people"],"content":"The 2i2c team is looking to hire a new team member! We are seeking a product and community lead with the following two goals:\nEmpower the communities we serve to have impact with our infrastructure. Guide our development and service design to reflect the needs of our users. This role will work alongside our engineering team as a partner, and will serve as a high-bandwidth interface to the communities that we work with.\nYou can find a link to the full job posting below, the rest of this post is a short rationale for this role, and how we hope it will fit within 2i2c’s team and strategy.\nLearn more and apply Why a new role? # When 2i2c began a year ago, we hired a team of engineers that had experience in cloud infrastructure, Jupyter, and open source ecosystems. In that time, we’ve built out the infrastructure foundation for scalable interactive computing environments that are customizable for the community, and respects their Right to Replicate.\nHowever, solely providing infrastructure is not enough. Working with the modern open source stack, using the cloud to its advantage, and bringing these tools into specific domains requires a lot of extra experience and expertise. We believe that 2i2c is in a good position to provide guidance and support to leaders in the communities that we serve, allowing them to get up-to-speed with the infrastructure more effectively so that they can have an impact.\nMoreover, we’ve also learned that it’s crucial to develop infrastructure in collaboration with the communities that we’re serving. A team of engineers tends to focus on code and infrastructure, and having a role that focuses on connecting with communities will give them an excellent perspective on what those communities need.\nWe hope that this role will combine these two aspects to create a culture of learning, sharing, and guiding between 2i2c’s team and the communities that we work with.\nWhat are similar roles? # We tried to find similar roles in the private and non-profit sector, but couldn’t find anything that was a perfect fit. However, there were a few close matches.\nThis role is kind-of like a product manager - their job is to understand the communities that we work with, and to use this to help us make decisions about what to build, how to present it, and how to engage with stakeholders. They will need to help us prioritize the work that is most impactful for our mission, and help us navigate trade-offs in the evolution of our services.\nThis role is also kind-of like a customer success manager or a developer advocate - they will guide and teach those in the communities we serve - particularly community leaders that go on to teach others - how to use our infrastructure most-effectively.\nIn fact, the closest role we could find is a relatively new one: the Research Applications Manager. This is a role that has been pioneered by the Turing Institute, and is similarly described as a connector that brings together many perspectives and encourages a participatory, team-based approach to research.\nHowever, the reality is that the person in this role will ultimately get to shape the nature of their work within 2i2c. As a young organization, there is a lot of flexibility for creativity and experimentation in bringing new skillsets into our organization. We hope that the person who fills this role will be excited about growing a culture of team-based approaches to our engineering and collaborations, and to share this culture with the communities that we serve.\nWhat’s next? # Effective today we are opening up applications for this position, and will begin reviewing them in 2 weeks on a rolling basis until the position is filled. For a more formal job posting, and instructions to apply, click the link below!\nLearn more and apply ","date":1645488e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1645488e3,"objectID":"9a790962fde35556190c78d24dace070","permalink":"https://2i2c.org/blog/2022/job-product-community-lead/","publishdate":"2022-02-22T00:00:00Z","relpermalink":"/blog/2022/job-product-community-lead/","section":"blog","summary":"The 2i2c team is looking to hire a new team member! We are seeking a product and community lead with the following two goals:\nEmpower the communities we serve to have impact with our infrastructure.","tags":[],"title":"New job posting: Product and Community Lead.","type":"blog"},{"authors":["Chris Holdgraf"],"categories":["organization"],"content":"Now that 2021 has come to an end, this marks the end of 2i2c’s first year of operations. In this year we have grown, experimented, and accomplished a lot - we have also faced challenges and learned as a team. Our primary goal in 2021 was to build a strong foundation for 2i2c.\nTo reflect on our work thus far, we’re writing three blog posts that describe progress in major areas of work towards this foundation for 2i2c. These three areas are:\nCreating services for use-cases - these are our first managed infrastructure offerings for communities in research and education. Developing cloud infrastructure and tools - this is the technical backbone that makes these services possible, built entirely on open source tools. Building an organizational foundation - this is the creation of our team structures, processes, and culture that help us carry out our mission. This first post will focus on services that we’ve created in our first year.\nUltimately, 2i2c’s mission is to facilitate use-cases in research and education via open source development and services. Throughout 2021 we ran several pilots to learn more about the needs of communities in research and education, and how we could build sustainable services that meet these needs. Here are some highlights for each major use-case we have targeted thus far:\nEducational community hubs # A primary use-case that 2i2c seeks to enable is collaborative, distributed educational spaces for learning with data. In 2021 we ran several pilots with educational communities:\nA university-wide hub for the University of Toronto. This hub is used in a variety of classes throughout the university, and is made freely available to anyone with a UofT account. We hope to repeat this model for other university-wide communities, and have learned a lot about the challenges of working with particularly large educational communities.\nSeveral hubs for community colleges across California. In partnership with UC Berkeley and CloudBank, we’ve run several hubs for nearly a dozen small community colleges teaching the Data 8 curriculum for their students. These hubs are lightweight and offer standardized environments for their students to use, in order to lower the cost of deploying and maintaining the hubs over time.\nWhat we learned # The organizational context around educational use-cases is different from research communities. Compared with research groups, educucational groups have more variance in their size (classes as small as 10 people and as large as 500) and think about cost by the student, not as a lump sum. This means that our initial hub-based pricing model may not map cleanly onto educational contexts, and we need to improve the match of scalability and price to these communities.\nMoreover, we’ve learned that for these communities, navigating all of the open source tools that are available for pedagogy is confusing! Everybody wants auto-grading but it’s unclear what is the “right tool for the job”. Tools like nbgitpuller have heavy use at “power universities” like UC Berkeley, but many others don’t know that it exists! We will need to invest more time into building guides and documentation that help others leverage these tools.\nResearch in the cloud # In addition to educational use-cases, we ran several pilots for research communities in order to leverage cloud infrastructure for scaling their work or collaborating more effectively.\nWe migrated Pangeo’s cloud infrastructure to be run via 2i2c. The Pangeo Community had been operating and developing their own JupyterHub for several years, but were looking for another organization to provide more reliable/sustained operations and support for their Pangeo Cloud Service. This year we migrated the service to run off of 2i2c’s deployment infrastructure.\nA scalable cloud hub for a SWOT satellite team. The MEOM research group at Grenoble is doing work with the NASA SWOT satellite project. However, the datasets generated from this project are huge, and only storable via the cloud. We’ve set up a JupyterHub to provide cloud-based access to this data, running a Pangeo-like environment.\nWhat we learned # Research communities tend to have more usecase-specific needs than educational ones. While introductory courses in data science tend to be similar across institutions, research needs are much more unique to the problem and team at hand. Moreover, they tend to want infrastructure that runs via institutional cloud accounts. This is possible due to the flexible nature of Jupyter and JupyterHub, but brings extra challenges in bureacracy and access permissions, given that 2i2c engineers usually are not members of these organizations already.\nAdditionally, many research use-cases are based around the location of the data. This is because data is the hardest thing to move from cloud to cloud. For this reason, it’s important to bring interactive sessions to the data. Jupyter’s ecosystem makes this possible, but we’d like to do more to make this easier. For …","date":1643068800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1643068800,"objectID":"858b571dced8d12fbbf3c313fdb00006","permalink":"https://2i2c.org/blog/2022/2021-review-services/","publishdate":"2022-01-25T00:00:00Z","relpermalink":"/blog/2022/2021-review-services/","section":"blog","summary":"Now that 2021 has come to an end, this marks the end of 2i2c’s first year of operations. In this year we have grown, experimented, and accomplished a lot - we have also faced challenges and learned as a team.","tags":[],"title":"2i2c’s first year, part 1: exploring Jupyter services.","type":"blog"},{"authors":["Sarah Gibson"],"categories":["impact"],"content":" Pangeo Cloud is an experimental service providing public cloud-based data-science environments for data-intensive geoscience research. We have recently finished re-creating the Pangeo community JupyterHub hosted on GCP in the 2i2c-org/infrastructure repository. This is a huge milestone in our partnership with Pangeo to provide expertise and operations of cloud-based, vendor-agnostic Jupyter infrastructure and workflows.\nFor users of Pangeo Cloud, the switch should have been a smooth one! The new hub should behave nearly identically to the old one, and will be managed by 2i2c engineers moving forward, in partnership with the Pangeo community. It will be available at the same URL ( us-central1-b.gcp.pangeo.io) and there’s no need to worry about your home directories, they were synced to the new hub only a few days before the migration took place. Development and operations on this hub will all be done in the open and we invite participation and feedback from others in our infrastructure work. Please see this Discourse thread as an initial place to provide feedback.\nOn 22nd November 2021, the old Pangeo GCP JupyterHub will be shut down, and the project will move forward on the new 2i2c Pangeo Hub. Moving forward, we plan to collaborate together in order to find new pathways for development in the Jupyter ecosystem - we will share more ideas of things we will work on soon!\nHistory of Pangeo Cloud Hubs # Pangeo has pioneered a new model in using open source and cloud-agnostic infrastructure to support scientific research in the cloud.\nThe first Pangeo cloud JupyterHub (pangeo.pydata.org; now defuct) was deployed for the 2017 American Meteoroligical Society Meeting; since then, the Pangeo community has iterated through several different versions of prototype cloud-based hubs. This allowed for many new workflows that enabled a more open and collaborative pathway to doing world class research, and included access to datasets and computational resources that were previously unattainable. Pangeo achieved this by working in partnership with open source communities and building technology that leveraged modular open source components for their platform.\nIn the last several years, Pangeo have built a thriving community of practice around this infrastructure. However as the community has grown, so has the need for more reliable and dedicated operational and developmental support since parts of the Pangeo stack require dedicated expertise and attention to managed. Modern scalable cloud infrastructure is one example of this. Maintaining a complex JupyterHub with many users is a difficult task, and has required significant resources from the Pangeo Project up to this point.\nThe Pangeo-2i2c Partnership # 2i2c is a non-profit team that develops and operates cloud infrastructure for interactive computing workflows. We have extensive experience in Jupyter workflows in the cloud and a long history of contributions to projects in this ecosystem. We have built a cloud deployment management system that allows us to centralise and configure the deployment of many independent JupyterHubs, empowering communities to leverage the same infrastructure (and team!) for JupyterHubs running in the cloud.\nSimilarly to Pangeo, all of 2i2c’s core infrastructure is cloud- and vendor-agnostic, and follows a model of building open source tools and giving back to those communities. Our partnership with Pangeo began through 2i2c’s core competency in these areas and the similarity between the two project’s technical stacks.\nWe’ve begun a partnership whereby 2i2c will manage Pangeo’s cloud infrastructure and lead efforts to develop new features, in partnership with open source communities. We sketched out a few ideas to focus on in this kick-off thread on Discourse. This approach allows each community to focus on it’s core strengths: Pangeo will continue to grow an open community and scientific software ecosystem around geospatial analytics, and 2i2c will oversee the development and operations of the core cloud infrastructure stack that powers Pangeo’s workflows. In some areas we are still experimenting with different collaboration models to ensure that the needs of the Pangeo community are met in a way that is also sustainable for 2i2c. Over the coming weeks, you may see some conversations (and threads for feedback!) about different support and operations models that work best for the community. We are excited to use this as an opportunity to learn more about how to serve more complex and diverse communities like Pangeo.\nWe are extremely grateful to the Pangeo project for giving us the opportunity to serve their community, and we look forward to a long partnership ahead! 🚀\n","date":1637020800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1637020800,"objectID":"24f81ee8ba42c2db1774c4d417072c6f","permalink":"https://2i2c.org/blog/2021/pangeo-goes-live/","publishdate":"2021-11-16T00:00:00Z","relpermalink":"/blog/2021/pangeo-goes-live/","section":"blog","summary":"2i2c are pleased to announce that the first Pangeo JupyterHub is now live on 2i2c-operated infrastructure! :tada: ","tags":["geoscience"],"title":"Pangeo Cloud goes live on 2i2c!","type":"blog"},{"authors":["Chris Holdgraf"],"categories":["updates"],"content":" This is a (roughly) quarterly update for the 2i2c community, with the goal of providing transparency about what we’ve been up to, sharing what we are working on and where we have struggled, and discussing what we’re up to next. In addition, almost all of the work we do is public and discoverable across our GitHub repositories, and is tracked by GitHub issues. Here’s a list of issues we’ve closed in ~Q3.\nIt is amazing how quickly 4 months goes by when you’re building an organization from scratch! It seems like only a few weeks ago that we were recapping the beginning of the year in our last community update. Since then, we have been hard at work to make 2i2c’s organizational and infrastructure more robust and sustainable.\nThere are several major strategic areas where 2i2c aims to have impact, and we’ve split this community update along each of these major areas below. We’ll cover major highlights, challenges we’ve faced, and where we’re going next.\nHighlights # Managed JupyterHub Service # Our Managed JupyterHub Service will be a sustainable, scalable, and participatory service to provide cloud-based DevOps around JupyterHub for communities of practice in research and education. For the past several months, we have been running individual JupyterHubs for many organizations as a pilot, in order to learn more about the challenges we’ll face, and give ourselves an opportunity to build centralized infrastructure around the service.\nWe focused on a few major areas for work, outlined below:\nAutomation across cloud providers. We wish to serve communities that run on any of the major commercial cloud providers. We can standardize some of our infrastructure through abstractions like Kubernetes, but must still create cloud-specific deployment infrastructure as well (that Kubernetes cluster has to come from somewhere first!). In the last four months we’ve worked on automating Kubernetes and JupyterHub deployments on AWS as well as Azure to complement our Google Cloud deployments. We would soon like to run more hubs on this infrastructure to test how well it scales. Monitoring and reporting infrastructure. We have worked on the JupyterHub grafana-dashboards project to improve dashboarding around JupyterHub deployments in general, and will soon automatically deploy Grafana dashboards for our hubs so that communities have insight into what is going on in their hubs. User environment management. We want communities to have control over the environments that are available on their hubs. We also want to encourage that our communities follow community standards for reproducible environments that can be re-used elsewhere. For this reason, we’ve improved the repo2docker GitHub action to work with more image registries, and created a 2i2c user image template repository for users to re-use for their hubs. See the User Environment docs for more information. Support and collaboration roles. In addition to technology changes, we have developed an alpha-level support and collaboration model for the communities we serve. Most relevant for our communities is the community representative role, who acts as the main point of contact with 2i2c engineers, and leads administrators on the hub to guide its customization for the community it serves. See the user roles documentation for more information. We have also begun prototyping a FreshDesk support model and team processes around monitoring our support channels and responding to requests and incidents. Pangeo # We are working with the Pangeo Community to migrate the Pangeo JupyterHub deployments to utilize 2i2c’s centralized infrastructure, with the goal of 2i2c taking over the development and operation of Pangeo hubs moving forward. We have spent the last few months re-creating the Pangeo hub environment from scratch on a new cloud project controlled by Columbia University, and are nearly ready to begin migration from the “old” Pangeo hub to the new one. After this, we will focus our attention on re-creating the Pangeo BinderHub and AWS hub. Follow along with this work in this GitHub Project.\nExecutable Books / Jupyter Book # We are nearing the final year of a grant from the Sloan Foundation to support development on the Executable Books Project. As such, we have begun shifting our attention to create a strategy for sustaining the project’s community beyond this grant. In the coming months we plan on prioritizing improving our documentation (both for users and developers), as well as improving the general maintainability and quality of our codebases.\nJupyterHub community support # We recently collaborated with the JupyterHub community to apply for two CZI EOSS awards. Last month, we were notified that our application to support a Community Strategic Lead was funded! This role will fund Sarah Gibson’s time to focus some of her thinking on building community structures and dynamics that are inclusive and sustainable. We’ll update with more information as this project starts moving. …","date":1633824e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1633824e3,"objectID":"eb8170fad0ccceb7840702fd5c2ef642","permalink":"https://2i2c.org/blog/2021/q3-update/","publishdate":"2021-10-10T00:00:00Z","relpermalink":"/blog/2021/q3-update/","section":"blog","summary":"This is a (roughly) quarterly update for the 2i2c community, with the goal of providing transparency about what we’ve been up to, sharing what we are working on and where we have struggled, and discussing what we’re up to next.","tags":[],"title":"Community update Q3 2021: A new fiscal sponsor, improving our infrastructure, nearing an alpha launch.","type":"blog"},{"authors":["Chris Holdgraf","Danielle Robinson"],"categories":["updates"],"content":"This post was originally written for the CS\u0026amp;S blog.\nCode for Science \u0026amp; Society is thrilled to welcome the International Interactive Computing Collaboration (2i2c, for short) as a fiscally sponsored project! After spending a year incubating in the International Computer Science Institute, where 2i2c received critical startup support, 2i2c now joins our fiscally sponsored project program to launch their next phase. 2i2c develops and operates cloud infrastructure for interactive computing, with a focus on the Jupyter ecosystem and cloud-native workflows in research and education. They will build a cloud services model that respects a community’s Right to Replicate their infrastructure by providing transparent and customizable JupyterHub deployments on cloud infrastructure that utilize community-driven open source tools. They aim to use the resources generated from this service in order to support the communities that underlie this infrastructure. Read on for more about 2i2c’s mission and how CS\u0026amp;S will support their team and vision.\n2i2c’s organizational mission is to develop and operate sustainable cloud services that provide interactive computing infrastructure with JupyterHub and an ecosystem of tools that support research and education. This model has been pioneered in the organizations that 2i2c’s co-founders have co-led for many years, including the Pangeo Project, the Syzygy Project, the Binder Project, and the UC Berkeley DataHub. These projects follow an “integrate, customize, and upstream” model. They integrate pre-existing open source tools, make necessary customizations to support their specific use-case, and make upstream contributions to extend the infrastructure beyond its current capabilities. This creates a virtuous cycle where tangible needs are met in research and education, while improvements are made to open source projects that benefit the broader community. 2i2c hopes to scale this model, and provide these JupyterHub-based cloud services available to the broader research and education community.\nCS\u0026amp;S is particularly interested in pursuing the opportunity to work closely with 2i2c as their team explores how to build sustainable, ethical services that support open scholarship as well as open source communities. The model that 2i2c will develop is different in many ways from traditional grant-based development, or service-based business, because it depends on running community-led infrastructure that 2i2c contributes to, but does not control or own. Both CS\u0026amp;S and 2i2c believe that this model is an opportunity to build more distributed, community-led infrastructure and services, as well aligning a sustainability model with both open source communities and the scholarly community. We hope that this work will also provide experience that helps improve CS\u0026amp;S’s other initiatives in this space, including CS\u0026amp;S’s other fiscally sponsored projects and participants in the Digital Infrastructure Incubator program.\nAchieving this mission will involve innovation at an infrastructure level, a business model level, and an open source community strategy level, and will be carried out over the coming years. 2i2c’s next steps are to run pilot JupyterHub infrastructure for select communities of practice in research and education, in order to better understand their needs and how these needs fit in with 2i2c’s developing sustainability model. They will also build infrastructure to deploy and customize a federation of JupyterHubs that are community-specific, and that run entirely on open source infrastructure.\nIf you believe that your community would benefit from a hub like this, please reach out to the 2i2c team, or join their mailing list. Stay tuned as 2i2c builds its sustainable, scalable, and community-driven platform for interactive computing in the cloud.\n","date":163296e4,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":163296e4,"objectID":"2a879062b3520ec9de025b6fcd6be1b1","permalink":"https://2i2c.org/blog/2021/css-announce/","publishdate":"2021-09-30T00:00:00Z","relpermalink":"/blog/2021/css-announce/","section":"blog","summary":"This post was originally written for the CS\u0026S blog.\nCode for Science \u0026 Society is thrilled to welcome the International Interactive Computing Collaboration (2i2c, for short) as a fiscally sponsored project!","tags":["2i2c"],"title":"2i2c launches next phase in partnership with CS\u0026S","type":"blog"},{"authors":["Damián Avila"],"categories":["impact"],"content":"","date":1630713600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1630713600,"objectID":"7129084e54d4bda7b3ec37c3b41dc2b3","permalink":"https://2i2c.org/blog/2021/myst-nikola-part-2/","publishdate":"2021-09-04T00:00:00Z","relpermalink":"/blog/2021/myst-nikola-part-2/","section":"blog","summary":"","tags":["open source","jupyter","myst"],"title":"A deep dive into MyST, Part 2: The MyST-Parser, Docutils and Sphinx","type":"blog"},{"authors":["Damián Avila"],"categories":["impact"],"content":"","date":1629676800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1629676800,"objectID":"d6c2657172e1b9cf296716eda7200d3d","permalink":"https://2i2c.org/blog/2021/myst-nikola-part-1/","publishdate":"2021-08-23T00:00:00Z","relpermalink":"/blog/2021/myst-nikola-part-1/","section":"blog","summary":"","tags":["open source","jupyter","myst"],"title":"A deep dive into MyST, Part 1: The MyST-Parser Python API usage in Nikola","type":"blog"},{"authors":["Chris Holdgraf"],"categories":["organization"],"content":"It has been about six months since 2i2c first began operations (after receiving funding from the Chan Zuckerberg Initiative). In that time we’ve made progress along several directions, and wish to use this blog post to provide updates about the ways in which 2i2c has evolved over the first months of its existence.\nBelow are a few major updates from the 2i2c community - as always, if you want to learn more about 2i2c, keep an eye on our blog or subscribe to the 2i2c mailing list.\nEarly pilot JupyterHub infrastructure # First off - we have been making progress building out our JupyterHub deployment infrastructure for 2i2c. One of our major organizational goals is to build a sustainable service managing open source cloud infrastructure for interactive computing. This service will provide hosted, customized JupyterHubs for communities of practice in research and education. They’ll be built entirely with open source tools that are community-driven, and that respect the community’s Right to Replicate.\nIn order to accomplish this, 2i2c is running several pilots with partners and interested organizations, supported by our funding from CZI, as well as from the JROST rapid response fund. These pilots are meant to be learning opportunities to understand what kind of infrastructure and service it needs to build moving forward.\nThe documentation for our pilot hubs infrastructure contains information about our deployments and infrastructure. It is served from this 2i2c-org/infrastructure repository, a centralized location for configuring and deploying a federated network of JupyterHubs. Each JupyterHub is independent of one another, and could be spun out from the centralized repository with minimal extra work, giving hub users the ability to replicate their infrastructure, with or without 2i2c. We will continue refining the code in this repository as we learn more from our hub infrastructure pilots.\nJupyterHub for geospatial analytics - A collaboration with Pangeo # As originally announced on the Pangeo blog, 2i2c is forging a collaboration with the Pangeo project around operating and developing cloud infrastructure for large-scale geospatial analytics! This collaboration is funded through a grant from the Moore Foundation (via Pangeo investigator Ryan Abernathey).\nOver the coming months, 2i2c plans to assume operation of infrastructure underlying the Pangeo project, allowing the Pangeo team to focus their efforts on their core scientific and development missions. Because Pangeo’s infrastructure is already running on a fully open source stack with JupyterHub, our first step will simply be to shift control over this infrastructure to 2i2c engineers. We don’t anticipate needing to make major changes to their infrastructure and deployments (part of the benefits of using open, modular tools).\nOnce this is complete, we’ll next shift our attention to some new areas of development that support use-cases in the Pangeo community (and in the scientific community more broadly). There’s a lot of progress that we imagine making - such as supporting sharing pipelines via the Pangeo Gallery or improving tools for scalable computing with Dask Gateway. We’ll provide updates as we formally begin this collaboration and hash out a plan for our next steps.\nJupyterHub for education - A collaboration with CloudBank and UC Berkeley # In addition, we’ve begun a partnership with the UC Berkeley Data Science in Undergraduate Studies program, as well as CloudBank. This collaboration aims to provide hosted JupyterHub infrastructure for community colleges across the state of California. It is an attempt at providing vendor-agnostic and open-source infrastructure to several institutions who would otherwise not be able to deploy this infrastructure on their own.\n2i2c will provide the deployment and configuration architecture for this collaboration, working with Sean Morris in operating this educational infrastructure. All of the cloud infrastructure for this pilot will be funded via CloudBank. We will begin by offering environments that are modeled after the Data 8 course at UC Berkeley. This is part of an effort to build a community of practice around Data Science education using open source tools.\nNew team members # We’ve also welcomed two new members to the 2i2c core team! 🎉\nThese individuals will both work towards 2i2c’s major projects, and collaborate together on running our 2i2c Pilot Hub infrastructure. Here’s a bit about each new team member.\nDamián Avila. Damián has been a Jupyter core team member for many years now, and has done work across many different parts of the PyData stack (in particular, Jupyter, Bokeh, RISE, and Nikola). Damián will focus his efforts on supporting JupyterHub infrastructure for the Pangeo project, as well as development across the Executable Books Project Sarah Gibson. Sarah will join 2i2c in June, after spending several years as a Research Software Engineer at the Turing Institute. She has also been involved with …","date":1621900800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1621900800,"objectID":"dd8c28b4e191724ed9c1ebae27d1be38","permalink":"https://2i2c.org/blog/2021/six-month-update/","publishdate":"2021-05-25T00:00:00Z","relpermalink":"/blog/2021/six-month-update/","section":"blog","summary":"It has been about six months since 2i2c first began operations (after receiving funding from the Chan Zuckerberg Initiative). In that time we’ve made progress along several directions, and wish to use this blog post to provide updates about the ways in which 2i2c has evolved over the first months of its existence.","tags":[],"title":"Pilot hubs, new collaborations, and new team members - A six month update","type":"blog"},{"authors":["Jenny Wong"],"categories":["impact"],"content":" Data8. MIT licensed. Data8 began as a large introductory data science class at UC Berkeley. It uses a Jupyter Book for all course materials, and uses JupyterHub magic links to distribute course content from the textbook.\n2i2c is working with the Data 8 team to deploy JupyterHubs for community colleges in California that run the Data8 course, to make the infrastructure and content broadly accessible.\nGiving people curricula, content, and infrastructure goes a long way to adoption. Communities want to remix content for their specific needs.\nAcknowledgements # This effort is funded by 2i2c together with UC Berkeley and CloudBank.\n","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"fe361272f42875d8a2e01e55296d02b6","permalink":"https://2i2c.org/blog/2021/data8-class/","publishdate":"2021-01-01T00:00:00Z","relpermalink":"/blog/2021/data8-class/","section":"blog","summary":"Data8. MIT licensed. Data8 began as a large introductory data science class at UC Berkeley. It uses a Jupyter Book for all course materials, and uses JupyterHub magic links to distribute course content from the textbook.","tags":["education"],"title":"2i2c partners with UC Berkeley and CloudBank to provide data science education hubs for community colleges in California","type":"blog"},{"authors":null,"categories":null,"content":"We are looking for an Open Source Infrastructure Engineer who will help shape the future of data-intensive scientific research and make a big impact on important problems shaping society. This engineer will lead the development and operation of cloud-based infrastructure, focusing on the Pangeo Project - a community platform for big data geoscience.\n❌❌❌\nThis posting is closed to new applications.\nSee the jobs page for our open positions.\n❌❌❌\nAbout the position\nSalary: $110,000 - $130,000 Location: anywhere (prefer a time zone between US/Pacific and Central European) Deadline: Major duties\nCloud infrastructure management and operations.\nDevelopment of open source infrastructure for hosted JupyterHub service\nFor more general information about 2i2c, see the links below:\nOur Team Compass Our Code of Conduct Our Mission and Values What it’s like to work at 2i2c Click here to Apply Who we are # 2i2c is a non-profit organization with a mission to make interactive computing more accessible, scalable, and powerful for research and education. We strive to…\nSupport data workflows in research and education through infrastructure for interactive computing. Support open tools and communities that underlie this infrastructure. We accomplish this mission by providing managed cloud services for interactive computing, by providing development and technical leadership to researchers and educators that utilize this infrastructure for specific communities, and by providing support for open source tools and communities in this ecosystem.\nWe have deep ties to the open source community, and have been leaders and core contributors across dozens of projects - in particular in the Jupyter ecosystem. We also have deep ties to research and education - our team has spent years deploying infrastructure for universities, community colleges, and research teams, and now we’re bringing this experience to a wider audience with 2i2c.\nWe believe strongly in communities that are inclusive, transparent, equitable, effective, and diverse, especially 2i2c itself. We believe that our values should permeate everything about 2i2c, including the work we do, the communities we serve, and our own organizational culture.\n2i2c is a project of the International Computer Science Institute, a 501(c)(3) not-for-profit.\nWhat you’ll do # You will define the overall strategy and technical approach to cloud computing usage in Pangeo, and will interface with the Pangeo community on a frequent basis. You will help deploy, customize, and operate cloud infrastructure for research and interactive computing. You’ll use the experience operating this infrastructure to identify development opportunities, with the goal of minimizing maintenance time and toil - your goal will be to spend more time developing and less time operating. You will contribute to the general development and maintenance of open source software packages for the advancement of scientific objectives, and develop applications for extracting, transforming, loading, managing, and cataloging scientific data in the cloud. You will engage and interact with open source communities surrounding the tools that you use in serving the Pangeo community, and will represent 2i2c in these engagements. You will also collaborate with scientists to support research projects, and may conduct some education and training around scientific computing.\nResponsibilities # Develops strategy and technical design for cloud computing architecture within the Pangeo project and related projects with 2i2c. Assists with site reliability for Pangeo infrastructure, and uses experience operating this infrastructure to identify new opportunities for development. Ensures the reliable operation of production cloud-based tools including JupyterHub / JupyterLab and Dask. Participates in the upstream open source communities we rely on (such as JupyterHub, Dask, etc) by contributing code, documentation, etc as needed. Develops dashboards and reports to quantify system usage and costs. Helps to maintain and operate Pangeo Gallery, an interactive showcase for data science projects based on binder and github workflows. Conducts education and outreach around cloud computing. Explores emerging technologies in the cloud / DevOps space. Travels to conferences and workshops (once COVID-19 restrictions end). Will work with minimal supervision from leadership at 2i2c in partnership with collaborators at Columbia and the Pangeo project. Will work independently and make their own decisions about where to best allocate effort. Requirements # Familiarity with deploying applications on cloud infrastructure. Experience developing tools in a general purpose programming language (eg. Python) Experience deploying and developing with Linux container technologies, such as Docker and Kubernetes Experience with continuous integration services (e.g. Travis CI, GitHub workflows) Experience building and deploying backend web services. Experience collaborating and …","date":1607472e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607472e3,"objectID":"0f43f426f967699a3f706a81695b7caa","permalink":"https://2i2c.org/jobs/2021/osie-pangeo/","publishdate":"2020-12-09T00:00:00Z","relpermalink":"/jobs/2021/osie-pangeo/","section":"jobs","summary":"We are looking for an Open Source Infrastructure Engineer who will help shape the future of data-intensive scientific research and make a big impact on important problems shaping society. This engineer will lead the development and operation of cloud-based infrastructure, focusing on the Pangeo Project - a community platform for big data geoscience.","tags":null,"title":"Open Source Infrastructure Engineer: Pangeo Project","type":"jobs"},{"authors":["Chris Holdgraf"],"categories":["organization"],"content":"Last week we announced the creation of 2i2c, a non-profit initiative dedicated to improving and facilitating access to infrastructure for interactive computing workflows in research and education. Today we are thrilled to announce that 2i2c has received core support from the Chan Zuckerberg Initiative. You can find CZI’s announcement here.\nThis funding totals around $1.4m over three years. It provides crucial core support for 2i2c as it bootstraps itself into existence. We are so thankful to CZI for this support. 🎉🙏✨\nThe rest of this post is a short run-down of what we’ll use this funding for, and what we hope to accomplish.\nThe big picture # In recent years, several projects including Binder, Pangeo, Syzygy, and the Berkeley DataHubs have built atop the Jupyter architecture to support cloud-based infrastructure for reproducible research, large-scale scientific data analysis, national-scale infrastructure for researchers, and broad-impact educational programs based on freely available computational materials. These projects illustrate the transformative potential of the open Jupyter architecture, but they have also shown that unlocking this potential in service of scientists and educators requires continued development and resources beyond those of open source volunteers.\nIn order to deploy these resources at scale, manage and maintain them for large communities, and to continue developing the underlying technologies for scientific use cases, we need models to sustainably deploy and improve Jupyter technology. We also need capacity for thinking strategically and forging new partnerships to accomplish this goal. This funding will support 2i2c’s early strategic planning and partnership efforts, as well as technical development and operation of Jupyter infrastructure for research and education.\nBelow are two keys goals for this grant:\nGoal 1: Build capacity for Jupyter in research and education # The primary goal of this funding is to build more capacity for Jupyter’s engagement in research and education. This funding will primarily support Chris Holdgraf to build strategic partnerships and collaborations, find opportunities for Jupyter infrastructure to benefit research and education, coordinate activity in the Jupyter project that benefits these communities, and secure more funding for development, maintenance, and support for Jupyter technology.\nWe are grateful to CZI for this funding because strategy, leadership, and community support are often difficult to fund from grants that are focused on technical deliverables. By funding strategic growth and capacity building, CZI is helping 2i2c lay a strong foundation from which it can have a greater impact.\nGoal 2: Support hosted Jupyter infrastructure for research and education # 2i2c will offer hosted interactive computing infrastructure utilizing the Jupyter ecosystem. It will both deploy and operate this infrastructure for researchers and educators, as well as perform core development to ensure that it serves these communities well. Funding from this grant will support 2i2c’s first hire - Georgiana Dolocan as an Open Source Infrastructure Engineer. Georgiana has been the JupyterHub Contributor in Residence for the past year, and we are so excited for her to join 2i2c!\nGeorgiana will begin by supporting several pilot hubs that are run by 2i2c for community colleges, universities, and research institutions. She will help these organizations accomplish their mission through 2i2c infrastructure, and will develop these technologies so they are stable, scalable, and serve a diverse set of needs in research and education. This will hopefully set the foundation for 2i2c to sustainably offer this hub infrastructure to a wider audience in the future.\nThis is the next step in Georgiana’s journey through the Jupyter ecosystem that began with an outreachy internship followed by a term as Contributor in Residence. Both of these steps were made possible thanks to Jupyter stakeholders who invest their resources, time, and mentorship to grow Jupyter’s community beyond the people that have traditionally been involved in the project. It’s also possible because of funders committing resources to broaden participation and inclusion - in particular, the Berkeley Institute for Data Science and NumFOCUS for their original support of our Outreachy interns and the CZI EOSS grant series for funding the original Contributor in Residence.\nWhat’s next # With this core support, 2i2c turns towards its JupyterHub pilot deployments to build early prototypes that serve research and education, and to build organizational models that sustain these hubs and their development. If you or your organization think you’d be a good fit for these pilots, please reach out to 2i2c and let us know!\nMany thanks again to CZI for this support - we believe that it is an excellent investment in the Jupyter community and in open source communities more generally. We also believe it will lead to major advancements …","date":1605744e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1605744e3,"objectID":"110ad797b7358afdff75f2722272af75","permalink":"https://2i2c.org/blog/2021/czi-core-support/","publishdate":"2020-11-19T00:00:00Z","relpermalink":"/blog/2021/czi-core-support/","section":"blog","summary":"Last week we announced the creation of 2i2c, a non-profit initiative dedicated to improving and facilitating access to infrastructure for interactive computing workflows in research and education. Today we are thrilled to announce that 2i2c has received core support from the Chan Zuckerberg Initiative.","tags":["meta"],"title":"2i2c receives core support from CZI","type":"blog"},{"authors":["Chris Holdgraf"],"categories":["organization"],"content":"👋 hey everyone!\nWe’d like to announce the creation of a new non-profit organization1 that we call 2i2c.\n2i2c stands for The International Interactive Computing Collaboration. It is a non-profit dedicated to making open tools for interactive computing more accessible and more powerful for the research and education communities.\nThis is a short post about why we created 2i2c, what we hope that it will do, and what we are up to next. If you’d prefer to watch a video instead of read a blog post, check out this talk about 2i2c at JupyterCon 2020:\nWhy create 2i2c? # The founding team of 2i2c has spent the last several years running projects that use interactive computing for research and education, including bringing data science education to thousands of students, connecting geospatial researchers with large datasets and computational resources in the cloud, and providing federated online environment hubs to schools across Canada, to name a few.\nOver time we realized that, while infrastructure for interactive computing could be a huge benefit to research and education, it also required a fair amount of expertise to configure, deploy, and develop. We wished for other organizations to enjoy the same success that we had found, but learned that for many, deploying their own infrastructure was a non-starter to adoption. Instead, many were turning to proprietary or vendor-specific tooling.\nWe created 2i2c so that these organizations can use entirely open-source tools without hiring and training their own dev-ops and infrastructure talent, and so that development and support of open tools for interactive computing continues to represent the interests of research and education.\nWhy a non-profit? # It may sound strange to create a non-profit initiative when there are many VC-funded startups and large tech companies offering notebook services these days. However, we think that a non-profit organization is the right approach to balance the interests of all the stakeholders that we wish to serve. We hope that 2i2c will be a partner to:\nResearch and educational communities, who can rely on 2i2c to provide them cutting-edge infrastructure for interactive computing that is 💯 open source. Researchers and educators who need development, who can rely on 2i2c as a collaborator that offers development and expertise in open-source infrastructure to push the cutting edge of interactive computing in the cloud. Open source communities, who can count on 2i2c support and grow the communities that underlie the tools that we deploy. Cloud providers, who wish to help the research and educational community via their infrastructure. Supporters of open source who wish to support interactive computing for research and education via a non-profit dedicated to exactly this mission. As a non-profit initiative, 2i2c is dedicated to supporting an ecosystem of tools and stakeholders across the open source community, and to ensuring that those tools are well-suited for research and education. We believe strongly in mission-driven work, and non-profit status will ensure that the work that we do is always aligned with our mission and values.\nWhat are we going to do? # With all of that in mind, what is 2i2c actually going to do? We are still working out the details, but here’s a rough picture:\nOffer hosted interactive computing environments on cloud infrastructure. These will be entirely open source and vendor-neutral, and customizable for the communities that are using them. They’ll be offered either as a fee-for-service model and/or subsidized through grants and donations. We wish to build upon the success of JupyterHub as a gateway to computational resources and environments, learning environments, and communities of users. For more information about the vision and values of our hosted infrastructure, see the 2i2c Right to Replicate document.\nProvide collaboration and development for interactive computing in research and education. Beyond providing hub infrastructure, there are many ways in which solving problems in research and education can lead to better tools, infrastructure, and workflows in the open source community. For example - how can we generalize a community’s solution to scalable computing so that it can be useful for other use-cases as well? We hope that 2i2c can be an aggregator and integrator of many perspectives in research and education, and build tools that are maximally useful across communities.\nProvide core development and community support for open source projects that we use. While many organizations use Jupyter technology in their projects, it is also crucial that they give back to those tools in order to keep the ecosystem healthy. As a mission-driven non-profit, 2i2c has a core goal in not only deploying and customizing open source tools, but also providing core support for them.\nNext steps # 2i2c is a young organization, but we already have a few exciting ideas to work towards in the coming months. Here’s an idea of what …","date":1604966400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1604966400,"objectID":"4fbd63f9efdd7c1913ddfa4eeef26698","permalink":"https://2i2c.org/blog/2021/hello-world/","publishdate":"2020-11-10T00:00:00Z","relpermalink":"/blog/2021/hello-world/","section":"blog","summary":"👋 hey everyone!\nWe’d like to announce the creation of a new non-profit organization1 that we call 2i2c.\n2i2c stands for The International Interactive Computing Collaboration. It is a non-profit dedicated to making open tools for interactive computing more accessible and more powerful for the research and education communities.","tags":["meta"],"title":"Hello World","type":"blog"},{"authors":null,"categories":null,"content":"The Right to Replicate gives communities the right to replicate their infrastructure in its entirety elsewhere, with or without 2i2c.\nThis document describes 2i2c’s commitment to a community’s “right to replicate”, and how this translates into specific infrastructure commitments from 2i2c. We make these commitments because we believe that using infrastructure that follows these principles will lead to a more fair, just, equitable world. We also believe they are the right foundation for more productive and impactful research and education.\n2i2c is committed to running its own infrastructure on open-source tools and vendor-agnostic infrastructure, though it does not force users to use only open-source tools in their own environments, code, and data. Below is a table describing how the Right to Replicate fits into 2i2c hub technology.\n(Definitions of MUST, MUST NOT, SHOULD, MAY, etc are defined in RFC 2119)\nUser Code and Data May be Open Source We encourage adopting and producing open source code and data, but this is up to the user. e.g., licenses for user content/code User Environment Should be Open Source Strong preference for open source tools only, although in some cases user needs may override this. e.g., Python, R, PyData stack. 2i2c Infrastructure Must be Open Source Strong commitment to using only open source software. e.g., JupyterHub, Kubernetes, Postgresql Cloud Provider Infrastructure Must be Portable See this blog post for more information. Below we describe our commitments in our own infrastructure stack in more detail.\nHow 2i2c infrastructure ensures this right # 2i2c infrastructure and documentation for it MUST BE as transparent \u0026amp; accessible as possible, so communities can replicate our configuration without having to extract any ‘secret sauce’ from 2i2c. If they choose to, they can also inspect, audit \u0026amp; modify the infrastructure they are paying for and using.\nTo ensure the Right to Replicate to our communities, 2i2c makes the following commitments to infrastructure we build and operate:\nWe MUST use only open source software to run our infrastructure. By only using software that is available to everyone on the same terms, we can ensure that communities can replicate the infrastructure without having to negotiate licensing terms with proprietary software vendors. In addition, any changes we make to open source software will be made in public and/or contributed upstream, so communities continue to have access to them regardless of where their infrastructure is.\nWe MUST NOT directly depend on proprietary cloud vendor specific products or APIs. Instead, we use cloud-managed open source software, or hide the dependency behind a layer of abstraction. This ensures that communities can port their infrastructure to any cloud provider of their choice, or run it on their own hardware with purely open source software.\nThis set of commitments acts as a business continuity plan for our partner communities, ensuring 2i2c will follow best practices within the open source, open education and open research ecosystems.\n","date":1530144e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1530144e3,"objectID":"f9d84027023bd7709772a71806b3aca9","permalink":"https://2i2c.org/right-to-replicate/","publishdate":"2018-06-28T00:00:00Z","relpermalink":"/right-to-replicate/","section":"","summary":"The Right to Replicate gives communities the right to replicate their infrastructure in its entirety elsewhere, with or without 2i2c.\nThis document describes 2i2c’s commitment to a community’s “right to replicate”, and how this translates into specific infrastructure commitments from 2i2c.","tags":null,"title":"The Community Right to Replicate","type":"page"},{"authors":null,"categories":null,"content":" How we are funded # To sustain and grow our operations, 2i2c receives funding from the following sources:\nRevenue from managed services. We build self-sustaining cloud services that generate revenue through management and support contracts. See our services page for more information. Project-focused grants. We lead and collaborate on several projects that involve developing and supporting infrastructure for research and education. See our projects page for more information. Core organizational support. We raise core funding that covers the costs of strategically-critical roles that are not easily linked to specific deliverables and contracts. 2i2c’s Financial and Sustainability Strategy page has our full financial sustainability strategy.\nOur accounting dashboards have all our latest costs and revenue.\nMajor sources of funding # The Chan Zuckerberg Initiative has supported 2i2c with three awards over 2i2c\u0026#39;s lifetime. In 2020, we received ~$1.4m over 3 years to support capacity building in the Jupyter ecosystem for research and education. In 2022, we received ~$800K over two years to serve open cloud infrastructure to communities in Latin America and Africa. In 2024, we received ~700K over one year for core organizational support for 2i2c\u0026#39;s mission.\nIn 2024, we received ~$1.5M over 2 years from The Navigation Fund to identify and build a scalable sustainability model for 2i2c.\nIn 2020, we received $500,000 over two years from the Climate Data Lab at Columbia University for managing and developing cloud infrastructure for the Pangeo Project.\nInvest in Open Infrastructure along with Joint Roadmap for Open Science Tools awarded 2i2c a $5,000 grant to fund JupyterHub cloud infrastructure for projects that did not have their own cloud funding.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"080d5a69558533d6e0e3d9e9fa594939","permalink":"https://2i2c.org/about/funding/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/about/funding/","section":"about","summary":"How we are funded # To sustain and grow our operations, 2i2c receives funding from the following sources:\nRevenue from managed services. We build self-sustaining cloud services that generate revenue through management and support contracts.","tags":null,"title":"","type":"about"},{"authors":null,"categories":null,"content":" Our commitment to open technology # This page describes 2i2c’s commitment to developing and contributing to infrastructure that is open source now and into the future. More context can be found in this blog post.\nDefinitions of MUST, MUST NOT, SHOULD, MAY, etc are defined in RFC 2119\nAll engineering artifacts (code, documentation, etc) produced by 2i2c’s engineering team MUST be licensed under an open source license approved by a non-profit organization that is not 2i2c.1 Open Source Projects originating at 2i2c, or stewarded by 2i2c, MUST NOT require a Contributor Licensing Agreement that includes Copyright Assignment to 2i2c. 2 The list of external organizations that define licenses we accept are3: the Open Source Initiative the Organization for Ethical Source. Modifying (1), (2), or (3) MUST be done through a 2/3 majority vote of 2i2c staff. 4 These commitments ensure 2i2c’s ongoing support for open source technology and community-owned infrastructure, and constrain us from changing this commitment in a way that would harm our communities. We hope that this builds trust with our communities to rely on 2i2c as a provider and a steward of their infrastructure. See this blog post for more context\nThis constrains us from writing proprietary engineering code or creating proprietary products. Note that this only applies to 2i2c artifacts, and not those that are created by our member communities. ↩︎\nProtects from the most common “bait and switch” licensing problem, where being the sole copyright owner of a project allows us to change the license in the future because we’ve retained ownership over all the code. ↩︎\nThis constrains us from creating a new non profit that rubberstamps a license that is fundamentally proprietary, while still allowing for experimentation with licenses that try to innovate on OSI. ↩︎\nThis sets an intentionally-high bar for modifying this policy. In 2025 we aim to re-establish our steering council along with a community advisory board that is tasked with defining policy like this. In the interrim, we choose 2/3 of the organization to be a reasonably high bar for changing this policy ↩︎\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"9152f5d2b5a778f8180098c4f8c61f2c","permalink":"https://2i2c.org/open-technology/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/open-technology/","section":"","summary":"Our commitment to open technology # This page describes 2i2c’s commitment to developing and contributing to infrastructure that is open source now and into the future. More context can be found in this blog post.","tags":null,"title":"","type":"page"},{"authors":null,"categories":null,"content":" ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"c2c20062023db009d767c2f4a7d38088","permalink":"https://2i2c.org/pilot-hubs/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/pilot-hubs/","section":"","summary":" ","tags":null,"title":"","type":"page"},{"authors":null,"categories":null,"content":" ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"74dcede968ab0952007871e9fa0da40e","permalink":"https://2i2c.org/pilot/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/pilot/","section":"","summary":" ","tags":null,"title":"","type":"page"},{"authors":null,"categories":null,"content":" ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"cbf2769f3919dc1ca746df7980be9eff","permalink":"https://2i2c.org/team-compass/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/team-compass/","section":"","summary":" ","tags":null,"title":"","type":"page"},{"authors":null,"categories":null,"content":"2i2c has expertise in cloud infrastructure and managed services for interactive computing in research and education workflows. We focus on the Jupyter ecosystem and adjacent open source communities (e.g., the PyData ecosystem), with a particular emphasis on JupyterHub.\nJoin our mailing list 📰 Send us an email ✉️ Our Team Compass contains all of 2i2c’s organizational strategy, policy, and team practices. Our updates blog series provides all major organizational updates for our community. Our Service Level Objectives describes our day-to-day goals running the service. Our Shared Responsibility Model describes how we collaborate with communities in this hub service. Our Infrastructure Guide describes all of our cloud infrastructure and engineering practices, with links to our codebase. Here are a few ways that you can connect with and collaborate with 2i2c.\nUse and support our managed JupyterHub services # 2i2c aims to provide Managed JupyterHubs in the cloud that are customized for communities in research and education. We are exploring sustainability and services models around this goal, and invite feedback and ideas for ways that we can improve this service. We are running JupyterHubs for many communities already, and are accepting new communities in batches as our capacity grows. If you are interested in having a managed JupyterHub for your community, check out our cloud service page for more information or send an email to partnerships@2i2c.org to discuss.\nPitch a project or grant # Our team is always looking our for opportunities to collaborate and learn from others in order to have an impact. Sometimes these can even lead to new grant ideas or ongoing projects. If you have an idea for collaboration that is aligned with our mission, and that would benefit from our skills and perspective, please send an email to partnerships@2i2c.org and we can discuss.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"5fff794d732d0d9048992165a6c484a4","permalink":"https://2i2c.org/collaborate/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/collaborate/","section":"","summary":"2i2c has expertise in cloud infrastructure and managed services for interactive computing in research and education workflows. We focus on the Jupyter ecosystem and adjacent open source communities (e.g., the PyData ecosystem), with a particular emphasis on JupyterHub.","tags":null,"title":"Contact us to collaborate","type":"page"},{"authors":null,"categories":null,"content":" Brand guidelines # Our Brand Guidelines document describes 2i2c’s overall brand and visual style.\nLogos # Square logo (default) # Logo\nDownload SVG | Download PDF\nLogo light\nLogo black\nWide logos # Wide logo\nDownload SVG | Download PDF\nWide logo light\nColors # Primary colors # Big Blue: #1D4EF5 Pale Blue: #F2F5FC Black: #000000 Secondary colors # Midnight: #230344\nMauve: #B86BFC\nForest: #057761\nLight Green: #0CEFAE\nMagenta: #C60A76\nPink: #FF808B\nCoral: #FF4E4F\nYellow: #FFDE17\nDesign assets # These two links are only accessible to 2i2c team members.\nFigma canvas with design assets\nGoogle Drive folder with design assets\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"0cb45ec32ab674771091450a1bc1fdc4","permalink":"https://2i2c.org/brand/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/brand/","section":"","summary":"Brand guidelines # Our Brand Guidelines document describes 2i2c’s overall brand and visual style.\nLogos # Square logo (default) # Logo\nDownload SVG | Download PDF\nLogo light\nLogo black","tags":null,"title":"Design and brand guidelines","type":"page"},{"authors":null,"categories":null,"content":"Much of the work we do is supported by grants and donations from stakeholders in our community. These resources go towards things like new development of open source technology, maintenance for open source projects, community development efforts, sponsoring hubs for under-resourced communities, and general support for 2i2c in its mission.\nFill our the form below to make a donation to 2i2c via its fiscal sponsor, Code for Science and Society. If you’d rather have a conversation with us first about your donation, please send us an email.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"ac26b9ca282f87df5d5ed826e374bb78","permalink":"https://2i2c.org/donate/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/donate/","section":"","summary":"Much of the work we do is supported by grants and donations from stakeholders in our community. These resources go towards things like new development of open source technology, maintenance for open source projects, community development efforts, sponsoring hubs for under-resourced communities, and general support for 2i2c in its mission.","tags":null,"title":"Donate to 2i2c","type":"page"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"6087c0ef875554f4409ac52928d79279","permalink":"https://2i2c.org/projects/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/projects/","section":"","summary":"","tags":null,"title":"Open Source","type":"widget_page"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"8ab4338b5212831f3b729ac977000df4","permalink":"https://2i2c.org/founders/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/founders/","section":"","summary":"","tags":null,"title":"Our Founding Team","type":"widget_page"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"6425ff024d90bbffa37d23fc4bf403ee","permalink":"https://2i2c.org/organization/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/organization/","section":"","summary":"","tags":null,"title":"Our organization","type":"widget_page"}]